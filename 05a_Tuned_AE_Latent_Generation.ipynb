{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09327dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 14:46:44.417464: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-23 14:46:44.417526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-23 14:46:44.419553: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-23 14:46:44.626224: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-23 14:46:46.572353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import glob\n",
    "import sklearn \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras_tuner import BayesianOptimization, HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e0bf33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.3249</td>\n",
       "      <td>9.6718</td>\n",
       "      <td>6.0082</td>\n",
       "      <td>9.6574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3105</td>\n",
       "      <td>10.6216</td>\n",
       "      <td>5.9996</td>\n",
       "      <td>11.2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7233</td>\n",
       "      <td>11.4243</td>\n",
       "      <td>7.3021</td>\n",
       "      <td>11.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.4864</td>\n",
       "      <td>10.7079</td>\n",
       "      <td>6.4156</td>\n",
       "      <td>10.7262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4673</td>\n",
       "      <td>12.0023</td>\n",
       "      <td>6.3573</td>\n",
       "      <td>11.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>4.9712</td>\n",
       "      <td>8.9677</td>\n",
       "      <td>10.1179</td>\n",
       "      <td>8.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>4.8021</td>\n",
       "      <td>9.0623</td>\n",
       "      <td>10.1026</td>\n",
       "      <td>8.6752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>5.9590</td>\n",
       "      <td>10.3438</td>\n",
       "      <td>8.6309</td>\n",
       "      <td>9.4556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>4.3996</td>\n",
       "      <td>10.3760</td>\n",
       "      <td>9.5901</td>\n",
       "      <td>9.3513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>5.2675</td>\n",
       "      <td>10.8606</td>\n",
       "      <td>8.6371</td>\n",
       "      <td>9.7884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            7       20       26       27\n",
       "0      6.3249   9.6718   6.0082   9.6574\n",
       "1      6.3105  10.6216   5.9996  11.2509\n",
       "2      5.7233  11.4243   7.3021  11.5329\n",
       "3      5.4864  10.7079   6.4156  10.7262\n",
       "4      5.4673  12.0023   6.3573  11.2367\n",
       "...       ...      ...      ...      ...\n",
       "39995  4.9712   8.9677  10.1179   8.9430\n",
       "39996  4.8021   9.0623  10.1026   8.6752\n",
       "39997  5.9590  10.3438   8.6309   9.4556\n",
       "39998  4.3996  10.3760   9.5901   9.3513\n",
       "39999  5.2675  10.8606   8.6371   9.7884\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.9702</td>\n",
       "      <td>17.3049</td>\n",
       "      <td>22.7152</td>\n",
       "      <td>30.7508</td>\n",
       "      <td>24.7567</td>\n",
       "      <td>23.1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.2704</td>\n",
       "      <td>22.4792</td>\n",
       "      <td>22.4227</td>\n",
       "      <td>28.1640</td>\n",
       "      <td>23.8363</td>\n",
       "      <td>23.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.8551</td>\n",
       "      <td>25.5636</td>\n",
       "      <td>24.6903</td>\n",
       "      <td>30.2936</td>\n",
       "      <td>24.8655</td>\n",
       "      <td>23.4604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.3881</td>\n",
       "      <td>26.4733</td>\n",
       "      <td>24.4458</td>\n",
       "      <td>29.5746</td>\n",
       "      <td>21.3842</td>\n",
       "      <td>22.6630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.2788</td>\n",
       "      <td>24.0147</td>\n",
       "      <td>23.2922</td>\n",
       "      <td>27.5496</td>\n",
       "      <td>23.8249</td>\n",
       "      <td>22.3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>19.7170</td>\n",
       "      <td>14.7258</td>\n",
       "      <td>12.9418</td>\n",
       "      <td>8.4287</td>\n",
       "      <td>24.3534</td>\n",
       "      <td>22.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>17.8741</td>\n",
       "      <td>15.5602</td>\n",
       "      <td>12.3054</td>\n",
       "      <td>7.1757</td>\n",
       "      <td>24.9417</td>\n",
       "      <td>24.1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>17.2324</td>\n",
       "      <td>15.4532</td>\n",
       "      <td>12.3721</td>\n",
       "      <td>7.1490</td>\n",
       "      <td>23.8513</td>\n",
       "      <td>27.4276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>17.0120</td>\n",
       "      <td>15.1188</td>\n",
       "      <td>13.4625</td>\n",
       "      <td>7.5725</td>\n",
       "      <td>25.4096</td>\n",
       "      <td>26.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>16.6571</td>\n",
       "      <td>15.4409</td>\n",
       "      <td>13.2021</td>\n",
       "      <td>7.2976</td>\n",
       "      <td>26.2683</td>\n",
       "      <td>24.6460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             6       16       17       19       29       30\n",
       "0      14.9702  17.3049  22.7152  30.7508  24.7567  23.1634\n",
       "1      13.2704  22.4792  22.4227  28.1640  23.8363  23.2798\n",
       "2      13.8551  25.5636  24.6903  30.2936  24.8655  23.4604\n",
       "3      12.3881  26.4733  24.4458  29.5746  21.3842  22.6630\n",
       "4      14.2788  24.0147  23.2922  27.5496  23.8249  22.3185\n",
       "...        ...      ...      ...      ...      ...      ...\n",
       "39995  19.7170  14.7258  12.9418   8.4287  24.3534  22.6400\n",
       "39996  17.8741  15.5602  12.3054   7.1757  24.9417  24.1508\n",
       "39997  17.2324  15.4532  12.3721   7.1490  23.8513  27.4276\n",
       "39998  17.0120  15.1188  13.4625   7.5725  25.4096  26.8701\n",
       "39999  16.6571  15.4409  13.2021   7.2976  26.2683  24.6460\n",
       "\n",
       "[40000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.2374</td>\n",
       "      <td>40.1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.5602</td>\n",
       "      <td>36.3229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.4329</td>\n",
       "      <td>41.2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.1207</td>\n",
       "      <td>39.2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.6335</td>\n",
       "      <td>38.7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>16.9755</td>\n",
       "      <td>31.9599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>17.0192</td>\n",
       "      <td>29.9824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>18.5272</td>\n",
       "      <td>29.4126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>17.1766</td>\n",
       "      <td>32.6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>17.7794</td>\n",
       "      <td>33.5279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             9       21\n",
       "0      14.2374  40.1886\n",
       "1      14.5602  36.3229\n",
       "2      17.4329  41.2223\n",
       "3      20.1207  39.2809\n",
       "4      15.6335  38.7009\n",
       "...        ...      ...\n",
       "39995  16.9755  31.9599\n",
       "39996  17.0192  29.9824\n",
       "39997  18.5272  29.4126\n",
       "39998  17.1766  32.6983\n",
       "39999  17.7794  33.5279\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------\n",
      "D132H for window size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.6253</td>\n",
       "      <td>11.4558</td>\n",
       "      <td>7.0366</td>\n",
       "      <td>10.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6219</td>\n",
       "      <td>11.7791</td>\n",
       "      <td>6.8272</td>\n",
       "      <td>10.8156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3355</td>\n",
       "      <td>9.9860</td>\n",
       "      <td>6.2585</td>\n",
       "      <td>9.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7119</td>\n",
       "      <td>8.4264</td>\n",
       "      <td>5.8994</td>\n",
       "      <td>8.1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.7166</td>\n",
       "      <td>9.3508</td>\n",
       "      <td>6.4404</td>\n",
       "      <td>10.1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>4.6642</td>\n",
       "      <td>10.3721</td>\n",
       "      <td>10.9673</td>\n",
       "      <td>9.8788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>4.7521</td>\n",
       "      <td>11.6737</td>\n",
       "      <td>10.7638</td>\n",
       "      <td>9.5196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>4.5160</td>\n",
       "      <td>9.7824</td>\n",
       "      <td>10.9669</td>\n",
       "      <td>9.6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>4.8358</td>\n",
       "      <td>7.8161</td>\n",
       "      <td>10.7679</td>\n",
       "      <td>9.6355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>4.5663</td>\n",
       "      <td>10.1266</td>\n",
       "      <td>10.9913</td>\n",
       "      <td>9.2231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            7       20       26       27\n",
       "0      5.6253  11.4558   7.0366  10.8265\n",
       "1      5.6219  11.7791   6.8272  10.8156\n",
       "2      6.3355   9.9860   6.2585   9.7506\n",
       "3      4.7119   8.4264   5.8994   8.1239\n",
       "4      7.7166   9.3508   6.4404  10.1599\n",
       "...       ...      ...      ...      ...\n",
       "39995  4.6642  10.3721  10.9673   9.8788\n",
       "39996  4.7521  11.6737  10.7638   9.5196\n",
       "39997  4.5160   9.7824  10.9669   9.6701\n",
       "39998  4.8358   7.8161  10.7679   9.6355\n",
       "39999  4.5663  10.1266  10.9913   9.2231\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D132H for window size = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.9958</td>\n",
       "      <td>16.3721</td>\n",
       "      <td>20.6416</td>\n",
       "      <td>29.6048</td>\n",
       "      <td>24.1730</td>\n",
       "      <td>23.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0499</td>\n",
       "      <td>15.4543</td>\n",
       "      <td>20.4593</td>\n",
       "      <td>28.2314</td>\n",
       "      <td>25.1477</td>\n",
       "      <td>23.0454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.5011</td>\n",
       "      <td>13.1972</td>\n",
       "      <td>16.8349</td>\n",
       "      <td>29.2049</td>\n",
       "      <td>23.6181</td>\n",
       "      <td>18.1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6412</td>\n",
       "      <td>15.6381</td>\n",
       "      <td>18.6334</td>\n",
       "      <td>27.5069</td>\n",
       "      <td>25.6890</td>\n",
       "      <td>20.3013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.5941</td>\n",
       "      <td>18.8374</td>\n",
       "      <td>20.8179</td>\n",
       "      <td>29.7816</td>\n",
       "      <td>23.7772</td>\n",
       "      <td>20.6936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>13.3469</td>\n",
       "      <td>15.4144</td>\n",
       "      <td>13.0795</td>\n",
       "      <td>12.4362</td>\n",
       "      <td>7.2937</td>\n",
       "      <td>12.2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>13.3072</td>\n",
       "      <td>15.0391</td>\n",
       "      <td>12.4597</td>\n",
       "      <td>12.2133</td>\n",
       "      <td>7.2107</td>\n",
       "      <td>13.3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>13.4729</td>\n",
       "      <td>15.5238</td>\n",
       "      <td>12.5300</td>\n",
       "      <td>12.2077</td>\n",
       "      <td>7.7544</td>\n",
       "      <td>12.6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>12.8318</td>\n",
       "      <td>15.9725</td>\n",
       "      <td>13.9111</td>\n",
       "      <td>12.2538</td>\n",
       "      <td>7.3585</td>\n",
       "      <td>12.1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>13.2777</td>\n",
       "      <td>15.6850</td>\n",
       "      <td>13.5851</td>\n",
       "      <td>12.3831</td>\n",
       "      <td>7.2522</td>\n",
       "      <td>12.8442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             6       16       17       19       29       30\n",
       "0      14.9958  16.3721  20.6416  29.6048  24.1730  23.9425\n",
       "1      15.0499  15.4543  20.4593  28.2314  25.1477  23.0454\n",
       "2      16.5011  13.1972  16.8349  29.2049  23.6181  18.1444\n",
       "3      13.6412  15.6381  18.6334  27.5069  25.6890  20.3013\n",
       "4      16.5941  18.8374  20.8179  29.7816  23.7772  20.6936\n",
       "...        ...      ...      ...      ...      ...      ...\n",
       "39995  13.3469  15.4144  13.0795  12.4362   7.2937  12.2014\n",
       "39996  13.3072  15.0391  12.4597  12.2133   7.2107  13.3563\n",
       "39997  13.4729  15.5238  12.5300  12.2077   7.7544  12.6172\n",
       "39998  12.8318  15.9725  13.9111  12.2538   7.3585  12.1032\n",
       "39999  13.2777  15.6850  13.5851  12.3831   7.2522  12.8442\n",
       "\n",
       "[40000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D132H for window size = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4055</td>\n",
       "      <td>41.6856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0150</td>\n",
       "      <td>40.2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0081</td>\n",
       "      <td>41.7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.6520</td>\n",
       "      <td>40.4408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.7450</td>\n",
       "      <td>38.0932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>14.0324</td>\n",
       "      <td>23.2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>14.9455</td>\n",
       "      <td>22.4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>14.0516</td>\n",
       "      <td>22.7481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>14.0350</td>\n",
       "      <td>23.5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>14.3382</td>\n",
       "      <td>22.8859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             9       21\n",
       "0      13.4055  41.6856\n",
       "1      12.0150  40.2262\n",
       "2      17.0081  41.7220\n",
       "3      15.6520  40.4408\n",
       "4      20.7450  38.0932\n",
       "...        ...      ...\n",
       "39995  14.0324  23.2605\n",
       "39996  14.9455  22.4160\n",
       "39997  14.0516  22.7481\n",
       "39998  14.0350  23.5958\n",
       "39999  14.3382  22.8859\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data import\n",
    "wt_filtered = ['wt_filtered_lcc_3_50.lccdata', 'wt_filtered_lcc_12_50.lccdata', 'wt_filtered_lcc_20_50.lccdata']\n",
    "\n",
    "# filtered wt LCC data import\n",
    "wt_f_var_names = ['wt_3f', 'wt_12f', 'wt_20f']\n",
    "\n",
    "for var, file in zip(wt_f_var_names, wt_filtered):\n",
    "    globals()[var] = pd.read_csv(file, sep='\\t').drop(columns='Unnamed: 0')\n",
    "\n",
    "# filtered mutant LCC data import\n",
    "D132H_filtered = ['D132H_filtered_lcc_3_50.lccdata', 'D132H_filtered_lcc_12_50.lccdata', 'D132H_filtered_lcc_20_50.lccdata']\n",
    "D132H_f_var_names = ['D132H_3f', 'D132H_12f', 'D132H_20f']\n",
    "\n",
    "for var, file in zip(D132H_f_var_names, D132H_filtered):\n",
    "    globals()[var] = pd.read_csv(file, sep='\\t').drop(columns='Unnamed: 0')\n",
    "    \n",
    "# Visualization of dataset\n",
    "print('WT for window size = 3')\n",
    "display(wt_3f)\n",
    "print('WT for window size = 12')\n",
    "display(wt_12f)\n",
    "print('WT for window size = 20')\n",
    "display(wt_20f)\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------')\n",
    "print('D132H for window size = 3')\n",
    "display(D132H_3f)\n",
    "print('D132H for window size = 12')\n",
    "display(D132H_12f)\n",
    "print('D132H for window size = 20')\n",
    "display(D132H_20f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc552490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concateneate wt and mutant dataframes and rename columns\n",
    "\n",
    "wt_f = pd.concat([wt_3f, wt_12f, wt_20f], axis = 1)\n",
    "    \n",
    "D132H_f = pd.concat([D132H_3f, D132H_12f, D132H_20f], axis = 1)\n",
    "\n",
    "colnames = [*range(0,12)]\n",
    "colnames\n",
    "wt_f.columns = colnames\n",
    "D132H_f.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9faae3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre processing\n",
    "\n",
    "def preprocessing(wt, mutant):\n",
    "    \n",
    "    wt_label = np.zeros(len(wt)) # Set wt labels to 0\n",
    "    \n",
    "    mutant_label = np.ones(len(mutant))\n",
    "    \n",
    "    # Concatenate data frames and label arrays\n",
    "\n",
    "    X_train_full = pd.concat([wt.reset_index(), mutant.reset_index()])\n",
    "    y_train_full = np.concatenate((wt_label, mutant_label))\n",
    "    \n",
    "    #Drop index column and normalise training data\n",
    "    X_train_full = X_train_full.drop(columns = 'index')\n",
    "    \n",
    "    X_train_full= X_train_full.div(100) ## When changed from 100 to 56.1035, errors generated.\n",
    "    \n",
    "    # Separate training and validation sets and print relevant shapes\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, stratify=y_train_full, test_size=0.2)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(X_valid.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_valid.shape)\n",
    "    \n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3072ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 12)\n",
      "(16000, 12)\n",
      "(64000,)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_f, X_valid_f, y_train_f, y_valid_f = preprocessing(wt_f, D132H_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa20bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid_f.to_csv('X_val.csv')\n",
    "\n",
    "y_valid_f_df = pd.DataFrame({'class':y_valid_f})\n",
    "y_valid_f_df.to_csv('y_val_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb1adf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "30165  0.048119  0.101472  0.091832  0.107898  0.145325  0.291379  0.282538   \n",
      "38538  0.068959  0.116012  0.106705  0.091525  0.127055  0.203078  0.162565   \n",
      "2022   0.095933  0.045604  0.077096  0.096224  0.171806  0.146170  0.170079   \n",
      "27634  0.045609  0.082652  0.079041  0.121000  0.098173  0.175467  0.155925   \n",
      "26385  0.058116  0.070519  0.084140  0.091053  0.123414  0.103483  0.051177   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "5720   0.054092  0.078507  0.089275  0.099536  0.130755  0.130880  0.126251   \n",
      "13949  0.050674  0.090001  0.083034  0.101010  0.153621  0.133054  0.081998   \n",
      "29852  0.062419  0.083368  0.082029  0.078645  0.186324  0.133922  0.170336   \n",
      "21815  0.046261  0.089445  0.052040  0.091658  0.145514  0.143408  0.161470   \n",
      "24882  0.049735  0.104655  0.093851  0.091000  0.110423  0.151178  0.132919   \n",
      "\n",
      "              7         8         9        10        11  \n",
      "30165  0.291810  0.184944  0.089273  0.327032  0.332418  \n",
      "38538  0.199806  0.175241  0.173300  0.177312  0.246122  \n",
      "2022   0.058993  0.280405  0.289495  0.116286  0.294761  \n",
      "27634  0.068218  0.172666  0.217632  0.145727  0.261135  \n",
      "26385  0.067258  0.236036  0.241411  0.189796  0.189387  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "5720   0.119531  0.121563  0.084123  0.137018  0.099316  \n",
      "13949  0.065498  0.157708  0.194168  0.134316  0.208787  \n",
      "29852  0.073948  0.226342  0.164590  0.123516  0.198720  \n",
      "21815  0.106446  0.175846  0.226883  0.150143  0.202933  \n",
      "24882  0.074970  0.102674  0.171432  0.201288  0.215001  \n",
      "\n",
      "[16000 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_valid_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f91c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get autoencoder model\n",
    "def get_ae(train_data, LeReLU_alpha=0.01):\n",
    "    \n",
    "    #Input layer\n",
    "    input_layer = Input(shape=(train_data.shape[1]), name='ae_input')\n",
    "    \n",
    "    encoder = Dense(336, activation=LeakyReLU(alpha=LeReLU_alpha), name='e1')(input_layer)\n",
    "    encoder = Dense(208, activation=LeakyReLU(alpha=LeReLU_alpha), name='e2')(encoder)\n",
    "    encoder = Dense(240, activation=LeakyReLU(alpha=LeReLU_alpha), name='e3')(encoder)\n",
    "\n",
    "    encoded = Dense(2, activation=LeakyReLU(alpha=LeReLU_alpha), name='ae_latent')(encoder)\n",
    "    \n",
    "    decoder = Dense(240, activation=LeakyReLU(alpha=LeReLU_alpha), name='d1')(encoded)\n",
    "    decoder = Dense(208, activation=LeakyReLU(alpha=LeReLU_alpha), name='d2')(decoder)\n",
    "    decoder = Dense(336, activation=LeakyReLU(alpha=LeReLU_alpha), name='d3')(decoder)\n",
    "\n",
    "    output_layer = Dense(train_data.shape[1], activation=LeakyReLU(alpha=LeReLU_alpha), name='ae_output')(decoder)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f15476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 12:45:07.188508: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Get ae for filtered data\n",
    "autoencoder = get_ae(X_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0364035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 12)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 336)               4368      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 208)               70096     \n",
      "                                                                 \n",
      " e3 (Dense)                  (None, 240)               50160     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 482       \n",
      "                                                                 \n",
      " d1 (Dense)                  (None, 240)               720       \n",
      "                                                                 \n",
      " d2 (Dense)                  (None, 208)               50128     \n",
      "                                                                 \n",
      " d3 (Dense)                  (None, 336)               70224     \n",
      "                                                                 \n",
      " ae_output (Dense)           (None, 12)                4044      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 250222 (977.43 KB)\n",
      "Trainable params: 250222 (977.43 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print summary of ae model\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a20e45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "autoencoder.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(learning_rate = 0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe077b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "250/250 [==============================] - 3s 8ms/step - loss: 0.0176 - val_loss: 0.0099\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 8.7810e-04\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 8.1928e-04 - val_loss: 7.8510e-04\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.6793e-04 - val_loss: 7.5238e-04\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.3893e-04 - val_loss: 7.2661e-04\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.1566e-04 - val_loss: 7.0472e-04\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.9591e-04 - val_loss: 6.8719e-04\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.8092e-04 - val_loss: 6.7468e-04\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.7077e-04 - val_loss: 6.6689e-04\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.6412e-04 - val_loss: 6.6064e-04\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.5926e-04 - val_loss: 6.5650e-04\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.5558e-04 - val_loss: 6.5308e-04\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.5236e-04 - val_loss: 6.5003e-04\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.4927e-04 - val_loss: 6.4686e-04\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.4630e-04 - val_loss: 6.4413e-04\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.4332e-04 - val_loss: 6.4102e-04\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.4039e-04 - val_loss: 6.3828e-04\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.3720e-04 - val_loss: 6.3451e-04\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.3409e-04 - val_loss: 6.3158e-04\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.3104e-04 - val_loss: 6.2880e-04\n",
      "Epoch 26/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2829e-04 - val_loss: 6.2614e-04\n",
      "Epoch 27/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2532e-04 - val_loss: 6.2310e-04\n",
      "Epoch 28/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2268e-04 - val_loss: 6.2056e-04\n",
      "Epoch 29/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.2014e-04 - val_loss: 6.1777e-04\n",
      "Epoch 30/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.1736e-04 - val_loss: 6.1635e-04\n",
      "Epoch 31/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.1499e-04 - val_loss: 6.1295e-04\n",
      "Epoch 32/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.1226e-04 - val_loss: 6.1023e-04\n",
      "Epoch 33/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0860e-04 - val_loss: 6.0650e-04\n",
      "Epoch 34/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0499e-04 - val_loss: 6.0371e-04\n",
      "Epoch 35/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0118e-04 - val_loss: 6.0004e-04\n",
      "Epoch 36/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9721e-04 - val_loss: 5.9474e-04\n",
      "Epoch 37/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.9246e-04 - val_loss: 5.9032e-04\n",
      "Epoch 38/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8752e-04 - val_loss: 5.8530e-04\n",
      "Epoch 39/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.8258e-04 - val_loss: 5.8097e-04\n",
      "Epoch 40/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7742e-04 - val_loss: 5.7702e-04\n",
      "Epoch 41/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.7288e-04 - val_loss: 5.7175e-04\n",
      "Epoch 42/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6891e-04 - val_loss: 5.6862e-04\n",
      "Epoch 43/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6554e-04 - val_loss: 5.6504e-04\n",
      "Epoch 44/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6270e-04 - val_loss: 5.6259e-04\n",
      "Epoch 45/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6020e-04 - val_loss: 5.6001e-04\n",
      "Epoch 46/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5788e-04 - val_loss: 5.5779e-04\n",
      "Epoch 47/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5579e-04 - val_loss: 5.5578e-04\n",
      "Epoch 48/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5379e-04 - val_loss: 5.5361e-04\n",
      "Epoch 49/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5209e-04 - val_loss: 5.5198e-04\n",
      "Epoch 50/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5040e-04 - val_loss: 5.5065e-04\n",
      "Epoch 51/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4903e-04 - val_loss: 5.4888e-04\n",
      "Epoch 52/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4755e-04 - val_loss: 5.4741e-04\n",
      "Epoch 53/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4611e-04 - val_loss: 5.4600e-04\n",
      "Epoch 54/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.4473e-04 - val_loss: 5.4435e-04\n",
      "Epoch 55/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4359e-04 - val_loss: 5.4329e-04\n",
      "Epoch 56/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4214e-04 - val_loss: 5.4195e-04\n",
      "Epoch 57/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4095e-04 - val_loss: 5.4047e-04\n",
      "Epoch 58/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3963e-04 - val_loss: 5.3916e-04\n",
      "Epoch 59/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3829e-04 - val_loss: 5.3798e-04\n",
      "Epoch 60/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3715e-04 - val_loss: 5.3675e-04\n",
      "Epoch 61/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3592e-04 - val_loss: 5.3544e-04\n",
      "Epoch 62/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3476e-04 - val_loss: 5.3391e-04\n",
      "Epoch 63/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3347e-04 - val_loss: 5.3256e-04\n",
      "Epoch 64/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3250e-04 - val_loss: 5.3200e-04\n",
      "Epoch 65/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3122e-04 - val_loss: 5.3069e-04\n",
      "Epoch 66/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.3003e-04 - val_loss: 5.2913e-04\n",
      "Epoch 67/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2890e-04 - val_loss: 5.2798e-04\n",
      "Epoch 68/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2809e-04 - val_loss: 5.2679e-04\n",
      "Epoch 69/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2675e-04 - val_loss: 5.2577e-04\n",
      "Epoch 70/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2567e-04 - val_loss: 5.2564e-04\n",
      "Epoch 71/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2444e-04 - val_loss: 5.2356e-04\n",
      "Epoch 72/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2342e-04 - val_loss: 5.2273e-04\n",
      "Epoch 73/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2240e-04 - val_loss: 5.2137e-04\n",
      "Epoch 74/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2136e-04 - val_loss: 5.2091e-04\n",
      "Epoch 75/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2034e-04 - val_loss: 5.1896e-04\n",
      "Epoch 76/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1923e-04 - val_loss: 5.1822e-04\n",
      "Epoch 77/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1808e-04 - val_loss: 5.1708e-04\n",
      "Epoch 78/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1712e-04 - val_loss: 5.1585e-04\n",
      "Epoch 79/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1608e-04 - val_loss: 5.1517e-04\n",
      "Epoch 80/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1500e-04 - val_loss: 5.1406e-04\n",
      "Epoch 81/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1400e-04 - val_loss: 5.1346e-04\n",
      "Epoch 82/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1310e-04 - val_loss: 5.1223e-04\n",
      "Epoch 83/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1218e-04 - val_loss: 5.1108e-04\n",
      "Epoch 84/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1112e-04 - val_loss: 5.0996e-04\n",
      "Epoch 85/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1012e-04 - val_loss: 5.0914e-04\n",
      "Epoch 86/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0905e-04 - val_loss: 5.0860e-04\n",
      "Epoch 87/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0825e-04 - val_loss: 5.0708e-04\n",
      "Epoch 88/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0718e-04 - val_loss: 5.0604e-04\n",
      "Epoch 89/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0623e-04 - val_loss: 5.0488e-04\n",
      "Epoch 90/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0524e-04 - val_loss: 5.0408e-04\n",
      "Epoch 91/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0431e-04 - val_loss: 5.0330e-04\n",
      "Epoch 92/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0334e-04 - val_loss: 5.0216e-04\n",
      "Epoch 93/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0247e-04 - val_loss: 5.0096e-04\n",
      "Epoch 94/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0145e-04 - val_loss: 5.0021e-04\n",
      "Epoch 95/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0051e-04 - val_loss: 4.9917e-04\n",
      "Epoch 96/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9959e-04 - val_loss: 4.9879e-04\n",
      "Epoch 97/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9884e-04 - val_loss: 4.9795e-04\n",
      "Epoch 98/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9773e-04 - val_loss: 4.9687e-04\n",
      "Epoch 99/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9683e-04 - val_loss: 4.9536e-04\n",
      "Epoch 100/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9581e-04 - val_loss: 4.9427e-04\n",
      "Epoch 101/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9474e-04 - val_loss: 4.9343e-04\n",
      "Epoch 102/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9378e-04 - val_loss: 4.9299e-04\n",
      "Epoch 103/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9283e-04 - val_loss: 4.9144e-04\n",
      "Epoch 104/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9177e-04 - val_loss: 4.9085e-04\n",
      "Epoch 105/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9075e-04 - val_loss: 4.8939e-04\n",
      "Epoch 106/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8981e-04 - val_loss: 4.8852e-04\n",
      "Epoch 107/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8882e-04 - val_loss: 4.8755e-04\n",
      "Epoch 108/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8782e-04 - val_loss: 4.8726e-04\n",
      "Epoch 109/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8684e-04 - val_loss: 4.8586e-04\n",
      "Epoch 110/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8580e-04 - val_loss: 4.8467e-04\n",
      "Epoch 111/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8487e-04 - val_loss: 4.8388e-04\n",
      "Epoch 112/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8386e-04 - val_loss: 4.8298e-04\n",
      "Epoch 113/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8296e-04 - val_loss: 4.8211e-04\n",
      "Epoch 114/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8203e-04 - val_loss: 4.8126e-04\n",
      "Epoch 115/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8096e-04 - val_loss: 4.8015e-04\n",
      "Epoch 116/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8016e-04 - val_loss: 4.7885e-04\n",
      "Epoch 117/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7921e-04 - val_loss: 4.7848e-04\n",
      "Epoch 118/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7843e-04 - val_loss: 4.7799e-04\n",
      "Epoch 119/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7747e-04 - val_loss: 4.7694e-04\n",
      "Epoch 120/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7671e-04 - val_loss: 4.7599e-04\n",
      "Epoch 121/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7578e-04 - val_loss: 4.7500e-04\n",
      "Epoch 122/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7499e-04 - val_loss: 4.7515e-04\n",
      "Epoch 123/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7417e-04 - val_loss: 4.7360e-04\n",
      "Epoch 124/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7332e-04 - val_loss: 4.7312e-04\n",
      "Epoch 125/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7253e-04 - val_loss: 4.7299e-04\n",
      "Epoch 126/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7164e-04 - val_loss: 4.7098e-04\n",
      "Epoch 127/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7088e-04 - val_loss: 4.7057e-04\n",
      "Epoch 128/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7023e-04 - val_loss: 4.7018e-04\n",
      "Epoch 129/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6931e-04 - val_loss: 4.6890e-04\n",
      "Epoch 130/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6855e-04 - val_loss: 4.6824e-04\n",
      "Epoch 131/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6795e-04 - val_loss: 4.6800e-04\n",
      "Epoch 132/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6725e-04 - val_loss: 4.6731e-04\n",
      "Epoch 133/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6666e-04 - val_loss: 4.6648e-04\n",
      "Epoch 134/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6593e-04 - val_loss: 4.6665e-04\n",
      "Epoch 135/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6538e-04 - val_loss: 4.6499e-04\n",
      "Epoch 136/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6460e-04 - val_loss: 4.6496e-04\n",
      "Epoch 137/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6394e-04 - val_loss: 4.6429e-04\n",
      "Epoch 138/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6335e-04 - val_loss: 4.6332e-04\n",
      "Epoch 139/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6271e-04 - val_loss: 4.6330e-04\n",
      "Epoch 140/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6212e-04 - val_loss: 4.6322e-04\n",
      "Epoch 141/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6153e-04 - val_loss: 4.6261e-04\n",
      "Epoch 142/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6109e-04 - val_loss: 4.6143e-04\n",
      "Epoch 143/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6052e-04 - val_loss: 4.6134e-04\n",
      "Epoch 144/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5991e-04 - val_loss: 4.6052e-04\n",
      "Epoch 145/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5938e-04 - val_loss: 4.5999e-04\n",
      "Epoch 146/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5879e-04 - val_loss: 4.5922e-04\n",
      "Epoch 147/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5827e-04 - val_loss: 4.5874e-04\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5774e-04 - val_loss: 4.5865e-04\n",
      "Epoch 149/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5729e-04 - val_loss: 4.5786e-04\n",
      "Epoch 150/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5677e-04 - val_loss: 4.5760e-04\n",
      "Epoch 151/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5632e-04 - val_loss: 4.5713e-04\n",
      "Epoch 152/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5563e-04 - val_loss: 4.5646e-04\n",
      "Epoch 153/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5534e-04 - val_loss: 4.5609e-04\n",
      "Epoch 154/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5486e-04 - val_loss: 4.5590e-04\n",
      "Epoch 155/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5424e-04 - val_loss: 4.5492e-04\n",
      "Epoch 156/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5393e-04 - val_loss: 4.5497e-04\n",
      "Epoch 157/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5334e-04 - val_loss: 4.5467e-04\n",
      "Epoch 158/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5296e-04 - val_loss: 4.5428e-04\n",
      "Epoch 159/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5259e-04 - val_loss: 4.5327e-04\n",
      "Epoch 160/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5205e-04 - val_loss: 4.5358e-04\n",
      "Epoch 161/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5168e-04 - val_loss: 4.5233e-04\n",
      "Epoch 162/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5134e-04 - val_loss: 4.5229e-04\n",
      "Epoch 163/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5075e-04 - val_loss: 4.5167e-04\n",
      "Epoch 164/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5036e-04 - val_loss: 4.5120e-04\n",
      "Epoch 165/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4980e-04 - val_loss: 4.5065e-04\n",
      "Epoch 166/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4950e-04 - val_loss: 4.5071e-04\n",
      "Epoch 167/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4915e-04 - val_loss: 4.5011e-04\n",
      "Epoch 168/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4865e-04 - val_loss: 4.5035e-04\n",
      "Epoch 169/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4841e-04 - val_loss: 4.4919e-04\n",
      "Epoch 170/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4787e-04 - val_loss: 4.4886e-04\n",
      "Epoch 171/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4747e-04 - val_loss: 4.4850e-04\n",
      "Epoch 172/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4720e-04 - val_loss: 4.4821e-04\n",
      "Epoch 173/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4686e-04 - val_loss: 4.4790e-04\n",
      "Epoch 174/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4622e-04 - val_loss: 4.4774e-04\n",
      "Epoch 175/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4595e-04 - val_loss: 4.4688e-04\n",
      "Epoch 176/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4576e-04 - val_loss: 4.4663e-04\n",
      "Epoch 177/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4528e-04 - val_loss: 4.4705e-04\n",
      "Epoch 178/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4478e-04 - val_loss: 4.4562e-04\n",
      "Epoch 179/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4452e-04 - val_loss: 4.4561e-04\n",
      "Epoch 180/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4419e-04 - val_loss: 4.4571e-04\n",
      "Epoch 181/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4384e-04 - val_loss: 4.4465e-04\n",
      "Epoch 182/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4339e-04 - val_loss: 4.4450e-04\n",
      "Epoch 183/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4324e-04 - val_loss: 4.4382e-04\n",
      "Epoch 184/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4301e-04 - val_loss: 4.4344e-04\n",
      "Epoch 185/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4244e-04 - val_loss: 4.4363e-04\n",
      "Epoch 186/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4220e-04 - val_loss: 4.4280e-04\n",
      "Epoch 187/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4172e-04 - val_loss: 4.4262e-04\n",
      "Epoch 188/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4156e-04 - val_loss: 4.4313e-04\n",
      "Epoch 189/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4120e-04 - val_loss: 4.4271e-04\n",
      "Epoch 190/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4083e-04 - val_loss: 4.4208e-04\n",
      "Epoch 191/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4070e-04 - val_loss: 4.4153e-04\n",
      "Epoch 192/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4.4022e-04 - val_loss: 4.4069e-04\n",
      "Epoch 193/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3993e-04 - val_loss: 4.4096e-04\n",
      "Epoch 194/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3974e-04 - val_loss: 4.4027e-04\n",
      "Epoch 195/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3933e-04 - val_loss: 4.4074e-04\n",
      "Epoch 196/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3913e-04 - val_loss: 4.3970e-04\n",
      "Epoch 197/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3873e-04 - val_loss: 4.3942e-04\n",
      "Epoch 198/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3842e-04 - val_loss: 4.3992e-04\n",
      "Epoch 199/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3827e-04 - val_loss: 4.3872e-04\n",
      "Epoch 200/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3782e-04 - val_loss: 4.3857e-04\n",
      "Epoch 201/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3772e-04 - val_loss: 4.3809e-04\n",
      "Epoch 202/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3727e-04 - val_loss: 4.3787e-04\n",
      "Epoch 203/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3709e-04 - val_loss: 4.3772e-04\n",
      "Epoch 204/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3662e-04 - val_loss: 4.3708e-04\n",
      "Epoch 205/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3666e-04 - val_loss: 4.3764e-04\n",
      "Epoch 206/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3610e-04 - val_loss: 4.3683e-04\n",
      "Epoch 207/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3581e-04 - val_loss: 4.3667e-04\n",
      "Epoch 208/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3566e-04 - val_loss: 4.3688e-04\n",
      "Epoch 209/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3539e-04 - val_loss: 4.3589e-04\n",
      "Epoch 210/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3507e-04 - val_loss: 4.3573e-04\n",
      "Epoch 211/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3472e-04 - val_loss: 4.3545e-04\n",
      "Epoch 212/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3449e-04 - val_loss: 4.3454e-04\n",
      "Epoch 213/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3417e-04 - val_loss: 4.3502e-04\n",
      "Epoch 214/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3408e-04 - val_loss: 4.3471e-04\n",
      "Epoch 215/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3353e-04 - val_loss: 4.3418e-04\n",
      "Epoch 216/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3347e-04 - val_loss: 4.3384e-04\n",
      "Epoch 217/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3309e-04 - val_loss: 4.3384e-04\n",
      "Epoch 218/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3288e-04 - val_loss: 4.3281e-04\n",
      "Epoch 219/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3271e-04 - val_loss: 4.3353e-04\n",
      "Epoch 220/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3240e-04 - val_loss: 4.3300e-04\n",
      "Epoch 221/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3217e-04 - val_loss: 4.3226e-04\n",
      "Epoch 222/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3186e-04 - val_loss: 4.3240e-04\n",
      "Epoch 223/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3158e-04 - val_loss: 4.3206e-04\n",
      "Epoch 224/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3143e-04 - val_loss: 4.3144e-04\n",
      "Epoch 225/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3110e-04 - val_loss: 4.3286e-04\n",
      "Epoch 226/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3095e-04 - val_loss: 4.3155e-04\n",
      "Epoch 227/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3080e-04 - val_loss: 4.3135e-04\n",
      "Epoch 228/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3041e-04 - val_loss: 4.3089e-04\n",
      "Epoch 229/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3020e-04 - val_loss: 4.3028e-04\n",
      "Epoch 230/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2994e-04 - val_loss: 4.3022e-04\n",
      "Epoch 231/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2977e-04 - val_loss: 4.3012e-04\n",
      "Epoch 232/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2949e-04 - val_loss: 4.2974e-04\n",
      "Epoch 233/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2919e-04 - val_loss: 4.2899e-04\n",
      "Epoch 234/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2910e-04 - val_loss: 4.2890e-04\n",
      "Epoch 235/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2891e-04 - val_loss: 4.2908e-04\n",
      "Epoch 236/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2850e-04 - val_loss: 4.2882e-04\n",
      "Epoch 237/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4.2826e-04 - val_loss: 4.2904e-04\n",
      "Epoch 238/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2804e-04 - val_loss: 4.2874e-04\n",
      "Epoch 239/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2776e-04 - val_loss: 4.2775e-04\n",
      "Epoch 240/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2777e-04 - val_loss: 4.2805e-04\n",
      "Epoch 241/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2749e-04 - val_loss: 4.2840e-04\n",
      "Epoch 242/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2715e-04 - val_loss: 4.2759e-04\n",
      "Epoch 243/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2703e-04 - val_loss: 4.2724e-04\n",
      "Epoch 244/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2685e-04 - val_loss: 4.2742e-04\n",
      "Epoch 245/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2652e-04 - val_loss: 4.2711e-04\n",
      "Epoch 246/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2648e-04 - val_loss: 4.2676e-04\n",
      "Epoch 247/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2611e-04 - val_loss: 4.2659e-04\n",
      "Epoch 248/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2601e-04 - val_loss: 4.2666e-04\n",
      "Epoch 249/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2562e-04 - val_loss: 4.2555e-04\n",
      "Epoch 250/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2537e-04 - val_loss: 4.2645e-04\n",
      "Epoch 251/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2533e-04 - val_loss: 4.2529e-04\n",
      "Epoch 252/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2520e-04 - val_loss: 4.2582e-04\n",
      "Epoch 253/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2501e-04 - val_loss: 4.2525e-04\n",
      "Epoch 254/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2480e-04 - val_loss: 4.2514e-04\n",
      "Epoch 255/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2439e-04 - val_loss: 4.2481e-04\n",
      "Epoch 256/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2434e-04 - val_loss: 4.2495e-04\n",
      "Epoch 257/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2411e-04 - val_loss: 4.2381e-04\n",
      "Epoch 258/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2383e-04 - val_loss: 4.2497e-04\n",
      "Epoch 259/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2374e-04 - val_loss: 4.2383e-04\n",
      "Epoch 260/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2357e-04 - val_loss: 4.2345e-04\n",
      "Epoch 261/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2331e-04 - val_loss: 4.2358e-04\n",
      "Epoch 262/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2312e-04 - val_loss: 4.2316e-04\n",
      "Epoch 263/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2281e-04 - val_loss: 4.2375e-04\n",
      "Epoch 264/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2268e-04 - val_loss: 4.2242e-04\n",
      "Epoch 265/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2270e-04 - val_loss: 4.2264e-04\n",
      "Epoch 266/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2233e-04 - val_loss: 4.2225e-04\n",
      "Epoch 267/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2215e-04 - val_loss: 4.2286e-04\n",
      "Epoch 268/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2184e-04 - val_loss: 4.2204e-04\n",
      "Epoch 269/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2171e-04 - val_loss: 4.2157e-04\n",
      "Epoch 270/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2164e-04 - val_loss: 4.2188e-04\n",
      "Epoch 271/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2137e-04 - val_loss: 4.2152e-04\n",
      "Epoch 272/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2114e-04 - val_loss: 4.2087e-04\n",
      "Epoch 273/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2112e-04 - val_loss: 4.2110e-04\n",
      "Epoch 274/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2075e-04 - val_loss: 4.2128e-04\n",
      "Epoch 275/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2075e-04 - val_loss: 4.2043e-04\n",
      "Epoch 276/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2045e-04 - val_loss: 4.2061e-04\n",
      "Epoch 277/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2053e-04 - val_loss: 4.2035e-04\n",
      "Epoch 278/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1992e-04 - val_loss: 4.1960e-04\n",
      "Epoch 279/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1986e-04 - val_loss: 4.1942e-04\n",
      "Epoch 280/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1965e-04 - val_loss: 4.1984e-04\n",
      "Epoch 281/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1938e-04 - val_loss: 4.1970e-04\n",
      "Epoch 282/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1916e-04 - val_loss: 4.1923e-04\n",
      "Epoch 283/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1925e-04 - val_loss: 4.1881e-04\n",
      "Epoch 284/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1896e-04 - val_loss: 4.1918e-04\n",
      "Epoch 285/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1887e-04 - val_loss: 4.1888e-04\n",
      "Epoch 286/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1890e-04 - val_loss: 4.1984e-04\n",
      "Epoch 287/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1844e-04 - val_loss: 4.1845e-04\n",
      "Epoch 288/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1825e-04 - val_loss: 4.1781e-04\n",
      "Epoch 289/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1803e-04 - val_loss: 4.1772e-04\n",
      "Epoch 290/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1775e-04 - val_loss: 4.1806e-04\n",
      "Epoch 291/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1764e-04 - val_loss: 4.1738e-04\n",
      "Epoch 292/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1749e-04 - val_loss: 4.1758e-04\n",
      "Epoch 293/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1733e-04 - val_loss: 4.1736e-04\n",
      "Epoch 294/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1710e-04 - val_loss: 4.1717e-04\n",
      "Epoch 295/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1697e-04 - val_loss: 4.1670e-04\n",
      "Epoch 296/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1672e-04 - val_loss: 4.1705e-04\n",
      "Epoch 297/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1640e-04 - val_loss: 4.1747e-04\n",
      "Epoch 298/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1622e-04 - val_loss: 4.1659e-04\n",
      "Epoch 299/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1634e-04 - val_loss: 4.1604e-04\n",
      "Epoch 300/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1616e-04 - val_loss: 4.1587e-04\n",
      "Epoch 301/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1575e-04 - val_loss: 4.1557e-04\n",
      "Epoch 302/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1574e-04 - val_loss: 4.1541e-04\n",
      "Epoch 303/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1530e-04 - val_loss: 4.1523e-04\n",
      "Epoch 304/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1535e-04 - val_loss: 4.1554e-04\n",
      "Epoch 305/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1504e-04 - val_loss: 4.1484e-04\n",
      "Epoch 306/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1484e-04 - val_loss: 4.1538e-04\n",
      "Epoch 307/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1488e-04 - val_loss: 4.1459e-04\n",
      "Epoch 308/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1459e-04 - val_loss: 4.1439e-04\n",
      "Epoch 309/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1434e-04 - val_loss: 4.1517e-04\n",
      "Epoch 310/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1432e-04 - val_loss: 4.1440e-04\n",
      "Epoch 311/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1395e-04 - val_loss: 4.1416e-04\n",
      "Epoch 312/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1379e-04 - val_loss: 4.1382e-04\n",
      "Epoch 313/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1365e-04 - val_loss: 4.1461e-04\n",
      "Epoch 314/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1341e-04 - val_loss: 4.1329e-04\n",
      "Epoch 315/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1341e-04 - val_loss: 4.1432e-04\n",
      "Epoch 316/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1313e-04 - val_loss: 4.1305e-04\n",
      "Epoch 317/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1300e-04 - val_loss: 4.1272e-04\n",
      "Epoch 318/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1296e-04 - val_loss: 4.1298e-04\n",
      "Epoch 319/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1250e-04 - val_loss: 4.1311e-04\n",
      "Epoch 320/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1243e-04 - val_loss: 4.1247e-04\n",
      "Epoch 321/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1222e-04 - val_loss: 4.1290e-04\n",
      "Epoch 322/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1214e-04 - val_loss: 4.1241e-04\n",
      "Epoch 323/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1183e-04 - val_loss: 4.1203e-04\n",
      "Epoch 324/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1176e-04 - val_loss: 4.1215e-04\n",
      "Epoch 325/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1161e-04 - val_loss: 4.1177e-04\n",
      "Epoch 326/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1131e-04 - val_loss: 4.1148e-04\n",
      "Epoch 327/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1132e-04 - val_loss: 4.1182e-04\n",
      "Epoch 328/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1096e-04 - val_loss: 4.1096e-04\n",
      "Epoch 329/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1098e-04 - val_loss: 4.1136e-04\n",
      "Epoch 330/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1099e-04 - val_loss: 4.1088e-04\n",
      "Epoch 331/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1054e-04 - val_loss: 4.1104e-04\n",
      "Epoch 332/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1029e-04 - val_loss: 4.1070e-04\n",
      "Epoch 333/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1029e-04 - val_loss: 4.1086e-04\n",
      "Epoch 334/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0999e-04 - val_loss: 4.1035e-04\n",
      "Epoch 335/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0982e-04 - val_loss: 4.1023e-04\n",
      "Epoch 336/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0966e-04 - val_loss: 4.0996e-04\n",
      "Epoch 337/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0954e-04 - val_loss: 4.0940e-04\n",
      "Epoch 338/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0933e-04 - val_loss: 4.0937e-04\n",
      "Epoch 339/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0927e-04 - val_loss: 4.0935e-04\n",
      "Epoch 340/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0915e-04 - val_loss: 4.0941e-04\n",
      "Epoch 341/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0885e-04 - val_loss: 4.0874e-04\n",
      "Epoch 342/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0884e-04 - val_loss: 4.0952e-04\n",
      "Epoch 343/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0854e-04 - val_loss: 4.0961e-04\n",
      "Epoch 344/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0836e-04 - val_loss: 4.0857e-04\n",
      "Epoch 345/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0820e-04 - val_loss: 4.0791e-04\n",
      "Epoch 346/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0801e-04 - val_loss: 4.0793e-04\n",
      "Epoch 347/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0787e-04 - val_loss: 4.0915e-04\n",
      "Epoch 348/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0773e-04 - val_loss: 4.0745e-04\n",
      "Epoch 349/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0744e-04 - val_loss: 4.0799e-04\n",
      "Epoch 350/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0731e-04 - val_loss: 4.0721e-04\n",
      "Epoch 351/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0710e-04 - val_loss: 4.0844e-04\n",
      "Epoch 352/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0694e-04 - val_loss: 4.0785e-04\n",
      "Epoch 353/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0676e-04 - val_loss: 4.0726e-04\n",
      "Epoch 354/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0667e-04 - val_loss: 4.0690e-04\n",
      "Epoch 355/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0656e-04 - val_loss: 4.0671e-04\n",
      "Epoch 356/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0640e-04 - val_loss: 4.0728e-04\n",
      "Epoch 357/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0615e-04 - val_loss: 4.0671e-04\n",
      "Epoch 358/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0595e-04 - val_loss: 4.0629e-04\n",
      "Epoch 359/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0598e-04 - val_loss: 4.0599e-04\n",
      "Epoch 360/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0578e-04 - val_loss: 4.0570e-04\n",
      "Epoch 361/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0552e-04 - val_loss: 4.0562e-04\n",
      "Epoch 362/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0530e-04 - val_loss: 4.0567e-04\n",
      "Epoch 363/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0526e-04 - val_loss: 4.0603e-04\n",
      "Epoch 364/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0485e-04 - val_loss: 4.0505e-04\n",
      "Epoch 365/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0491e-04 - val_loss: 4.0560e-04\n",
      "Epoch 366/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0472e-04 - val_loss: 4.0515e-04\n",
      "Epoch 367/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0472e-04 - val_loss: 4.0533e-04\n",
      "Epoch 368/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0451e-04 - val_loss: 4.0497e-04\n",
      "Epoch 369/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0425e-04 - val_loss: 4.0456e-04\n",
      "Epoch 370/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0409e-04 - val_loss: 4.0430e-04\n",
      "Epoch 371/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0408e-04 - val_loss: 4.0428e-04\n",
      "Epoch 372/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0380e-04 - val_loss: 4.0409e-04\n",
      "Epoch 373/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0366e-04 - val_loss: 4.0428e-04\n",
      "Epoch 374/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0353e-04 - val_loss: 4.0407e-04\n",
      "Epoch 375/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0335e-04 - val_loss: 4.0379e-04\n",
      "Epoch 376/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0322e-04 - val_loss: 4.0335e-04\n",
      "Epoch 377/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0294e-04 - val_loss: 4.0362e-04\n",
      "Epoch 378/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0280e-04 - val_loss: 4.0331e-04\n",
      "Epoch 379/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0270e-04 - val_loss: 4.0345e-04\n",
      "Epoch 380/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0258e-04 - val_loss: 4.0330e-04\n",
      "Epoch 381/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0243e-04 - val_loss: 4.0294e-04\n",
      "Epoch 382/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0217e-04 - val_loss: 4.0313e-04\n",
      "Epoch 383/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0222e-04 - val_loss: 4.0298e-04\n",
      "Epoch 384/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0211e-04 - val_loss: 4.0362e-04\n",
      "Epoch 385/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0196e-04 - val_loss: 4.0280e-04\n",
      "Epoch 386/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0174e-04 - val_loss: 4.0245e-04\n",
      "Epoch 387/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0150e-04 - val_loss: 4.0354e-04\n",
      "Epoch 388/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0163e-04 - val_loss: 4.0284e-04\n",
      "Epoch 389/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0123e-04 - val_loss: 4.0193e-04\n",
      "Epoch 390/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0117e-04 - val_loss: 4.0227e-04\n",
      "Epoch 391/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0085e-04 - val_loss: 4.0221e-04\n",
      "Epoch 392/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0104e-04 - val_loss: 4.0178e-04\n",
      "Epoch 393/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0076e-04 - val_loss: 4.0258e-04\n",
      "Epoch 394/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0063e-04 - val_loss: 4.0147e-04\n",
      "Epoch 395/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0048e-04 - val_loss: 4.0139e-04\n",
      "Epoch 396/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0030e-04 - val_loss: 4.0099e-04\n",
      "Epoch 397/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0013e-04 - val_loss: 4.0082e-04\n",
      "Epoch 398/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0008e-04 - val_loss: 4.0128e-04\n",
      "Epoch 399/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9998e-04 - val_loss: 4.0106e-04\n",
      "Epoch 400/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9970e-04 - val_loss: 4.0075e-04\n",
      "Epoch 401/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9978e-04 - val_loss: 4.0207e-04\n",
      "Epoch 402/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9947e-04 - val_loss: 4.0138e-04\n",
      "Epoch 403/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9936e-04 - val_loss: 4.0144e-04\n",
      "Epoch 404/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9933e-04 - val_loss: 4.0088e-04\n",
      "Epoch 405/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9915e-04 - val_loss: 3.9986e-04\n",
      "Epoch 406/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9918e-04 - val_loss: 3.9972e-04\n",
      "Epoch 407/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9873e-04 - val_loss: 3.9970e-04\n",
      "Epoch 408/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9875e-04 - val_loss: 4.0096e-04\n",
      "Epoch 409/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9862e-04 - val_loss: 3.9955e-04\n",
      "Epoch 410/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9838e-04 - val_loss: 3.9928e-04\n",
      "Epoch 411/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9839e-04 - val_loss: 3.9927e-04\n",
      "Epoch 412/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9825e-04 - val_loss: 4.0005e-04\n",
      "Epoch 413/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9831e-04 - val_loss: 3.9940e-04\n",
      "Epoch 414/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9802e-04 - val_loss: 3.9909e-04\n",
      "Epoch 415/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9777e-04 - val_loss: 3.9989e-04\n",
      "Epoch 416/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9785e-04 - val_loss: 3.9951e-04\n",
      "Epoch 417/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9751e-04 - val_loss: 3.9911e-04\n",
      "Epoch 418/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9773e-04 - val_loss: 3.9876e-04\n",
      "Epoch 419/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9748e-04 - val_loss: 3.9873e-04\n",
      "Epoch 420/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9727e-04 - val_loss: 3.9835e-04\n",
      "Epoch 421/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9716e-04 - val_loss: 3.9859e-04\n",
      "Epoch 422/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9704e-04 - val_loss: 3.9820e-04\n",
      "Epoch 423/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9672e-04 - val_loss: 3.9914e-04\n",
      "Epoch 424/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9657e-04 - val_loss: 3.9808e-04\n",
      "Epoch 425/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9644e-04 - val_loss: 3.9753e-04\n",
      "Epoch 426/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9647e-04 - val_loss: 3.9772e-04\n",
      "Epoch 427/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9655e-04 - val_loss: 3.9806e-04\n",
      "Epoch 428/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9617e-04 - val_loss: 3.9785e-04\n",
      "Epoch 429/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9621e-04 - val_loss: 3.9746e-04\n",
      "Epoch 430/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9610e-04 - val_loss: 3.9767e-04\n",
      "Epoch 431/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9594e-04 - val_loss: 3.9746e-04\n",
      "Epoch 432/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9576e-04 - val_loss: 3.9729e-04\n",
      "Epoch 433/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9558e-04 - val_loss: 3.9822e-04\n",
      "Epoch 434/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9586e-04 - val_loss: 3.9665e-04\n",
      "Epoch 435/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9552e-04 - val_loss: 3.9696e-04\n",
      "Epoch 436/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9534e-04 - val_loss: 3.9664e-04\n",
      "Epoch 437/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9523e-04 - val_loss: 3.9746e-04\n",
      "Epoch 438/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9511e-04 - val_loss: 3.9625e-04\n",
      "Epoch 439/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9520e-04 - val_loss: 3.9669e-04\n",
      "Epoch 440/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9480e-04 - val_loss: 3.9634e-04\n",
      "Epoch 441/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9459e-04 - val_loss: 3.9638e-04\n",
      "Epoch 442/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9472e-04 - val_loss: 3.9580e-04\n",
      "Epoch 443/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9447e-04 - val_loss: 3.9641e-04\n",
      "Epoch 444/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9435e-04 - val_loss: 3.9707e-04\n",
      "Epoch 445/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9455e-04 - val_loss: 3.9588e-04\n",
      "Epoch 446/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9407e-04 - val_loss: 3.9570e-04\n",
      "Epoch 447/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9412e-04 - val_loss: 3.9574e-04\n",
      "Epoch 448/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9395e-04 - val_loss: 3.9544e-04\n",
      "Epoch 449/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9387e-04 - val_loss: 3.9644e-04\n",
      "Epoch 450/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9384e-04 - val_loss: 3.9556e-04\n",
      "Epoch 451/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9371e-04 - val_loss: 3.9486e-04\n",
      "Epoch 452/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9362e-04 - val_loss: 3.9628e-04\n",
      "Epoch 453/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9353e-04 - val_loss: 3.9495e-04\n",
      "Epoch 454/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9351e-04 - val_loss: 3.9560e-04\n",
      "Epoch 455/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9321e-04 - val_loss: 3.9448e-04\n",
      "Epoch 456/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9307e-04 - val_loss: 3.9470e-04\n",
      "Epoch 457/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9300e-04 - val_loss: 3.9460e-04\n",
      "Epoch 458/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9286e-04 - val_loss: 3.9445e-04\n",
      "Epoch 459/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9276e-04 - val_loss: 3.9421e-04\n",
      "Epoch 460/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9250e-04 - val_loss: 3.9459e-04\n",
      "Epoch 461/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9238e-04 - val_loss: 3.9444e-04\n",
      "Epoch 462/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9271e-04 - val_loss: 3.9435e-04\n",
      "Epoch 463/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9214e-04 - val_loss: 3.9480e-04\n",
      "Epoch 464/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9224e-04 - val_loss: 3.9444e-04\n",
      "Epoch 465/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9199e-04 - val_loss: 3.9353e-04\n",
      "Epoch 466/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9196e-04 - val_loss: 3.9351e-04\n",
      "Epoch 467/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9183e-04 - val_loss: 3.9377e-04\n",
      "Epoch 468/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9178e-04 - val_loss: 3.9321e-04\n",
      "Epoch 469/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9169e-04 - val_loss: 3.9351e-04\n",
      "Epoch 470/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9152e-04 - val_loss: 3.9363e-04\n",
      "Epoch 471/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9152e-04 - val_loss: 3.9372e-04\n",
      "Epoch 472/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9123e-04 - val_loss: 3.9284e-04\n",
      "Epoch 473/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9132e-04 - val_loss: 3.9269e-04\n",
      "Epoch 474/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9121e-04 - val_loss: 3.9267e-04\n",
      "Epoch 475/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9099e-04 - val_loss: 3.9256e-04\n",
      "Epoch 476/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9093e-04 - val_loss: 3.9267e-04\n",
      "Epoch 477/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9080e-04 - val_loss: 3.9291e-04\n",
      "Epoch 478/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9083e-04 - val_loss: 3.9233e-04\n",
      "Epoch 479/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9060e-04 - val_loss: 3.9232e-04\n",
      "Epoch 480/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9064e-04 - val_loss: 3.9225e-04\n",
      "Epoch 481/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9032e-04 - val_loss: 3.9232e-04\n",
      "Epoch 482/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9037e-04 - val_loss: 3.9233e-04\n",
      "Epoch 483/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9025e-04 - val_loss: 3.9205e-04\n",
      "Epoch 484/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8987e-04 - val_loss: 3.9212e-04\n",
      "Epoch 485/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8978e-04 - val_loss: 3.9200e-04\n",
      "Epoch 486/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8987e-04 - val_loss: 3.9204e-04\n",
      "Epoch 487/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8972e-04 - val_loss: 3.9162e-04\n",
      "Epoch 488/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8951e-04 - val_loss: 3.9107e-04\n",
      "Epoch 489/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8952e-04 - val_loss: 3.9188e-04\n",
      "Epoch 490/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8936e-04 - val_loss: 3.9142e-04\n",
      "Epoch 491/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8930e-04 - val_loss: 3.9119e-04\n",
      "Epoch 492/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8931e-04 - val_loss: 3.9112e-04\n",
      "Epoch 493/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8928e-04 - val_loss: 3.9111e-04\n",
      "Epoch 494/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8909e-04 - val_loss: 3.9112e-04\n",
      "Epoch 495/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8909e-04 - val_loss: 3.9195e-04\n",
      "Epoch 496/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8874e-04 - val_loss: 3.9042e-04\n",
      "Epoch 497/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8880e-04 - val_loss: 3.9138e-04\n",
      "Epoch 498/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8873e-04 - val_loss: 3.9037e-04\n",
      "Epoch 499/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8847e-04 - val_loss: 3.9068e-04\n",
      "Epoch 500/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8860e-04 - val_loss: 3.9068e-04\n",
      "Epoch 501/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8818e-04 - val_loss: 3.9004e-04\n",
      "Epoch 502/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8814e-04 - val_loss: 3.8963e-04\n",
      "Epoch 503/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8810e-04 - val_loss: 3.8988e-04\n",
      "Epoch 504/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8793e-04 - val_loss: 3.8990e-04\n",
      "Epoch 505/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8778e-04 - val_loss: 3.9010e-04\n",
      "Epoch 506/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8779e-04 - val_loss: 3.8974e-04\n",
      "Epoch 507/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8781e-04 - val_loss: 3.8966e-04\n",
      "Epoch 508/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8780e-04 - val_loss: 3.8975e-04\n",
      "Epoch 509/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8760e-04 - val_loss: 3.8997e-04\n",
      "Epoch 510/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8740e-04 - val_loss: 3.8937e-04\n",
      "Epoch 511/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8728e-04 - val_loss: 3.9013e-04\n",
      "Epoch 512/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8730e-04 - val_loss: 3.9039e-04\n",
      "Epoch 513/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8708e-04 - val_loss: 3.9055e-04\n",
      "Epoch 514/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8722e-04 - val_loss: 3.9009e-04\n",
      "Epoch 515/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8691e-04 - val_loss: 3.8938e-04\n",
      "Epoch 516/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8669e-04 - val_loss: 3.8979e-04\n",
      "Epoch 517/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8671e-04 - val_loss: 3.8876e-04\n",
      "Epoch 518/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8685e-04 - val_loss: 3.8861e-04\n",
      "Epoch 519/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8649e-04 - val_loss: 3.8810e-04\n",
      "Epoch 520/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8653e-04 - val_loss: 3.8861e-04\n",
      "Epoch 521/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8648e-04 - val_loss: 3.8868e-04\n",
      "Epoch 522/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8634e-04 - val_loss: 3.8823e-04\n",
      "Epoch 523/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8621e-04 - val_loss: 3.8813e-04\n",
      "Epoch 524/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8591e-04 - val_loss: 3.8823e-04\n",
      "Epoch 525/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8595e-04 - val_loss: 3.8909e-04\n",
      "Epoch 526/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8585e-04 - val_loss: 3.8820e-04\n",
      "Epoch 527/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8567e-04 - val_loss: 3.8784e-04\n",
      "Epoch 528/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8577e-04 - val_loss: 3.8751e-04\n",
      "Epoch 529/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8545e-04 - val_loss: 3.8797e-04\n",
      "Epoch 530/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8568e-04 - val_loss: 3.8776e-04\n",
      "Epoch 531/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8551e-04 - val_loss: 3.8766e-04\n",
      "Epoch 532/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8516e-04 - val_loss: 3.8732e-04\n",
      "Epoch 533/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8528e-04 - val_loss: 3.8830e-04\n",
      "Epoch 534/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8511e-04 - val_loss: 3.8689e-04\n",
      "Epoch 535/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8503e-04 - val_loss: 3.8721e-04\n",
      "Epoch 536/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8488e-04 - val_loss: 3.8678e-04\n",
      "Epoch 537/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8472e-04 - val_loss: 3.8742e-04\n",
      "Epoch 538/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8464e-04 - val_loss: 3.8685e-04\n",
      "Epoch 539/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8474e-04 - val_loss: 3.8699e-04\n",
      "Epoch 540/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8439e-04 - val_loss: 3.8653e-04\n",
      "Epoch 541/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8463e-04 - val_loss: 3.8624e-04\n",
      "Epoch 542/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.8451e-04 - val_loss: 3.8613e-04\n",
      "Epoch 543/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8430e-04 - val_loss: 3.8611e-04\n",
      "Epoch 544/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8422e-04 - val_loss: 3.8639e-04\n",
      "Epoch 545/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8424e-04 - val_loss: 3.8678e-04\n",
      "Epoch 546/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8418e-04 - val_loss: 3.8586e-04\n",
      "Epoch 547/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8404e-04 - val_loss: 3.8555e-04\n",
      "Epoch 548/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8395e-04 - val_loss: 3.8680e-04\n",
      "Epoch 549/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8374e-04 - val_loss: 3.8640e-04\n",
      "Epoch 550/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8361e-04 - val_loss: 3.8553e-04\n",
      "Epoch 551/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8354e-04 - val_loss: 3.8560e-04\n",
      "Epoch 552/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8337e-04 - val_loss: 3.8568e-04\n",
      "Epoch 553/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8350e-04 - val_loss: 3.8613e-04\n",
      "Epoch 554/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8323e-04 - val_loss: 3.8572e-04\n",
      "Epoch 555/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8318e-04 - val_loss: 3.8509e-04\n",
      "Epoch 556/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8310e-04 - val_loss: 3.8651e-04\n",
      "Epoch 557/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8319e-04 - val_loss: 3.8509e-04\n",
      "Epoch 558/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8295e-04 - val_loss: 3.8663e-04\n",
      "Epoch 559/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8279e-04 - val_loss: 3.8522e-04\n",
      "Epoch 560/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8267e-04 - val_loss: 3.8451e-04\n",
      "Epoch 561/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8278e-04 - val_loss: 3.8528e-04\n",
      "Epoch 562/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8245e-04 - val_loss: 3.8465e-04\n",
      "Epoch 563/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8241e-04 - val_loss: 3.8451e-04\n",
      "Epoch 564/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8250e-04 - val_loss: 3.8424e-04\n",
      "Epoch 565/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8216e-04 - val_loss: 3.8414e-04\n",
      "Epoch 566/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8212e-04 - val_loss: 3.8403e-04\n",
      "Epoch 567/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8221e-04 - val_loss: 3.8377e-04\n",
      "Epoch 568/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8214e-04 - val_loss: 3.8428e-04\n",
      "Epoch 569/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8180e-04 - val_loss: 3.8425e-04\n",
      "Epoch 570/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8173e-04 - val_loss: 3.8379e-04\n",
      "Epoch 571/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8172e-04 - val_loss: 3.8360e-04\n",
      "Epoch 572/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8157e-04 - val_loss: 3.8387e-04\n",
      "Epoch 573/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8148e-04 - val_loss: 3.8324e-04\n",
      "Epoch 574/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8152e-04 - val_loss: 3.8352e-04\n",
      "Epoch 575/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8123e-04 - val_loss: 3.8353e-04\n",
      "Epoch 576/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8131e-04 - val_loss: 3.8356e-04\n",
      "Epoch 577/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8128e-04 - val_loss: 3.8328e-04\n",
      "Epoch 578/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8107e-04 - val_loss: 3.8336e-04\n",
      "Epoch 579/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8116e-04 - val_loss: 3.8372e-04\n",
      "Epoch 580/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8081e-04 - val_loss: 3.8322e-04\n",
      "Epoch 581/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8083e-04 - val_loss: 3.8274e-04\n",
      "Epoch 582/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8080e-04 - val_loss: 3.8276e-04\n",
      "Epoch 583/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8070e-04 - val_loss: 3.8372e-04\n",
      "Epoch 584/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8062e-04 - val_loss: 3.8220e-04\n",
      "Epoch 585/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8036e-04 - val_loss: 3.8326e-04\n",
      "Epoch 586/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8049e-04 - val_loss: 3.8229e-04\n",
      "Epoch 587/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8023e-04 - val_loss: 3.8228e-04\n",
      "Epoch 588/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8010e-04 - val_loss: 3.8201e-04\n",
      "Epoch 589/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8021e-04 - val_loss: 3.8187e-04\n",
      "Epoch 590/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8035e-04 - val_loss: 3.8212e-04\n",
      "Epoch 591/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7993e-04 - val_loss: 3.8241e-04\n",
      "Epoch 592/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7973e-04 - val_loss: 3.8181e-04\n",
      "Epoch 593/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7974e-04 - val_loss: 3.8156e-04\n",
      "Epoch 594/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7958e-04 - val_loss: 3.8232e-04\n",
      "Epoch 595/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7959e-04 - val_loss: 3.8151e-04\n",
      "Epoch 596/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7945e-04 - val_loss: 3.8157e-04\n",
      "Epoch 597/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7947e-04 - val_loss: 3.8132e-04\n",
      "Epoch 598/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7955e-04 - val_loss: 3.8093e-04\n",
      "Epoch 599/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7894e-04 - val_loss: 3.8126e-04\n",
      "Epoch 600/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7910e-04 - val_loss: 3.8135e-04\n",
      "Epoch 601/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7898e-04 - val_loss: 3.8105e-04\n",
      "Epoch 602/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7908e-04 - val_loss: 3.8093e-04\n",
      "Epoch 603/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7872e-04 - val_loss: 3.8095e-04\n",
      "Epoch 604/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7879e-04 - val_loss: 3.8126e-04\n",
      "Epoch 605/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7881e-04 - val_loss: 3.8103e-04\n",
      "Epoch 606/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7865e-04 - val_loss: 3.8076e-04\n",
      "Epoch 607/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7856e-04 - val_loss: 3.8090e-04\n",
      "Epoch 608/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7859e-04 - val_loss: 3.8110e-04\n",
      "Epoch 609/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7825e-04 - val_loss: 3.8136e-04\n",
      "Epoch 610/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7870e-04 - val_loss: 3.8060e-04\n",
      "Epoch 611/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7836e-04 - val_loss: 3.8090e-04\n",
      "Epoch 612/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7805e-04 - val_loss: 3.8015e-04\n",
      "Epoch 613/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7807e-04 - val_loss: 3.8009e-04\n",
      "Epoch 614/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7821e-04 - val_loss: 3.7967e-04\n",
      "Epoch 615/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7796e-04 - val_loss: 3.8045e-04\n",
      "Epoch 616/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7790e-04 - val_loss: 3.7970e-04\n",
      "Epoch 617/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7768e-04 - val_loss: 3.7992e-04\n",
      "Epoch 618/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7764e-04 - val_loss: 3.7973e-04\n",
      "Epoch 619/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7761e-04 - val_loss: 3.7979e-04\n",
      "Epoch 620/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7756e-04 - val_loss: 3.8109e-04\n",
      "Epoch 621/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7736e-04 - val_loss: 3.7990e-04\n",
      "Epoch 622/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7738e-04 - val_loss: 3.7913e-04\n",
      "Epoch 623/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7742e-04 - val_loss: 3.7952e-04\n",
      "Epoch 624/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7711e-04 - val_loss: 3.7961e-04\n",
      "Epoch 625/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7715e-04 - val_loss: 3.7908e-04\n",
      "Epoch 626/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7688e-04 - val_loss: 3.7960e-04\n",
      "Epoch 627/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7675e-04 - val_loss: 3.8041e-04\n",
      "Epoch 628/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7680e-04 - val_loss: 3.7961e-04\n",
      "Epoch 629/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7681e-04 - val_loss: 3.7898e-04\n",
      "Epoch 630/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7680e-04 - val_loss: 3.7942e-04\n",
      "Epoch 631/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7672e-04 - val_loss: 3.7899e-04\n",
      "Epoch 632/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7644e-04 - val_loss: 3.7895e-04\n",
      "Epoch 633/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7634e-04 - val_loss: 3.7956e-04\n",
      "Epoch 634/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7627e-04 - val_loss: 3.7921e-04\n",
      "Epoch 635/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7660e-04 - val_loss: 3.7917e-04\n",
      "Epoch 636/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7606e-04 - val_loss: 3.7852e-04\n",
      "Epoch 637/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7608e-04 - val_loss: 3.7852e-04\n",
      "Epoch 638/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7595e-04 - val_loss: 3.7775e-04\n",
      "Epoch 639/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7609e-04 - val_loss: 3.7880e-04\n",
      "Epoch 640/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7599e-04 - val_loss: 3.7888e-04\n",
      "Epoch 641/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7583e-04 - val_loss: 3.7771e-04\n",
      "Epoch 642/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7580e-04 - val_loss: 3.7807e-04\n",
      "Epoch 643/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7585e-04 - val_loss: 3.7909e-04\n",
      "Epoch 644/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7531e-04 - val_loss: 3.7789e-04\n",
      "Epoch 645/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7566e-04 - val_loss: 3.7740e-04\n",
      "Epoch 646/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7558e-04 - val_loss: 3.7775e-04\n",
      "Epoch 647/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7515e-04 - val_loss: 3.7732e-04\n",
      "Epoch 648/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7539e-04 - val_loss: 3.7750e-04\n",
      "Epoch 649/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7532e-04 - val_loss: 3.7742e-04\n",
      "Epoch 650/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7528e-04 - val_loss: 3.7757e-04\n",
      "Epoch 651/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7500e-04 - val_loss: 3.7761e-04\n",
      "Epoch 652/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7481e-04 - val_loss: 3.7730e-04\n",
      "Epoch 653/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7501e-04 - val_loss: 3.7759e-04\n",
      "Epoch 654/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7479e-04 - val_loss: 3.7743e-04\n",
      "Epoch 655/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7465e-04 - val_loss: 3.7700e-04\n",
      "Epoch 656/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7480e-04 - val_loss: 3.7720e-04\n",
      "Epoch 657/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7469e-04 - val_loss: 3.7771e-04\n",
      "Epoch 658/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7464e-04 - val_loss: 3.7719e-04\n",
      "Epoch 659/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7457e-04 - val_loss: 3.7742e-04\n",
      "Epoch 660/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7439e-04 - val_loss: 3.7689e-04\n",
      "Epoch 661/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7419e-04 - val_loss: 3.7710e-04\n",
      "Epoch 662/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7428e-04 - val_loss: 3.7677e-04\n",
      "Epoch 663/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7422e-04 - val_loss: 3.7719e-04\n",
      "Epoch 664/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7402e-04 - val_loss: 3.7687e-04\n",
      "Epoch 665/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7388e-04 - val_loss: 3.7724e-04\n",
      "Epoch 666/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7397e-04 - val_loss: 3.7694e-04\n",
      "Epoch 667/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7394e-04 - val_loss: 3.7808e-04\n",
      "Epoch 668/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7394e-04 - val_loss: 3.7605e-04\n",
      "Epoch 669/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7367e-04 - val_loss: 3.7668e-04\n",
      "Epoch 670/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7360e-04 - val_loss: 3.7674e-04\n",
      "Epoch 671/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7373e-04 - val_loss: 3.7563e-04\n",
      "Epoch 672/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7356e-04 - val_loss: 3.7584e-04\n",
      "Epoch 673/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7357e-04 - val_loss: 3.7660e-04\n",
      "Epoch 674/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7359e-04 - val_loss: 3.7568e-04\n",
      "Epoch 675/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7335e-04 - val_loss: 3.7520e-04\n",
      "Epoch 676/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7344e-04 - val_loss: 3.7592e-04\n",
      "Epoch 677/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7325e-04 - val_loss: 3.7644e-04\n",
      "Epoch 678/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7322e-04 - val_loss: 3.7621e-04\n",
      "Epoch 679/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7325e-04 - val_loss: 3.7591e-04\n",
      "Epoch 680/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7304e-04 - val_loss: 3.7559e-04\n",
      "Epoch 681/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7335e-04 - val_loss: 3.7567e-04\n",
      "Epoch 682/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7277e-04 - val_loss: 3.7562e-04\n",
      "Epoch 683/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7292e-04 - val_loss: 3.7502e-04\n",
      "Epoch 684/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7287e-04 - val_loss: 3.7513e-04\n",
      "Epoch 685/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7267e-04 - val_loss: 3.7527e-04\n",
      "Epoch 686/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7254e-04 - val_loss: 3.7623e-04\n",
      "Epoch 687/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7258e-04 - val_loss: 3.7589e-04\n",
      "Epoch 688/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7257e-04 - val_loss: 3.7567e-04\n",
      "Epoch 689/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7273e-04 - val_loss: 3.7509e-04\n",
      "Epoch 690/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7246e-04 - val_loss: 3.7589e-04\n",
      "Epoch 691/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7223e-04 - val_loss: 3.7467e-04\n",
      "Epoch 692/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7224e-04 - val_loss: 3.7480e-04\n",
      "Epoch 693/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7234e-04 - val_loss: 3.7514e-04\n",
      "Epoch 694/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7220e-04 - val_loss: 3.7507e-04\n",
      "Epoch 695/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7222e-04 - val_loss: 3.7451e-04\n",
      "Epoch 696/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7192e-04 - val_loss: 3.7500e-04\n",
      "Epoch 697/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7206e-04 - val_loss: 3.7504e-04\n",
      "Epoch 698/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7204e-04 - val_loss: 3.7579e-04\n",
      "Epoch 699/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7206e-04 - val_loss: 3.7406e-04\n",
      "Epoch 700/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7173e-04 - val_loss: 3.7441e-04\n",
      "Epoch 701/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7157e-04 - val_loss: 3.7509e-04\n",
      "Epoch 702/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7188e-04 - val_loss: 3.7475e-04\n",
      "Epoch 703/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7160e-04 - val_loss: 3.7437e-04\n",
      "Epoch 704/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7154e-04 - val_loss: 3.7384e-04\n",
      "Epoch 705/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7148e-04 - val_loss: 3.7467e-04\n",
      "Epoch 706/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7132e-04 - val_loss: 3.7396e-04\n",
      "Epoch 707/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7136e-04 - val_loss: 3.7384e-04\n",
      "Epoch 708/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7146e-04 - val_loss: 3.7373e-04\n",
      "Epoch 709/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7121e-04 - val_loss: 3.7371e-04\n",
      "Epoch 710/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7110e-04 - val_loss: 3.7425e-04\n",
      "Epoch 711/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7092e-04 - val_loss: 3.7322e-04\n",
      "Epoch 712/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7101e-04 - val_loss: 3.7335e-04\n",
      "Epoch 713/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7105e-04 - val_loss: 3.7389e-04\n",
      "Epoch 714/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7092e-04 - val_loss: 3.7328e-04\n",
      "Epoch 715/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7081e-04 - val_loss: 3.7471e-04\n",
      "Epoch 716/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7081e-04 - val_loss: 3.7363e-04\n",
      "Epoch 717/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7074e-04 - val_loss: 3.7318e-04\n",
      "Epoch 718/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7057e-04 - val_loss: 3.7389e-04\n",
      "Epoch 719/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7064e-04 - val_loss: 3.7392e-04\n",
      "Epoch 720/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7075e-04 - val_loss: 3.7311e-04\n",
      "Epoch 721/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7060e-04 - val_loss: 3.7453e-04\n",
      "Epoch 722/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7036e-04 - val_loss: 3.7302e-04\n",
      "Epoch 723/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7035e-04 - val_loss: 3.7302e-04\n",
      "Epoch 724/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7031e-04 - val_loss: 3.7308e-04\n",
      "Epoch 725/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7021e-04 - val_loss: 3.7339e-04\n",
      "Epoch 726/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7035e-04 - val_loss: 3.7323e-04\n",
      "Epoch 727/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7002e-04 - val_loss: 3.7345e-04\n",
      "Epoch 728/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7016e-04 - val_loss: 3.7401e-04\n",
      "Epoch 729/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7009e-04 - val_loss: 3.7231e-04\n",
      "Epoch 730/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6988e-04 - val_loss: 3.7278e-04\n",
      "Epoch 731/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7000e-04 - val_loss: 3.7250e-04\n",
      "Epoch 732/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6986e-04 - val_loss: 3.7336e-04\n",
      "Epoch 733/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6992e-04 - val_loss: 3.7320e-04\n",
      "Epoch 734/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6979e-04 - val_loss: 3.7190e-04\n",
      "Epoch 735/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6983e-04 - val_loss: 3.7226e-04\n",
      "Epoch 736/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6972e-04 - val_loss: 3.7189e-04\n",
      "Epoch 737/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6950e-04 - val_loss: 3.7350e-04\n",
      "Epoch 738/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6939e-04 - val_loss: 3.7232e-04\n",
      "Epoch 739/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6931e-04 - val_loss: 3.7239e-04\n",
      "Epoch 740/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6935e-04 - val_loss: 3.7261e-04\n",
      "Epoch 741/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6930e-04 - val_loss: 3.7204e-04\n",
      "Epoch 742/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6915e-04 - val_loss: 3.7179e-04\n",
      "Epoch 743/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6919e-04 - val_loss: 3.7198e-04\n",
      "Epoch 744/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6928e-04 - val_loss: 3.7254e-04\n",
      "Epoch 745/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6905e-04 - val_loss: 3.7192e-04\n",
      "Epoch 746/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6907e-04 - val_loss: 3.7139e-04\n",
      "Epoch 747/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6895e-04 - val_loss: 3.7130e-04\n",
      "Epoch 748/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6896e-04 - val_loss: 3.7262e-04\n",
      "Epoch 749/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6873e-04 - val_loss: 3.7223e-04\n",
      "Epoch 750/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6865e-04 - val_loss: 3.7187e-04\n",
      "Epoch 751/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6879e-04 - val_loss: 3.7187e-04\n",
      "Epoch 752/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6856e-04 - val_loss: 3.7166e-04\n",
      "Epoch 753/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6854e-04 - val_loss: 3.7090e-04\n",
      "Epoch 754/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6849e-04 - val_loss: 3.7150e-04\n",
      "Epoch 755/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6843e-04 - val_loss: 3.7138e-04\n",
      "Epoch 756/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6840e-04 - val_loss: 3.7212e-04\n",
      "Epoch 757/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6832e-04 - val_loss: 3.7112e-04\n",
      "Epoch 758/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6825e-04 - val_loss: 3.7070e-04\n",
      "Epoch 759/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6823e-04 - val_loss: 3.7117e-04\n",
      "Epoch 760/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6813e-04 - val_loss: 3.7125e-04\n",
      "Epoch 761/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6821e-04 - val_loss: 3.7196e-04\n",
      "Epoch 762/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6821e-04 - val_loss: 3.7118e-04\n",
      "Epoch 763/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6814e-04 - val_loss: 3.7092e-04\n",
      "Epoch 764/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6808e-04 - val_loss: 3.7079e-04\n",
      "Epoch 765/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6795e-04 - val_loss: 3.7180e-04\n",
      "Epoch 766/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6795e-04 - val_loss: 3.7099e-04\n",
      "Epoch 767/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6785e-04 - val_loss: 3.7111e-04\n",
      "Epoch 768/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6770e-04 - val_loss: 3.7089e-04\n",
      "Epoch 769/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6757e-04 - val_loss: 3.7197e-04\n",
      "Epoch 770/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6782e-04 - val_loss: 3.7072e-04\n",
      "Epoch 771/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6774e-04 - val_loss: 3.7125e-04\n",
      "Epoch 772/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6749e-04 - val_loss: 3.7086e-04\n",
      "Epoch 773/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6748e-04 - val_loss: 3.7123e-04\n",
      "Epoch 774/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6741e-04 - val_loss: 3.7039e-04\n",
      "Epoch 775/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6751e-04 - val_loss: 3.7008e-04\n",
      "Epoch 776/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6724e-04 - val_loss: 3.7129e-04\n",
      "Epoch 777/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6738e-04 - val_loss: 3.7150e-04\n",
      "Epoch 778/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6725e-04 - val_loss: 3.7069e-04\n",
      "Epoch 779/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6722e-04 - val_loss: 3.6995e-04\n",
      "Epoch 780/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6709e-04 - val_loss: 3.7079e-04\n",
      "Epoch 781/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6684e-04 - val_loss: 3.7019e-04\n",
      "Epoch 782/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6692e-04 - val_loss: 3.7043e-04\n",
      "Epoch 783/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6689e-04 - val_loss: 3.6958e-04\n",
      "Epoch 784/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6681e-04 - val_loss: 3.7031e-04\n",
      "Epoch 785/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6693e-04 - val_loss: 3.7001e-04\n",
      "Epoch 786/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6673e-04 - val_loss: 3.7129e-04\n",
      "Epoch 787/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6660e-04 - val_loss: 3.7085e-04\n",
      "Epoch 788/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6671e-04 - val_loss: 3.7049e-04\n",
      "Epoch 789/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6669e-04 - val_loss: 3.7036e-04\n",
      "Epoch 790/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6643e-04 - val_loss: 3.6967e-04\n",
      "Epoch 791/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.6647e-04 - val_loss: 3.7050e-04\n",
      "Epoch 792/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.6668e-04 - val_loss: 3.6976e-04\n",
      "Epoch 793/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6645e-04 - val_loss: 3.6928e-04\n",
      "Epoch 794/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6637e-04 - val_loss: 3.7028e-04\n",
      "Epoch 795/1000\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 3.6658e-04 - val_loss: 3.6995e-04\n",
      "Epoch 796/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6619e-04 - val_loss: 3.6932e-04\n",
      "Epoch 797/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6618e-04 - val_loss: 3.6920e-04\n",
      "Epoch 798/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6594e-04 - val_loss: 3.7020e-04\n",
      "Epoch 799/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6636e-04 - val_loss: 3.6897e-04\n",
      "Epoch 800/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6629e-04 - val_loss: 3.7009e-04\n",
      "Epoch 801/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6595e-04 - val_loss: 3.6942e-04\n",
      "Epoch 802/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6596e-04 - val_loss: 3.6912e-04\n",
      "Epoch 803/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6594e-04 - val_loss: 3.6925e-04\n",
      "Epoch 804/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6599e-04 - val_loss: 3.6989e-04\n",
      "Epoch 805/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6620e-04 - val_loss: 3.6891e-04\n",
      "Epoch 806/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6572e-04 - val_loss: 3.6878e-04\n",
      "Epoch 807/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6577e-04 - val_loss: 3.6976e-04\n",
      "Epoch 808/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6593e-04 - val_loss: 3.6945e-04\n",
      "Epoch 809/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6559e-04 - val_loss: 3.6920e-04\n",
      "Epoch 810/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6550e-04 - val_loss: 3.6842e-04\n",
      "Epoch 811/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6535e-04 - val_loss: 3.6892e-04\n",
      "Epoch 812/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6529e-04 - val_loss: 3.6960e-04\n",
      "Epoch 813/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6532e-04 - val_loss: 3.6858e-04\n",
      "Epoch 814/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6534e-04 - val_loss: 3.6863e-04\n",
      "Epoch 815/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6519e-04 - val_loss: 3.6802e-04\n",
      "Epoch 816/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6527e-04 - val_loss: 3.6918e-04\n",
      "Epoch 817/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6523e-04 - val_loss: 3.6820e-04\n",
      "Epoch 818/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6515e-04 - val_loss: 3.6872e-04\n",
      "Epoch 819/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6508e-04 - val_loss: 3.6826e-04\n",
      "Epoch 820/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6515e-04 - val_loss: 3.6812e-04\n",
      "Epoch 821/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6511e-04 - val_loss: 3.6871e-04\n",
      "Epoch 822/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6481e-04 - val_loss: 3.6873e-04\n",
      "Epoch 823/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6497e-04 - val_loss: 3.6802e-04\n",
      "Epoch 824/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6483e-04 - val_loss: 3.6828e-04\n",
      "Epoch 825/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6470e-04 - val_loss: 3.6848e-04\n",
      "Epoch 826/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6467e-04 - val_loss: 3.6808e-04\n",
      "Epoch 827/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6446e-04 - val_loss: 3.6866e-04\n",
      "Epoch 828/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6446e-04 - val_loss: 3.6740e-04\n",
      "Epoch 829/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6464e-04 - val_loss: 3.6810e-04\n",
      "Epoch 830/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6446e-04 - val_loss: 3.6759e-04\n",
      "Epoch 831/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6458e-04 - val_loss: 3.6851e-04\n",
      "Epoch 832/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6415e-04 - val_loss: 3.6797e-04\n",
      "Epoch 833/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6420e-04 - val_loss: 3.6767e-04\n",
      "Epoch 834/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6433e-04 - val_loss: 3.6722e-04\n",
      "Epoch 835/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6415e-04 - val_loss: 3.6766e-04\n",
      "Epoch 836/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6435e-04 - val_loss: 3.6839e-04\n",
      "Epoch 837/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6410e-04 - val_loss: 3.6769e-04\n",
      "Epoch 838/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6409e-04 - val_loss: 3.6761e-04\n",
      "Epoch 839/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6389e-04 - val_loss: 3.6719e-04\n",
      "Epoch 840/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6398e-04 - val_loss: 3.6709e-04\n",
      "Epoch 841/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6391e-04 - val_loss: 3.6746e-04\n",
      "Epoch 842/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6388e-04 - val_loss: 3.6841e-04\n",
      "Epoch 843/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6382e-04 - val_loss: 3.6696e-04\n",
      "Epoch 844/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6363e-04 - val_loss: 3.6692e-04\n",
      "Epoch 845/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6367e-04 - val_loss: 3.6706e-04\n",
      "Epoch 846/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6375e-04 - val_loss: 3.6728e-04\n",
      "Epoch 847/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6346e-04 - val_loss: 3.6775e-04\n",
      "Epoch 848/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6373e-04 - val_loss: 3.6743e-04\n",
      "Epoch 849/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6338e-04 - val_loss: 3.6696e-04\n",
      "Epoch 850/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6324e-04 - val_loss: 3.6725e-04\n",
      "Epoch 851/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6345e-04 - val_loss: 3.6722e-04\n",
      "Epoch 852/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6328e-04 - val_loss: 3.6832e-04\n",
      "Epoch 853/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6311e-04 - val_loss: 3.6708e-04\n",
      "Epoch 854/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6324e-04 - val_loss: 3.6705e-04\n",
      "Epoch 855/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6324e-04 - val_loss: 3.6676e-04\n",
      "Epoch 856/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6327e-04 - val_loss: 3.6640e-04\n",
      "Epoch 857/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6302e-04 - val_loss: 3.6727e-04\n",
      "Epoch 858/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6310e-04 - val_loss: 3.6648e-04\n",
      "Epoch 859/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6280e-04 - val_loss: 3.6667e-04\n",
      "Epoch 860/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6303e-04 - val_loss: 3.6595e-04\n",
      "Epoch 861/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6293e-04 - val_loss: 3.6679e-04\n",
      "Epoch 862/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6295e-04 - val_loss: 3.6585e-04\n",
      "Epoch 863/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6300e-04 - val_loss: 3.6650e-04\n",
      "Epoch 864/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6255e-04 - val_loss: 3.6606e-04\n",
      "Epoch 865/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6273e-04 - val_loss: 3.6572e-04\n",
      "Epoch 866/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6249e-04 - val_loss: 3.6632e-04\n",
      "Epoch 867/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6253e-04 - val_loss: 3.6605e-04\n",
      "Epoch 868/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6264e-04 - val_loss: 3.6612e-04\n",
      "Epoch 869/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6228e-04 - val_loss: 3.6588e-04\n",
      "Epoch 870/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6239e-04 - val_loss: 3.6570e-04\n",
      "Epoch 871/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6231e-04 - val_loss: 3.6596e-04\n",
      "Epoch 872/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6240e-04 - val_loss: 3.6552e-04\n",
      "Epoch 873/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6230e-04 - val_loss: 3.6567e-04\n",
      "Epoch 874/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6227e-04 - val_loss: 3.6593e-04\n",
      "Epoch 875/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6250e-04 - val_loss: 3.6600e-04\n",
      "Epoch 876/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6218e-04 - val_loss: 3.6615e-04\n",
      "Epoch 877/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6222e-04 - val_loss: 3.6594e-04\n",
      "Epoch 878/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6208e-04 - val_loss: 3.6783e-04\n",
      "Epoch 879/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6181e-04 - val_loss: 3.6533e-04\n",
      "Epoch 880/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6195e-04 - val_loss: 3.6515e-04\n",
      "Epoch 881/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6186e-04 - val_loss: 3.6544e-04\n",
      "Epoch 882/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6187e-04 - val_loss: 3.6508e-04\n",
      "Epoch 883/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6176e-04 - val_loss: 3.6537e-04\n",
      "Epoch 884/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6177e-04 - val_loss: 3.6625e-04\n",
      "Epoch 885/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6158e-04 - val_loss: 3.6525e-04\n",
      "Epoch 886/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6166e-04 - val_loss: 3.6475e-04\n",
      "Epoch 887/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6159e-04 - val_loss: 3.6469e-04\n",
      "Epoch 888/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6145e-04 - val_loss: 3.6529e-04\n",
      "Epoch 889/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6167e-04 - val_loss: 3.6489e-04\n",
      "Epoch 890/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6167e-04 - val_loss: 3.6472e-04\n",
      "Epoch 891/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6145e-04 - val_loss: 3.6547e-04\n",
      "Epoch 892/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6155e-04 - val_loss: 3.6470e-04\n",
      "Epoch 893/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6134e-04 - val_loss: 3.6485e-04\n",
      "Epoch 894/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6127e-04 - val_loss: 3.6556e-04\n",
      "Epoch 895/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6128e-04 - val_loss: 3.6473e-04\n",
      "Epoch 896/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6111e-04 - val_loss: 3.6533e-04\n",
      "Epoch 897/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6102e-04 - val_loss: 3.6492e-04\n",
      "Epoch 898/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6105e-04 - val_loss: 3.6498e-04\n",
      "Epoch 899/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6117e-04 - val_loss: 3.6469e-04\n",
      "Epoch 900/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6102e-04 - val_loss: 3.6387e-04\n",
      "Epoch 901/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6087e-04 - val_loss: 3.6450e-04\n",
      "Epoch 902/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6096e-04 - val_loss: 3.6392e-04\n",
      "Epoch 903/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6086e-04 - val_loss: 3.6396e-04\n",
      "Epoch 904/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6055e-04 - val_loss: 3.6432e-04\n",
      "Epoch 905/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6085e-04 - val_loss: 3.6496e-04\n",
      "Epoch 906/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6072e-04 - val_loss: 3.6412e-04\n",
      "Epoch 907/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6068e-04 - val_loss: 3.6428e-04\n",
      "Epoch 908/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6067e-04 - val_loss: 3.6474e-04\n",
      "Epoch 909/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6042e-04 - val_loss: 3.6429e-04\n",
      "Epoch 910/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6061e-04 - val_loss: 3.6480e-04\n",
      "Epoch 911/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6057e-04 - val_loss: 3.6427e-04\n",
      "Epoch 912/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6031e-04 - val_loss: 3.6377e-04\n",
      "Epoch 913/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6017e-04 - val_loss: 3.6397e-04\n",
      "Epoch 914/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6023e-04 - val_loss: 3.6447e-04\n",
      "Epoch 915/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6014e-04 - val_loss: 3.6453e-04\n",
      "Epoch 916/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6011e-04 - val_loss: 3.6388e-04\n",
      "Epoch 917/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6002e-04 - val_loss: 3.6440e-04\n",
      "Epoch 918/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6004e-04 - val_loss: 3.6390e-04\n",
      "Epoch 919/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6005e-04 - val_loss: 3.6382e-04\n",
      "Epoch 920/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5990e-04 - val_loss: 3.6349e-04\n",
      "Epoch 921/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5993e-04 - val_loss: 3.6324e-04\n",
      "Epoch 922/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6001e-04 - val_loss: 3.6384e-04\n",
      "Epoch 923/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6017e-04 - val_loss: 3.6308e-04\n",
      "Epoch 924/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5999e-04 - val_loss: 3.6421e-04\n",
      "Epoch 925/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5979e-04 - val_loss: 3.6335e-04\n",
      "Epoch 926/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5980e-04 - val_loss: 3.6326e-04\n",
      "Epoch 927/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5987e-04 - val_loss: 3.6325e-04\n",
      "Epoch 928/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5966e-04 - val_loss: 3.6370e-04\n",
      "Epoch 929/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5950e-04 - val_loss: 3.6441e-04\n",
      "Epoch 930/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5952e-04 - val_loss: 3.6274e-04\n",
      "Epoch 931/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5965e-04 - val_loss: 3.6415e-04\n",
      "Epoch 932/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5960e-04 - val_loss: 3.6310e-04\n",
      "Epoch 933/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5954e-04 - val_loss: 3.6298e-04\n",
      "Epoch 934/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5932e-04 - val_loss: 3.6284e-04\n",
      "Epoch 935/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5923e-04 - val_loss: 3.6349e-04\n",
      "Epoch 936/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5936e-04 - val_loss: 3.6435e-04\n",
      "Epoch 937/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5921e-04 - val_loss: 3.6358e-04\n",
      "Epoch 938/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5899e-04 - val_loss: 3.6247e-04\n",
      "Epoch 939/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5916e-04 - val_loss: 3.6443e-04\n",
      "Epoch 940/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5904e-04 - val_loss: 3.6222e-04\n",
      "Epoch 941/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5899e-04 - val_loss: 3.6278e-04\n",
      "Epoch 942/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5887e-04 - val_loss: 3.6230e-04\n",
      "Epoch 943/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5881e-04 - val_loss: 3.6217e-04\n",
      "Epoch 944/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5869e-04 - val_loss: 3.6241e-04\n",
      "Epoch 945/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5878e-04 - val_loss: 3.6255e-04\n",
      "Epoch 946/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5877e-04 - val_loss: 3.6206e-04\n",
      "Epoch 947/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5871e-04 - val_loss: 3.6229e-04\n",
      "Epoch 948/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5875e-04 - val_loss: 3.6260e-04\n",
      "Epoch 949/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5882e-04 - val_loss: 3.6223e-04\n",
      "Epoch 950/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5862e-04 - val_loss: 3.6205e-04\n",
      "Epoch 951/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5849e-04 - val_loss: 3.6286e-04\n",
      "Epoch 952/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5848e-04 - val_loss: 3.6176e-04\n",
      "Epoch 953/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5842e-04 - val_loss: 3.6268e-04\n",
      "Epoch 954/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5835e-04 - val_loss: 3.6174e-04\n",
      "Epoch 955/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5819e-04 - val_loss: 3.6222e-04\n",
      "Epoch 956/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5832e-04 - val_loss: 3.6280e-04\n",
      "Epoch 957/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5823e-04 - val_loss: 3.6245e-04\n",
      "Epoch 958/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5825e-04 - val_loss: 3.6341e-04\n",
      "Epoch 959/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5827e-04 - val_loss: 3.6217e-04\n",
      "Epoch 960/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5817e-04 - val_loss: 3.6189e-04\n",
      "Epoch 961/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5807e-04 - val_loss: 3.6164e-04\n",
      "Epoch 962/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5798e-04 - val_loss: 3.6254e-04\n",
      "Epoch 963/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5781e-04 - val_loss: 3.6142e-04\n",
      "Epoch 964/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5786e-04 - val_loss: 3.6184e-04\n",
      "Epoch 965/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5807e-04 - val_loss: 3.6156e-04\n",
      "Epoch 966/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5794e-04 - val_loss: 3.6217e-04\n",
      "Epoch 967/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5769e-04 - val_loss: 3.6180e-04\n",
      "Epoch 968/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5797e-04 - val_loss: 3.6187e-04\n",
      "Epoch 969/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5777e-04 - val_loss: 3.6177e-04\n",
      "Epoch 970/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5754e-04 - val_loss: 3.6154e-04\n",
      "Epoch 971/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5755e-04 - val_loss: 3.6199e-04\n",
      "Epoch 972/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5766e-04 - val_loss: 3.6123e-04\n",
      "Epoch 973/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5731e-04 - val_loss: 3.6097e-04\n",
      "Epoch 974/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5751e-04 - val_loss: 3.6125e-04\n",
      "Epoch 975/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5725e-04 - val_loss: 3.6286e-04\n",
      "Epoch 976/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5734e-04 - val_loss: 3.6069e-04\n",
      "Epoch 977/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5745e-04 - val_loss: 3.6117e-04\n",
      "Epoch 978/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5717e-04 - val_loss: 3.6100e-04\n",
      "Epoch 979/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5740e-04 - val_loss: 3.6095e-04\n",
      "Epoch 980/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5704e-04 - val_loss: 3.6098e-04\n",
      "Epoch 981/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5701e-04 - val_loss: 3.6061e-04\n",
      "Epoch 982/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5711e-04 - val_loss: 3.6038e-04\n",
      "Epoch 983/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5698e-04 - val_loss: 3.6099e-04\n",
      "Epoch 984/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5686e-04 - val_loss: 3.6205e-04\n",
      "Epoch 985/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5686e-04 - val_loss: 3.6020e-04\n",
      "Epoch 986/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5695e-04 - val_loss: 3.6184e-04\n",
      "Epoch 987/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5692e-04 - val_loss: 3.6048e-04\n",
      "Epoch 988/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5672e-04 - val_loss: 3.6079e-04\n",
      "Epoch 989/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5709e-04 - val_loss: 3.6077e-04\n",
      "Epoch 990/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5673e-04 - val_loss: 3.6070e-04\n",
      "Epoch 991/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5675e-04 - val_loss: 3.6040e-04\n",
      "Epoch 992/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5669e-04 - val_loss: 3.5996e-04\n",
      "Epoch 993/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5674e-04 - val_loss: 3.6033e-04\n",
      "Epoch 994/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5641e-04 - val_loss: 3.6024e-04\n",
      "Epoch 995/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5637e-04 - val_loss: 3.6074e-04\n",
      "Epoch 996/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5643e-04 - val_loss: 3.6035e-04\n",
      "Epoch 997/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5627e-04 - val_loss: 3.6139e-04\n",
      "Epoch 998/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5642e-04 - val_loss: 3.6002e-04\n",
      "Epoch 999/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5631e-04 - val_loss: 3.6040e-04\n",
      "Epoch 1000/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5610e-04 - val_loss: 3.5961e-04\n",
      "INFO:tensorflow:Assets written to: AET_CF_Trial_11/models/saved_model_11_LSP_AET_CF_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: AET_CF_Trial_11/models/saved_model_11_LSP_AET_CF_0/assets\n",
      " 50%|█████████████████████▌                     | 1/2 [21:29<21:29, 1289.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.5629e-04 - val_loss: 3.6035e-04\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5602e-04 - val_loss: 3.6026e-04\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5625e-04 - val_loss: 3.6085e-04\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5590e-04 - val_loss: 3.6120e-04\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5589e-04 - val_loss: 3.5962e-04\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5591e-04 - val_loss: 3.5999e-04\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5582e-04 - val_loss: 3.5978e-04\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5574e-04 - val_loss: 3.6017e-04\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5593e-04 - val_loss: 3.5984e-04\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5588e-04 - val_loss: 3.6000e-04\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5582e-04 - val_loss: 3.5986e-04\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5569e-04 - val_loss: 3.5957e-04\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5578e-04 - val_loss: 3.5975e-04\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5554e-04 - val_loss: 3.5942e-04\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5532e-04 - val_loss: 3.5979e-04\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5536e-04 - val_loss: 3.5932e-04\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5559e-04 - val_loss: 3.5945e-04\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5552e-04 - val_loss: 3.6057e-04\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5551e-04 - val_loss: 3.5926e-04\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5514e-04 - val_loss: 3.5979e-04\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5520e-04 - val_loss: 3.5953e-04\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5515e-04 - val_loss: 3.5933e-04\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5510e-04 - val_loss: 3.5852e-04\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5504e-04 - val_loss: 3.5930e-04\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5540e-04 - val_loss: 3.5894e-04\n",
      "Epoch 26/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5492e-04 - val_loss: 3.5901e-04\n",
      "Epoch 27/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5509e-04 - val_loss: 3.5890e-04\n",
      "Epoch 28/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5483e-04 - val_loss: 3.5862e-04\n",
      "Epoch 29/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5476e-04 - val_loss: 3.5854e-04\n",
      "Epoch 30/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5491e-04 - val_loss: 3.5966e-04\n",
      "Epoch 31/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5483e-04 - val_loss: 3.5857e-04\n",
      "Epoch 32/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5466e-04 - val_loss: 3.5850e-04\n",
      "Epoch 33/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5452e-04 - val_loss: 3.5840e-04\n",
      "Epoch 34/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5471e-04 - val_loss: 3.5897e-04\n",
      "Epoch 35/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5467e-04 - val_loss: 3.5846e-04\n",
      "Epoch 36/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5439e-04 - val_loss: 3.5857e-04\n",
      "Epoch 37/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5459e-04 - val_loss: 3.5822e-04\n",
      "Epoch 38/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5449e-04 - val_loss: 3.5839e-04\n",
      "Epoch 39/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5433e-04 - val_loss: 3.5847e-04\n",
      "Epoch 40/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5454e-04 - val_loss: 3.5840e-04\n",
      "Epoch 41/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5424e-04 - val_loss: 3.5821e-04\n",
      "Epoch 42/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5433e-04 - val_loss: 3.5932e-04\n",
      "Epoch 43/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5426e-04 - val_loss: 3.5758e-04\n",
      "Epoch 44/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5434e-04 - val_loss: 3.5801e-04\n",
      "Epoch 45/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5424e-04 - val_loss: 3.5799e-04\n",
      "Epoch 46/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5404e-04 - val_loss: 3.5804e-04\n",
      "Epoch 47/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5426e-04 - val_loss: 3.5784e-04\n",
      "Epoch 48/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5386e-04 - val_loss: 3.5911e-04\n",
      "Epoch 49/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5391e-04 - val_loss: 3.5792e-04\n",
      "Epoch 50/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5393e-04 - val_loss: 3.5862e-04\n",
      "Epoch 51/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5368e-04 - val_loss: 3.5884e-04\n",
      "Epoch 52/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5390e-04 - val_loss: 3.5806e-04\n",
      "Epoch 53/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5377e-04 - val_loss: 3.5745e-04\n",
      "Epoch 54/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5364e-04 - val_loss: 3.5744e-04\n",
      "Epoch 55/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5369e-04 - val_loss: 3.5781e-04\n",
      "Epoch 56/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5361e-04 - val_loss: 3.5764e-04\n",
      "Epoch 57/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5359e-04 - val_loss: 3.5751e-04\n",
      "Epoch 58/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5350e-04 - val_loss: 3.5782e-04\n",
      "Epoch 59/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5369e-04 - val_loss: 3.5876e-04\n",
      "Epoch 60/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5365e-04 - val_loss: 3.5727e-04\n",
      "Epoch 61/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5318e-04 - val_loss: 3.5819e-04\n",
      "Epoch 62/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5325e-04 - val_loss: 3.5749e-04\n",
      "Epoch 63/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5320e-04 - val_loss: 3.5697e-04\n",
      "Epoch 64/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5312e-04 - val_loss: 3.5824e-04\n",
      "Epoch 65/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5314e-04 - val_loss: 3.5756e-04\n",
      "Epoch 66/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5304e-04 - val_loss: 3.5832e-04\n",
      "Epoch 67/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5325e-04 - val_loss: 3.5789e-04\n",
      "Epoch 68/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5296e-04 - val_loss: 3.5706e-04\n",
      "Epoch 69/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5311e-04 - val_loss: 3.5652e-04\n",
      "Epoch 70/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5302e-04 - val_loss: 3.5696e-04\n",
      "Epoch 71/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5310e-04 - val_loss: 3.5655e-04\n",
      "Epoch 72/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5281e-04 - val_loss: 3.5661e-04\n",
      "Epoch 73/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5278e-04 - val_loss: 3.5709e-04\n",
      "Epoch 74/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5268e-04 - val_loss: 3.5910e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5285e-04 - val_loss: 3.5778e-04\n",
      "Epoch 76/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5247e-04 - val_loss: 3.5672e-04\n",
      "Epoch 77/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5260e-04 - val_loss: 3.5658e-04\n",
      "Epoch 78/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5253e-04 - val_loss: 3.5642e-04\n",
      "Epoch 79/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5246e-04 - val_loss: 3.5585e-04\n",
      "Epoch 80/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5249e-04 - val_loss: 3.5632e-04\n",
      "Epoch 81/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5273e-04 - val_loss: 3.5687e-04\n",
      "Epoch 82/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5253e-04 - val_loss: 3.5629e-04\n",
      "Epoch 83/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5223e-04 - val_loss: 3.5634e-04\n",
      "Epoch 84/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5234e-04 - val_loss: 3.5682e-04\n",
      "Epoch 85/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5219e-04 - val_loss: 3.5604e-04\n",
      "Epoch 86/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5230e-04 - val_loss: 3.5674e-04\n",
      "Epoch 87/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5217e-04 - val_loss: 3.5641e-04\n",
      "Epoch 88/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5239e-04 - val_loss: 3.5637e-04\n",
      "Epoch 89/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5196e-04 - val_loss: 3.5622e-04\n",
      "Epoch 90/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5193e-04 - val_loss: 3.5577e-04\n",
      "Epoch 91/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5189e-04 - val_loss: 3.5661e-04\n",
      "Epoch 92/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5214e-04 - val_loss: 3.5623e-04\n",
      "Epoch 93/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5187e-04 - val_loss: 3.5600e-04\n",
      "Epoch 94/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5162e-04 - val_loss: 3.5676e-04\n",
      "Epoch 95/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5186e-04 - val_loss: 3.5737e-04\n",
      "Epoch 96/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5166e-04 - val_loss: 3.5559e-04\n",
      "Epoch 97/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5151e-04 - val_loss: 3.5618e-04\n",
      "Epoch 98/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5159e-04 - val_loss: 3.5557e-04\n",
      "Epoch 99/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5179e-04 - val_loss: 3.5555e-04\n",
      "Epoch 100/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5166e-04 - val_loss: 3.5536e-04\n",
      "Epoch 101/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5158e-04 - val_loss: 3.5573e-04\n",
      "Epoch 102/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5156e-04 - val_loss: 3.5530e-04\n",
      "Epoch 103/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5127e-04 - val_loss: 3.5603e-04\n",
      "Epoch 104/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5157e-04 - val_loss: 3.5644e-04\n",
      "Epoch 105/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5137e-04 - val_loss: 3.5508e-04\n",
      "Epoch 106/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5122e-04 - val_loss: 3.5476e-04\n",
      "Epoch 107/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5108e-04 - val_loss: 3.5515e-04\n",
      "Epoch 108/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5115e-04 - val_loss: 3.5538e-04\n",
      "Epoch 109/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5120e-04 - val_loss: 3.5499e-04\n",
      "Epoch 110/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5098e-04 - val_loss: 3.5526e-04\n",
      "Epoch 111/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5106e-04 - val_loss: 3.5480e-04\n",
      "Epoch 112/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5088e-04 - val_loss: 3.5545e-04\n",
      "Epoch 113/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5097e-04 - val_loss: 3.5495e-04\n",
      "Epoch 114/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5086e-04 - val_loss: 3.5498e-04\n",
      "Epoch 115/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5074e-04 - val_loss: 3.5494e-04\n",
      "Epoch 116/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5101e-04 - val_loss: 3.5514e-04\n",
      "Epoch 117/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5106e-04 - val_loss: 3.5477e-04\n",
      "Epoch 118/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5084e-04 - val_loss: 3.5493e-04\n",
      "Epoch 119/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5080e-04 - val_loss: 3.5517e-04\n",
      "Epoch 120/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5045e-04 - val_loss: 3.5516e-04\n",
      "Epoch 121/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5036e-04 - val_loss: 3.5520e-04\n",
      "Epoch 122/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5063e-04 - val_loss: 3.5466e-04\n",
      "Epoch 123/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5051e-04 - val_loss: 3.5524e-04\n",
      "Epoch 124/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5047e-04 - val_loss: 3.5417e-04\n",
      "Epoch 125/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5032e-04 - val_loss: 3.5439e-04\n",
      "Epoch 126/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5032e-04 - val_loss: 3.5513e-04\n",
      "Epoch 127/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5033e-04 - val_loss: 3.5431e-04\n",
      "Epoch 128/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5033e-04 - val_loss: 3.5479e-04\n",
      "Epoch 129/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5006e-04 - val_loss: 3.5468e-04\n",
      "Epoch 130/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5007e-04 - val_loss: 3.5471e-04\n",
      "Epoch 131/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5056e-04 - val_loss: 3.5445e-04\n",
      "Epoch 132/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5004e-04 - val_loss: 3.5412e-04\n",
      "Epoch 133/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5004e-04 - val_loss: 3.5406e-04\n",
      "Epoch 134/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4988e-04 - val_loss: 3.5430e-04\n",
      "Epoch 135/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4989e-04 - val_loss: 3.5525e-04\n",
      "Epoch 136/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4985e-04 - val_loss: 3.5395e-04\n",
      "Epoch 137/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5002e-04 - val_loss: 3.5401e-04\n",
      "Epoch 138/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4988e-04 - val_loss: 3.5440e-04\n",
      "Epoch 139/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4980e-04 - val_loss: 3.5435e-04\n",
      "Epoch 140/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4975e-04 - val_loss: 3.5393e-04\n",
      "Epoch 141/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4974e-04 - val_loss: 3.5436e-04\n",
      "Epoch 142/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4951e-04 - val_loss: 3.5414e-04\n",
      "Epoch 143/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4954e-04 - val_loss: 3.5359e-04\n",
      "Epoch 144/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4965e-04 - val_loss: 3.5536e-04\n",
      "Epoch 145/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4951e-04 - val_loss: 3.5396e-04\n",
      "Epoch 146/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4965e-04 - val_loss: 3.5476e-04\n",
      "Epoch 147/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4941e-04 - val_loss: 3.5541e-04\n",
      "Epoch 148/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4968e-04 - val_loss: 3.5380e-04\n",
      "Epoch 149/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4944e-04 - val_loss: 3.5330e-04\n",
      "Epoch 150/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4915e-04 - val_loss: 3.5417e-04\n",
      "Epoch 151/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4911e-04 - val_loss: 3.5339e-04\n",
      "Epoch 152/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4912e-04 - val_loss: 3.5399e-04\n",
      "Epoch 153/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4918e-04 - val_loss: 3.5404e-04\n",
      "Epoch 154/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4911e-04 - val_loss: 3.5331e-04\n",
      "Epoch 155/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4907e-04 - val_loss: 3.5397e-04\n",
      "Epoch 156/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4911e-04 - val_loss: 3.5310e-04\n",
      "Epoch 157/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4885e-04 - val_loss: 3.5350e-04\n",
      "Epoch 158/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4899e-04 - val_loss: 3.5316e-04\n",
      "Epoch 159/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4893e-04 - val_loss: 3.5340e-04\n",
      "Epoch 160/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4890e-04 - val_loss: 3.5303e-04\n",
      "Epoch 161/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4869e-04 - val_loss: 3.5275e-04\n",
      "Epoch 162/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4859e-04 - val_loss: 3.5381e-04\n",
      "Epoch 163/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4856e-04 - val_loss: 3.5274e-04\n",
      "Epoch 164/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4853e-04 - val_loss: 3.5289e-04\n",
      "Epoch 165/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4866e-04 - val_loss: 3.5334e-04\n",
      "Epoch 166/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4849e-04 - val_loss: 3.5224e-04\n",
      "Epoch 167/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4859e-04 - val_loss: 3.5301e-04\n",
      "Epoch 168/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4830e-04 - val_loss: 3.5260e-04\n",
      "Epoch 169/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4828e-04 - val_loss: 3.5320e-04\n",
      "Epoch 170/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4823e-04 - val_loss: 3.5208e-04\n",
      "Epoch 171/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4854e-04 - val_loss: 3.5235e-04\n",
      "Epoch 172/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4823e-04 - val_loss: 3.5253e-04\n",
      "Epoch 173/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4828e-04 - val_loss: 3.5428e-04\n",
      "Epoch 174/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4814e-04 - val_loss: 3.5264e-04\n",
      "Epoch 175/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4823e-04 - val_loss: 3.5228e-04\n",
      "Epoch 176/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4822e-04 - val_loss: 3.5308e-04\n",
      "Epoch 177/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4802e-04 - val_loss: 3.5382e-04\n",
      "Epoch 178/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4811e-04 - val_loss: 3.5273e-04\n",
      "Epoch 179/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4809e-04 - val_loss: 3.5293e-04\n",
      "Epoch 180/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4799e-04 - val_loss: 3.5205e-04\n",
      "Epoch 181/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4776e-04 - val_loss: 3.5241e-04\n",
      "Epoch 182/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4781e-04 - val_loss: 3.5234e-04\n",
      "Epoch 183/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4790e-04 - val_loss: 3.5208e-04\n",
      "Epoch 184/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4769e-04 - val_loss: 3.5152e-04\n",
      "Epoch 185/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4750e-04 - val_loss: 3.5185e-04\n",
      "Epoch 186/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.4759e-04 - val_loss: 3.5192e-04\n",
      "Epoch 187/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4754e-04 - val_loss: 3.5236e-04\n",
      "Epoch 188/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4752e-04 - val_loss: 3.5237e-04\n",
      "Epoch 189/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4746e-04 - val_loss: 3.5160e-04\n",
      "Epoch 190/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4744e-04 - val_loss: 3.5129e-04\n",
      "Epoch 191/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4750e-04 - val_loss: 3.5189e-04\n",
      "Epoch 192/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4729e-04 - val_loss: 3.5189e-04\n",
      "Epoch 193/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4734e-04 - val_loss: 3.5190e-04\n",
      "Epoch 194/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4750e-04 - val_loss: 3.5349e-04\n",
      "Epoch 195/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4718e-04 - val_loss: 3.5201e-04\n",
      "Epoch 196/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4715e-04 - val_loss: 3.5174e-04\n",
      "Epoch 197/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4720e-04 - val_loss: 3.5198e-04\n",
      "Epoch 198/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4694e-04 - val_loss: 3.5175e-04\n",
      "Epoch 199/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4706e-04 - val_loss: 3.5197e-04\n",
      "Epoch 200/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4715e-04 - val_loss: 3.5182e-04\n",
      "Epoch 201/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4696e-04 - val_loss: 3.5137e-04\n",
      "Epoch 202/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4695e-04 - val_loss: 3.5132e-04\n",
      "Epoch 203/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4676e-04 - val_loss: 3.5162e-04\n",
      "Epoch 204/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4672e-04 - val_loss: 3.5134e-04\n",
      "Epoch 205/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4669e-04 - val_loss: 3.5126e-04\n",
      "Epoch 206/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4671e-04 - val_loss: 3.5199e-04\n",
      "Epoch 207/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4726e-04 - val_loss: 3.5152e-04\n",
      "Epoch 208/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4664e-04 - val_loss: 3.5065e-04\n",
      "Epoch 209/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4663e-04 - val_loss: 3.5169e-04\n",
      "Epoch 210/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4670e-04 - val_loss: 3.5134e-04\n",
      "Epoch 211/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4649e-04 - val_loss: 3.5132e-04\n",
      "Epoch 212/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4648e-04 - val_loss: 3.5171e-04\n",
      "Epoch 213/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4652e-04 - val_loss: 3.5078e-04\n",
      "Epoch 214/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4651e-04 - val_loss: 3.5090e-04\n",
      "Epoch 215/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4627e-04 - val_loss: 3.5055e-04\n",
      "Epoch 216/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4624e-04 - val_loss: 3.5033e-04\n",
      "Epoch 217/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4629e-04 - val_loss: 3.5110e-04\n",
      "Epoch 218/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4629e-04 - val_loss: 3.5028e-04\n",
      "Epoch 219/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4622e-04 - val_loss: 3.5139e-04\n",
      "Epoch 220/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4600e-04 - val_loss: 3.5079e-04\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4611e-04 - val_loss: 3.5095e-04\n",
      "Epoch 222/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4616e-04 - val_loss: 3.5104e-04\n",
      "Epoch 223/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4605e-04 - val_loss: 3.5012e-04\n",
      "Epoch 224/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4604e-04 - val_loss: 3.5060e-04\n",
      "Epoch 225/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4598e-04 - val_loss: 3.5001e-04\n",
      "Epoch 226/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4575e-04 - val_loss: 3.5064e-04\n",
      "Epoch 227/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4606e-04 - val_loss: 3.5101e-04\n",
      "Epoch 228/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4586e-04 - val_loss: 3.5055e-04\n",
      "Epoch 229/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4589e-04 - val_loss: 3.5062e-04\n",
      "Epoch 230/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4594e-04 - val_loss: 3.5063e-04\n",
      "Epoch 231/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4564e-04 - val_loss: 3.5069e-04\n",
      "Epoch 232/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4550e-04 - val_loss: 3.5016e-04\n",
      "Epoch 233/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4567e-04 - val_loss: 3.4991e-04\n",
      "Epoch 234/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4562e-04 - val_loss: 3.5049e-04\n",
      "Epoch 235/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4561e-04 - val_loss: 3.4996e-04\n",
      "Epoch 236/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4548e-04 - val_loss: 3.5018e-04\n",
      "Epoch 237/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4536e-04 - val_loss: 3.5036e-04\n",
      "Epoch 238/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4547e-04 - val_loss: 3.5036e-04\n",
      "Epoch 239/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4523e-04 - val_loss: 3.5054e-04\n",
      "Epoch 240/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4559e-04 - val_loss: 3.5002e-04\n",
      "Epoch 241/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4523e-04 - val_loss: 3.5010e-04\n",
      "Epoch 242/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4505e-04 - val_loss: 3.4980e-04\n",
      "Epoch 243/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4525e-04 - val_loss: 3.5032e-04\n",
      "Epoch 244/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4527e-04 - val_loss: 3.4996e-04\n",
      "Epoch 245/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4501e-04 - val_loss: 3.4950e-04\n",
      "Epoch 246/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4518e-04 - val_loss: 3.4923e-04\n",
      "Epoch 247/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4491e-04 - val_loss: 3.4941e-04\n",
      "Epoch 248/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4479e-04 - val_loss: 3.4974e-04\n",
      "Epoch 249/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4533e-04 - val_loss: 3.5032e-04\n",
      "Epoch 250/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4507e-04 - val_loss: 3.4974e-04\n",
      "Epoch 251/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4484e-04 - val_loss: 3.4977e-04\n",
      "Epoch 252/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4496e-04 - val_loss: 3.4951e-04\n",
      "Epoch 253/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.4490e-04 - val_loss: 3.4901e-04\n",
      "Epoch 254/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4470e-04 - val_loss: 3.4993e-04\n",
      "Epoch 255/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4485e-04 - val_loss: 3.4925e-04\n",
      "Epoch 256/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4468e-04 - val_loss: 3.4888e-04\n",
      "Epoch 257/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4439e-04 - val_loss: 3.4900e-04\n",
      "Epoch 258/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4459e-04 - val_loss: 3.4945e-04\n",
      "Epoch 259/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4463e-04 - val_loss: 3.4902e-04\n",
      "Epoch 260/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4444e-04 - val_loss: 3.4909e-04\n",
      "Epoch 261/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4432e-04 - val_loss: 3.4879e-04\n",
      "Epoch 262/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4449e-04 - val_loss: 3.4912e-04\n",
      "Epoch 263/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4433e-04 - val_loss: 3.4907e-04\n",
      "Epoch 264/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4431e-04 - val_loss: 3.4930e-04\n",
      "Epoch 265/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4429e-04 - val_loss: 3.4861e-04\n",
      "Epoch 266/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4414e-04 - val_loss: 3.4975e-04\n",
      "Epoch 267/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4402e-04 - val_loss: 3.4899e-04\n",
      "Epoch 268/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4418e-04 - val_loss: 3.4870e-04\n",
      "Epoch 269/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4415e-04 - val_loss: 3.4935e-04\n",
      "Epoch 270/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4400e-04 - val_loss: 3.4848e-04\n",
      "Epoch 271/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4376e-04 - val_loss: 3.4883e-04\n",
      "Epoch 272/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4391e-04 - val_loss: 3.4862e-04\n",
      "Epoch 273/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4398e-04 - val_loss: 3.4863e-04\n",
      "Epoch 274/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4387e-04 - val_loss: 3.4881e-04\n",
      "Epoch 275/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4385e-04 - val_loss: 3.4854e-04\n",
      "Epoch 276/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4390e-04 - val_loss: 3.4818e-04\n",
      "Epoch 277/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4391e-04 - val_loss: 3.4888e-04\n",
      "Epoch 278/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4370e-04 - val_loss: 3.4870e-04\n",
      "Epoch 279/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.4360e-04 - val_loss: 3.4834e-04\n",
      "Epoch 280/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4375e-04 - val_loss: 3.4921e-04\n",
      "Epoch 281/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4364e-04 - val_loss: 3.4779e-04\n",
      "Epoch 282/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4370e-04 - val_loss: 3.4854e-04\n",
      "Epoch 283/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4363e-04 - val_loss: 3.4766e-04\n",
      "Epoch 284/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4331e-04 - val_loss: 3.4876e-04\n",
      "Epoch 285/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4354e-04 - val_loss: 3.4793e-04\n",
      "Epoch 286/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4337e-04 - val_loss: 3.4822e-04\n",
      "Epoch 287/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4332e-04 - val_loss: 3.4825e-04\n",
      "Epoch 288/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4323e-04 - val_loss: 3.4789e-04\n",
      "Epoch 289/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4313e-04 - val_loss: 3.4759e-04\n",
      "Epoch 290/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4318e-04 - val_loss: 3.4786e-04\n",
      "Epoch 291/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4318e-04 - val_loss: 3.4813e-04\n",
      "Epoch 292/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4333e-04 - val_loss: 3.4877e-04\n",
      "Epoch 293/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4308e-04 - val_loss: 3.4837e-04\n",
      "Epoch 294/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4291e-04 - val_loss: 3.4764e-04\n",
      "Epoch 295/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4302e-04 - val_loss: 3.4768e-04\n",
      "Epoch 296/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4299e-04 - val_loss: 3.4856e-04\n",
      "Epoch 297/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4294e-04 - val_loss: 3.4814e-04\n",
      "Epoch 298/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4263e-04 - val_loss: 3.4808e-04\n",
      "Epoch 299/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4261e-04 - val_loss: 3.4809e-04\n",
      "Epoch 300/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4266e-04 - val_loss: 3.4721e-04\n",
      "Epoch 301/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4287e-04 - val_loss: 3.4839e-04\n",
      "Epoch 302/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4258e-04 - val_loss: 3.4786e-04\n",
      "Epoch 303/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4248e-04 - val_loss: 3.4836e-04\n",
      "Epoch 304/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4251e-04 - val_loss: 3.4765e-04\n",
      "Epoch 305/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4273e-04 - val_loss: 3.4761e-04\n",
      "Epoch 306/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4246e-04 - val_loss: 3.4977e-04\n",
      "Epoch 307/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4279e-04 - val_loss: 3.4772e-04\n",
      "Epoch 308/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4242e-04 - val_loss: 3.4729e-04\n",
      "Epoch 309/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4239e-04 - val_loss: 3.4688e-04\n",
      "Epoch 310/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4227e-04 - val_loss: 3.4719e-04\n",
      "Epoch 311/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4227e-04 - val_loss: 3.4746e-04\n",
      "Epoch 312/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4221e-04 - val_loss: 3.4683e-04\n",
      "Epoch 313/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4231e-04 - val_loss: 3.4744e-04\n",
      "Epoch 314/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4224e-04 - val_loss: 3.4713e-04\n",
      "Epoch 315/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4215e-04 - val_loss: 3.4680e-04\n",
      "Epoch 316/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4221e-04 - val_loss: 3.4673e-04\n",
      "Epoch 317/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4211e-04 - val_loss: 3.4678e-04\n",
      "Epoch 318/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4209e-04 - val_loss: 3.4765e-04\n",
      "Epoch 319/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4216e-04 - val_loss: 3.4684e-04\n",
      "Epoch 320/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4192e-04 - val_loss: 3.4675e-04\n",
      "Epoch 321/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4203e-04 - val_loss: 3.4659e-04\n",
      "Epoch 322/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4209e-04 - val_loss: 3.4617e-04\n",
      "Epoch 323/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4186e-04 - val_loss: 3.4661e-04\n",
      "Epoch 324/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4171e-04 - val_loss: 3.4701e-04\n",
      "Epoch 325/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4171e-04 - val_loss: 3.4691e-04\n",
      "Epoch 326/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4176e-04 - val_loss: 3.4655e-04\n",
      "Epoch 327/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4190e-04 - val_loss: 3.4648e-04\n",
      "Epoch 328/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4157e-04 - val_loss: 3.4675e-04\n",
      "Epoch 329/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4163e-04 - val_loss: 3.4663e-04\n",
      "Epoch 330/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4152e-04 - val_loss: 3.4681e-04\n",
      "Epoch 331/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4149e-04 - val_loss: 3.4669e-04\n",
      "Epoch 332/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4171e-04 - val_loss: 3.4780e-04\n",
      "Epoch 333/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4137e-04 - val_loss: 3.4620e-04\n",
      "Epoch 334/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4141e-04 - val_loss: 3.4608e-04\n",
      "Epoch 335/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4139e-04 - val_loss: 3.4595e-04\n",
      "Epoch 336/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4133e-04 - val_loss: 3.4578e-04\n",
      "Epoch 337/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4153e-04 - val_loss: 3.4694e-04\n",
      "Epoch 338/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4139e-04 - val_loss: 3.4630e-04\n",
      "Epoch 339/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4131e-04 - val_loss: 3.4613e-04\n",
      "Epoch 340/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4097e-04 - val_loss: 3.4630e-04\n",
      "Epoch 341/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4117e-04 - val_loss: 3.4589e-04\n",
      "Epoch 342/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4115e-04 - val_loss: 3.4682e-04\n",
      "Epoch 343/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4121e-04 - val_loss: 3.4674e-04\n",
      "Epoch 344/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4109e-04 - val_loss: 3.4532e-04\n",
      "Epoch 345/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4096e-04 - val_loss: 3.4586e-04\n",
      "Epoch 346/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4102e-04 - val_loss: 3.4624e-04\n",
      "Epoch 347/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4093e-04 - val_loss: 3.4558e-04\n",
      "Epoch 348/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4102e-04 - val_loss: 3.4608e-04\n",
      "Epoch 349/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4084e-04 - val_loss: 3.4536e-04\n",
      "Epoch 350/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4088e-04 - val_loss: 3.4610e-04\n",
      "Epoch 351/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4088e-04 - val_loss: 3.4603e-04\n",
      "Epoch 352/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4074e-04 - val_loss: 3.4539e-04\n",
      "Epoch 353/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4061e-04 - val_loss: 3.4543e-04\n",
      "Epoch 354/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4037e-04 - val_loss: 3.4512e-04\n",
      "Epoch 355/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4066e-04 - val_loss: 3.4711e-04\n",
      "Epoch 356/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4079e-04 - val_loss: 3.4511e-04\n",
      "Epoch 357/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4058e-04 - val_loss: 3.4535e-04\n",
      "Epoch 358/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4045e-04 - val_loss: 3.4528e-04\n",
      "Epoch 359/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4060e-04 - val_loss: 3.4606e-04\n",
      "Epoch 360/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4036e-04 - val_loss: 3.4530e-04\n",
      "Epoch 361/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4032e-04 - val_loss: 3.4524e-04\n",
      "Epoch 362/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4025e-04 - val_loss: 3.4546e-04\n",
      "Epoch 363/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4048e-04 - val_loss: 3.4615e-04\n",
      "Epoch 364/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4015e-04 - val_loss: 3.4587e-04\n",
      "Epoch 365/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4022e-04 - val_loss: 3.4585e-04\n",
      "Epoch 366/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4034e-04 - val_loss: 3.4480e-04\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4047e-04 - val_loss: 3.4473e-04\n",
      "Epoch 368/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3999e-04 - val_loss: 3.4521e-04\n",
      "Epoch 369/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4007e-04 - val_loss: 3.4448e-04\n",
      "Epoch 370/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4004e-04 - val_loss: 3.4532e-04\n",
      "Epoch 371/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4034e-04 - val_loss: 3.4479e-04\n",
      "Epoch 372/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3999e-04 - val_loss: 3.4406e-04\n",
      "Epoch 373/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3973e-04 - val_loss: 3.4519e-04\n",
      "Epoch 374/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3989e-04 - val_loss: 3.4488e-04\n",
      "Epoch 375/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4007e-04 - val_loss: 3.4516e-04\n",
      "Epoch 376/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3972e-04 - val_loss: 3.4500e-04\n",
      "Epoch 377/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3979e-04 - val_loss: 3.4493e-04\n",
      "Epoch 378/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3976e-04 - val_loss: 3.4499e-04\n",
      "Epoch 379/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3980e-04 - val_loss: 3.4479e-04\n",
      "Epoch 380/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3968e-04 - val_loss: 3.4514e-04\n",
      "Epoch 381/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3968e-04 - val_loss: 3.4526e-04\n",
      "Epoch 382/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3975e-04 - val_loss: 3.4519e-04\n",
      "Epoch 383/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3967e-04 - val_loss: 3.4488e-04\n",
      "Epoch 384/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3951e-04 - val_loss: 3.4437e-04\n",
      "Epoch 385/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3963e-04 - val_loss: 3.4463e-04\n",
      "Epoch 386/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3936e-04 - val_loss: 3.4421e-04\n",
      "Epoch 387/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3939e-04 - val_loss: 3.4443e-04\n",
      "Epoch 388/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3932e-04 - val_loss: 3.4419e-04\n",
      "Epoch 389/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3917e-04 - val_loss: 3.4473e-04\n",
      "Epoch 390/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3933e-04 - val_loss: 3.4471e-04\n",
      "Epoch 391/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3937e-04 - val_loss: 3.4405e-04\n",
      "Epoch 392/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3898e-04 - val_loss: 3.4384e-04\n",
      "Epoch 393/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3980e-04 - val_loss: 3.4421e-04\n",
      "Epoch 394/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3900e-04 - val_loss: 3.4400e-04\n",
      "Epoch 395/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3913e-04 - val_loss: 3.4508e-04\n",
      "Epoch 396/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3906e-04 - val_loss: 3.4456e-04\n",
      "Epoch 397/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3905e-04 - val_loss: 3.4382e-04\n",
      "Epoch 398/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3898e-04 - val_loss: 3.4450e-04\n",
      "Epoch 399/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3909e-04 - val_loss: 3.4526e-04\n",
      "Epoch 400/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3890e-04 - val_loss: 3.4431e-04\n",
      "Epoch 401/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3896e-04 - val_loss: 3.4426e-04\n",
      "Epoch 402/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3868e-04 - val_loss: 3.4384e-04\n",
      "Epoch 403/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3862e-04 - val_loss: 3.4433e-04\n",
      "Epoch 404/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3860e-04 - val_loss: 3.4474e-04\n",
      "Epoch 405/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3890e-04 - val_loss: 3.4401e-04\n",
      "Epoch 406/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3849e-04 - val_loss: 3.4497e-04\n",
      "Epoch 407/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3845e-04 - val_loss: 3.4353e-04\n",
      "Epoch 408/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3862e-04 - val_loss: 3.4427e-04\n",
      "Epoch 409/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3872e-04 - val_loss: 3.4434e-04\n",
      "Epoch 410/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3864e-04 - val_loss: 3.4443e-04\n",
      "Epoch 411/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3829e-04 - val_loss: 3.4448e-04\n",
      "Epoch 412/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3838e-04 - val_loss: 3.4424e-04\n",
      "Epoch 413/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3843e-04 - val_loss: 3.4290e-04\n",
      "Epoch 414/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3894e-04 - val_loss: 3.4606e-04\n",
      "Epoch 415/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3852e-04 - val_loss: 3.4318e-04\n",
      "Epoch 416/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3833e-04 - val_loss: 3.4444e-04\n",
      "Epoch 417/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3840e-04 - val_loss: 3.4370e-04\n",
      "Epoch 418/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3824e-04 - val_loss: 3.4317e-04\n",
      "Epoch 419/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3818e-04 - val_loss: 3.4438e-04\n",
      "Epoch 420/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3822e-04 - val_loss: 3.4416e-04\n",
      "Epoch 421/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3811e-04 - val_loss: 3.4297e-04\n",
      "Epoch 422/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3813e-04 - val_loss: 3.4351e-04\n",
      "Epoch 423/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3806e-04 - val_loss: 3.4297e-04\n",
      "Epoch 424/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3819e-04 - val_loss: 3.4330e-04\n",
      "Epoch 425/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3840e-04 - val_loss: 3.4485e-04\n",
      "Epoch 426/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3822e-04 - val_loss: 3.4452e-04\n",
      "Epoch 427/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3790e-04 - val_loss: 3.4388e-04\n",
      "Epoch 428/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3779e-04 - val_loss: 3.4401e-04\n",
      "Epoch 429/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3797e-04 - val_loss: 3.4298e-04\n",
      "Epoch 430/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3800e-04 - val_loss: 3.4373e-04\n",
      "Epoch 431/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.3779e-04 - val_loss: 3.4344e-04\n",
      "Epoch 432/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3768e-04 - val_loss: 3.4310e-04\n",
      "Epoch 433/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3762e-04 - val_loss: 3.4334e-04\n",
      "Epoch 434/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3771e-04 - val_loss: 3.4281e-04\n",
      "Epoch 435/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3770e-04 - val_loss: 3.4399e-04\n",
      "Epoch 436/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3758e-04 - val_loss: 3.4361e-04\n",
      "Epoch 437/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3755e-04 - val_loss: 3.4286e-04\n",
      "Epoch 438/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3749e-04 - val_loss: 3.4391e-04\n",
      "Epoch 439/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3748e-04 - val_loss: 3.4236e-04\n",
      "Epoch 440/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3723e-04 - val_loss: 3.4304e-04\n",
      "Epoch 441/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3752e-04 - val_loss: 3.4330e-04\n",
      "Epoch 442/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3764e-04 - val_loss: 3.4285e-04\n",
      "Epoch 443/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3733e-04 - val_loss: 3.4257e-04\n",
      "Epoch 444/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3747e-04 - val_loss: 3.4202e-04\n",
      "Epoch 445/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3722e-04 - val_loss: 3.4309e-04\n",
      "Epoch 446/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3725e-04 - val_loss: 3.4268e-04\n",
      "Epoch 447/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3731e-04 - val_loss: 3.4234e-04\n",
      "Epoch 448/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3720e-04 - val_loss: 3.4271e-04\n",
      "Epoch 449/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3714e-04 - val_loss: 3.4212e-04\n",
      "Epoch 450/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3735e-04 - val_loss: 3.4304e-04\n",
      "Epoch 451/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3716e-04 - val_loss: 3.4229e-04\n",
      "Epoch 452/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3710e-04 - val_loss: 3.4235e-04\n",
      "Epoch 453/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3709e-04 - val_loss: 3.4257e-04\n",
      "Epoch 454/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3722e-04 - val_loss: 3.4216e-04\n",
      "Epoch 455/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3695e-04 - val_loss: 3.4195e-04\n",
      "Epoch 456/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3692e-04 - val_loss: 3.4202e-04\n",
      "Epoch 457/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3679e-04 - val_loss: 3.4323e-04\n",
      "Epoch 458/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3694e-04 - val_loss: 3.4228e-04\n",
      "Epoch 459/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3673e-04 - val_loss: 3.4241e-04\n",
      "Epoch 460/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3677e-04 - val_loss: 3.4227e-04\n",
      "Epoch 461/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3664e-04 - val_loss: 3.4289e-04\n",
      "Epoch 462/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3660e-04 - val_loss: 3.4168e-04\n",
      "Epoch 463/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3683e-04 - val_loss: 3.4171e-04\n",
      "Epoch 464/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3673e-04 - val_loss: 3.4205e-04\n",
      "Epoch 465/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3666e-04 - val_loss: 3.4345e-04\n",
      "Epoch 466/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3666e-04 - val_loss: 3.4194e-04\n",
      "Epoch 467/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3658e-04 - val_loss: 3.4160e-04\n",
      "Epoch 468/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3645e-04 - val_loss: 3.4166e-04\n",
      "Epoch 469/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3636e-04 - val_loss: 3.4204e-04\n",
      "Epoch 470/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3648e-04 - val_loss: 3.4160e-04\n",
      "Epoch 471/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3643e-04 - val_loss: 3.4122e-04\n",
      "Epoch 472/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3640e-04 - val_loss: 3.4204e-04\n",
      "Epoch 473/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3607e-04 - val_loss: 3.4352e-04\n",
      "Epoch 474/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3643e-04 - val_loss: 3.4192e-04\n",
      "Epoch 475/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3620e-04 - val_loss: 3.4167e-04\n",
      "Epoch 476/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3610e-04 - val_loss: 3.4159e-04\n",
      "Epoch 477/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3618e-04 - val_loss: 3.4146e-04\n",
      "Epoch 478/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3618e-04 - val_loss: 3.4137e-04\n",
      "Epoch 479/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3595e-04 - val_loss: 3.4208e-04\n",
      "Epoch 480/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3613e-04 - val_loss: 3.4133e-04\n",
      "Epoch 481/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3603e-04 - val_loss: 3.4211e-04\n",
      "Epoch 482/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3616e-04 - val_loss: 3.4114e-04\n",
      "Epoch 483/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3606e-04 - val_loss: 3.4159e-04\n",
      "Epoch 484/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3601e-04 - val_loss: 3.4124e-04\n",
      "Epoch 485/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3576e-04 - val_loss: 3.4217e-04\n",
      "Epoch 486/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3577e-04 - val_loss: 3.4149e-04\n",
      "Epoch 487/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3572e-04 - val_loss: 3.4153e-04\n",
      "Epoch 488/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3574e-04 - val_loss: 3.4133e-04\n",
      "Epoch 489/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3579e-04 - val_loss: 3.4194e-04\n",
      "Epoch 490/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3565e-04 - val_loss: 3.4125e-04\n",
      "Epoch 491/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3567e-04 - val_loss: 3.4207e-04\n",
      "Epoch 492/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3582e-04 - val_loss: 3.4205e-04\n",
      "Epoch 493/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3576e-04 - val_loss: 3.4079e-04\n",
      "Epoch 494/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3569e-04 - val_loss: 3.4235e-04\n",
      "Epoch 495/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3540e-04 - val_loss: 3.4078e-04\n",
      "Epoch 496/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3550e-04 - val_loss: 3.4101e-04\n",
      "Epoch 497/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3578e-04 - val_loss: 3.4169e-04\n",
      "Epoch 498/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3553e-04 - val_loss: 3.4112e-04\n",
      "Epoch 499/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3525e-04 - val_loss: 3.4099e-04\n",
      "Epoch 500/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3546e-04 - val_loss: 3.4074e-04\n",
      "Epoch 501/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3546e-04 - val_loss: 3.4047e-04\n",
      "Epoch 502/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3505e-04 - val_loss: 3.4098e-04\n",
      "Epoch 503/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3535e-04 - val_loss: 3.4109e-04\n",
      "Epoch 504/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3520e-04 - val_loss: 3.4081e-04\n",
      "Epoch 505/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3513e-04 - val_loss: 3.4090e-04\n",
      "Epoch 506/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3508e-04 - val_loss: 3.4096e-04\n",
      "Epoch 507/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3502e-04 - val_loss: 3.4168e-04\n",
      "Epoch 508/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3518e-04 - val_loss: 3.4022e-04\n",
      "Epoch 509/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3514e-04 - val_loss: 3.4131e-04\n",
      "Epoch 510/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3520e-04 - val_loss: 3.4111e-04\n",
      "Epoch 511/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3495e-04 - val_loss: 3.4029e-04\n",
      "Epoch 512/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3481e-04 - val_loss: 3.4074e-04\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3475e-04 - val_loss: 3.4062e-04\n",
      "Epoch 514/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3478e-04 - val_loss: 3.4048e-04\n",
      "Epoch 515/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3492e-04 - val_loss: 3.4052e-04\n",
      "Epoch 516/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3476e-04 - val_loss: 3.4077e-04\n",
      "Epoch 517/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3480e-04 - val_loss: 3.4171e-04\n",
      "Epoch 518/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3483e-04 - val_loss: 3.3968e-04\n",
      "Epoch 519/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3494e-04 - val_loss: 3.4127e-04\n",
      "Epoch 520/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3458e-04 - val_loss: 3.4200e-04\n",
      "Epoch 521/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3472e-04 - val_loss: 3.3979e-04\n",
      "Epoch 522/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3448e-04 - val_loss: 3.4011e-04\n",
      "Epoch 523/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3467e-04 - val_loss: 3.4065e-04\n",
      "Epoch 524/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3463e-04 - val_loss: 3.4116e-04\n",
      "Epoch 525/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3448e-04 - val_loss: 3.4025e-04\n",
      "Epoch 526/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3454e-04 - val_loss: 3.3993e-04\n",
      "Epoch 527/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3434e-04 - val_loss: 3.4072e-04\n",
      "Epoch 528/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3444e-04 - val_loss: 3.3964e-04\n",
      "Epoch 529/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3441e-04 - val_loss: 3.3963e-04\n",
      "Epoch 530/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3422e-04 - val_loss: 3.4017e-04\n",
      "Epoch 531/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3442e-04 - val_loss: 3.4043e-04\n",
      "Epoch 532/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3435e-04 - val_loss: 3.4002e-04\n",
      "Epoch 533/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3406e-04 - val_loss: 3.4037e-04\n",
      "Epoch 534/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3430e-04 - val_loss: 3.4200e-04\n",
      "Epoch 535/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3425e-04 - val_loss: 3.4020e-04\n",
      "Epoch 536/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3407e-04 - val_loss: 3.3985e-04\n",
      "Epoch 537/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3410e-04 - val_loss: 3.3987e-04\n",
      "Epoch 538/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3413e-04 - val_loss: 3.3997e-04\n",
      "Epoch 539/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3408e-04 - val_loss: 3.4009e-04\n",
      "Epoch 540/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3411e-04 - val_loss: 3.3930e-04\n",
      "Epoch 541/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3387e-04 - val_loss: 3.3962e-04\n",
      "Epoch 542/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3386e-04 - val_loss: 3.3954e-04\n",
      "Epoch 543/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3398e-04 - val_loss: 3.4127e-04\n",
      "Epoch 544/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3386e-04 - val_loss: 3.4004e-04\n",
      "Epoch 545/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3379e-04 - val_loss: 3.3983e-04\n",
      "Epoch 546/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3367e-04 - val_loss: 3.4045e-04\n",
      "Epoch 547/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3373e-04 - val_loss: 3.4013e-04\n",
      "Epoch 548/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3397e-04 - val_loss: 3.3986e-04\n",
      "Epoch 549/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3366e-04 - val_loss: 3.3977e-04\n",
      "Epoch 550/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3356e-04 - val_loss: 3.4050e-04\n",
      "Epoch 551/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3352e-04 - val_loss: 3.3989e-04\n",
      "Epoch 552/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3364e-04 - val_loss: 3.4015e-04\n",
      "Epoch 553/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3361e-04 - val_loss: 3.3956e-04\n",
      "Epoch 554/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3367e-04 - val_loss: 3.3920e-04\n",
      "Epoch 555/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3353e-04 - val_loss: 3.4138e-04\n",
      "Epoch 556/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3362e-04 - val_loss: 3.3955e-04\n",
      "Epoch 557/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3332e-04 - val_loss: 3.3968e-04\n",
      "Epoch 558/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3330e-04 - val_loss: 3.3938e-04\n",
      "Epoch 559/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3329e-04 - val_loss: 3.3872e-04\n",
      "Epoch 560/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3315e-04 - val_loss: 3.3957e-04\n",
      "Epoch 561/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3338e-04 - val_loss: 3.3985e-04\n",
      "Epoch 562/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3352e-04 - val_loss: 3.3911e-04\n",
      "Epoch 563/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3311e-04 - val_loss: 3.4013e-04\n",
      "Epoch 564/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3321e-04 - val_loss: 3.3922e-04\n",
      "Epoch 565/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3291e-04 - val_loss: 3.3903e-04\n",
      "Epoch 566/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3323e-04 - val_loss: 3.3859e-04\n",
      "Epoch 567/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3305e-04 - val_loss: 3.3875e-04\n",
      "Epoch 568/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3300e-04 - val_loss: 3.4082e-04\n",
      "Epoch 569/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3295e-04 - val_loss: 3.3878e-04\n",
      "Epoch 570/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3307e-04 - val_loss: 3.3915e-04\n",
      "Epoch 571/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3279e-04 - val_loss: 3.3951e-04\n",
      "Epoch 572/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3295e-04 - val_loss: 3.3953e-04\n",
      "Epoch 573/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3294e-04 - val_loss: 3.3842e-04\n",
      "Epoch 574/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3276e-04 - val_loss: 3.3869e-04\n",
      "Epoch 575/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3298e-04 - val_loss: 3.3857e-04\n",
      "Epoch 576/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3286e-04 - val_loss: 3.3900e-04\n",
      "Epoch 577/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3250e-04 - val_loss: 3.3877e-04\n",
      "Epoch 578/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3253e-04 - val_loss: 3.3873e-04\n",
      "Epoch 579/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3285e-04 - val_loss: 3.3896e-04\n",
      "Epoch 580/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3266e-04 - val_loss: 3.3892e-04\n",
      "Epoch 581/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3262e-04 - val_loss: 3.3854e-04\n",
      "Epoch 582/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3252e-04 - val_loss: 3.3953e-04\n",
      "Epoch 583/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3256e-04 - val_loss: 3.3856e-04\n",
      "Epoch 584/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3255e-04 - val_loss: 3.3886e-04\n",
      "Epoch 585/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3253e-04 - val_loss: 3.3864e-04\n",
      "Epoch 586/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3246e-04 - val_loss: 3.3828e-04\n",
      "Epoch 587/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3243e-04 - val_loss: 3.3896e-04\n",
      "Epoch 588/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3249e-04 - val_loss: 3.3821e-04\n",
      "Epoch 589/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3234e-04 - val_loss: 3.3911e-04\n",
      "Epoch 590/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.3224e-04 - val_loss: 3.3934e-04\n",
      "Epoch 591/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3224e-04 - val_loss: 3.3953e-04\n",
      "Epoch 592/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3225e-04 - val_loss: 3.3945e-04\n",
      "Epoch 593/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3209e-04 - val_loss: 3.3806e-04\n",
      "Epoch 594/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3208e-04 - val_loss: 3.3852e-04\n",
      "Epoch 595/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3230e-04 - val_loss: 3.3815e-04\n",
      "Epoch 596/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3209e-04 - val_loss: 3.3790e-04\n",
      "Epoch 597/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3217e-04 - val_loss: 3.3827e-04\n",
      "Epoch 598/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3194e-04 - val_loss: 3.3822e-04\n",
      "Epoch 599/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3196e-04 - val_loss: 3.3863e-04\n",
      "Epoch 600/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3217e-04 - val_loss: 3.3915e-04\n",
      "Epoch 601/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3183e-04 - val_loss: 3.3797e-04\n",
      "Epoch 602/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3177e-04 - val_loss: 3.3796e-04\n",
      "Epoch 603/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3200e-04 - val_loss: 3.3769e-04\n",
      "Epoch 604/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3194e-04 - val_loss: 3.3852e-04\n",
      "Epoch 605/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3189e-04 - val_loss: 3.3891e-04\n",
      "Epoch 606/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3156e-04 - val_loss: 3.3837e-04\n",
      "Epoch 607/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3192e-04 - val_loss: 3.3785e-04\n",
      "Epoch 608/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3199e-04 - val_loss: 3.3809e-04\n",
      "Epoch 609/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3174e-04 - val_loss: 3.3802e-04\n",
      "Epoch 610/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3172e-04 - val_loss: 3.3814e-04\n",
      "Epoch 611/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3147e-04 - val_loss: 3.3904e-04\n",
      "Epoch 612/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3156e-04 - val_loss: 3.3885e-04\n",
      "Epoch 613/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3171e-04 - val_loss: 3.3812e-04\n",
      "Epoch 614/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3147e-04 - val_loss: 3.3799e-04\n",
      "Epoch 615/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3134e-04 - val_loss: 3.3746e-04\n",
      "Epoch 616/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3133e-04 - val_loss: 3.3784e-04\n",
      "Epoch 617/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3153e-04 - val_loss: 3.3837e-04\n",
      "Epoch 618/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3145e-04 - val_loss: 3.3878e-04\n",
      "Epoch 619/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3128e-04 - val_loss: 3.3871e-04\n",
      "Epoch 620/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3140e-04 - val_loss: 3.3851e-04\n",
      "Epoch 621/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3131e-04 - val_loss: 3.3768e-04\n",
      "Epoch 622/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3141e-04 - val_loss: 3.3844e-04\n",
      "Epoch 623/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3121e-04 - val_loss: 3.3752e-04\n",
      "Epoch 624/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3126e-04 - val_loss: 3.3809e-04\n",
      "Epoch 625/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3123e-04 - val_loss: 3.3821e-04\n",
      "Epoch 626/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3138e-04 - val_loss: 3.3779e-04\n",
      "Epoch 627/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3096e-04 - val_loss: 3.3725e-04\n",
      "Epoch 628/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3099e-04 - val_loss: 3.3717e-04\n",
      "Epoch 629/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3115e-04 - val_loss: 3.3784e-04\n",
      "Epoch 630/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3098e-04 - val_loss: 3.3774e-04\n",
      "Epoch 631/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3090e-04 - val_loss: 3.3769e-04\n",
      "Epoch 632/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3084e-04 - val_loss: 3.3641e-04\n",
      "Epoch 633/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3092e-04 - val_loss: 3.3689e-04\n",
      "Epoch 634/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3104e-04 - val_loss: 3.3697e-04\n",
      "Epoch 635/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3080e-04 - val_loss: 3.3776e-04\n",
      "Epoch 636/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3087e-04 - val_loss: 3.3737e-04\n",
      "Epoch 637/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3074e-04 - val_loss: 3.3753e-04\n",
      "Epoch 638/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3084e-04 - val_loss: 3.3763e-04\n",
      "Epoch 639/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3083e-04 - val_loss: 3.3783e-04\n",
      "Epoch 640/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3105e-04 - val_loss: 3.3708e-04\n",
      "Epoch 641/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3064e-04 - val_loss: 3.3664e-04\n",
      "Epoch 642/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3044e-04 - val_loss: 3.3707e-04\n",
      "Epoch 643/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3067e-04 - val_loss: 3.3710e-04\n",
      "Epoch 644/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3055e-04 - val_loss: 3.3696e-04\n",
      "Epoch 645/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3050e-04 - val_loss: 3.3767e-04\n",
      "Epoch 646/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3046e-04 - val_loss: 3.3820e-04\n",
      "Epoch 647/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3059e-04 - val_loss: 3.3746e-04\n",
      "Epoch 648/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3031e-04 - val_loss: 3.3789e-04\n",
      "Epoch 649/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3037e-04 - val_loss: 3.3664e-04\n",
      "Epoch 650/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3058e-04 - val_loss: 3.3730e-04\n",
      "Epoch 651/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3043e-04 - val_loss: 3.3655e-04\n",
      "Epoch 652/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3016e-04 - val_loss: 3.3658e-04\n",
      "Epoch 653/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3039e-04 - val_loss: 3.3718e-04\n",
      "Epoch 654/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3031e-04 - val_loss: 3.3637e-04\n",
      "Epoch 655/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3015e-04 - val_loss: 3.3652e-04\n",
      "Epoch 656/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3011e-04 - val_loss: 3.3704e-04\n",
      "Epoch 657/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3041e-04 - val_loss: 3.3642e-04\n",
      "Epoch 658/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3012e-04 - val_loss: 3.3713e-04\n",
      "Epoch 659/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3002e-04 - val_loss: 3.3630e-04\n",
      "Epoch 660/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3012e-04 - val_loss: 3.3652e-04\n",
      "Epoch 661/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3013e-04 - val_loss: 3.3669e-04\n",
      "Epoch 662/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2983e-04 - val_loss: 3.3681e-04\n",
      "Epoch 663/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3017e-04 - val_loss: 3.3677e-04\n",
      "Epoch 664/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2999e-04 - val_loss: 3.3572e-04\n",
      "Epoch 665/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2996e-04 - val_loss: 3.3659e-04\n",
      "Epoch 666/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2983e-04 - val_loss: 3.3624e-04\n",
      "Epoch 667/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2989e-04 - val_loss: 3.3616e-04\n",
      "Epoch 668/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2967e-04 - val_loss: 3.3636e-04\n",
      "Epoch 669/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2965e-04 - val_loss: 3.3592e-04\n",
      "Epoch 670/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3006e-04 - val_loss: 3.3698e-04\n",
      "Epoch 671/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2990e-04 - val_loss: 3.3669e-04\n",
      "Epoch 672/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2988e-04 - val_loss: 3.3733e-04\n",
      "Epoch 673/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2981e-04 - val_loss: 3.3763e-04\n",
      "Epoch 674/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2981e-04 - val_loss: 3.3561e-04\n",
      "Epoch 675/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2955e-04 - val_loss: 3.3643e-04\n",
      "Epoch 676/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2966e-04 - val_loss: 3.3616e-04\n",
      "Epoch 677/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2958e-04 - val_loss: 3.3737e-04\n",
      "Epoch 678/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2975e-04 - val_loss: 3.3590e-04\n",
      "Epoch 679/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2944e-04 - val_loss: 3.3602e-04\n",
      "Epoch 680/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2951e-04 - val_loss: 3.3581e-04\n",
      "Epoch 681/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2929e-04 - val_loss: 3.3658e-04\n",
      "Epoch 682/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2936e-04 - val_loss: 3.3601e-04\n",
      "Epoch 683/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2940e-04 - val_loss: 3.3586e-04\n",
      "Epoch 684/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2946e-04 - val_loss: 3.3576e-04\n",
      "Epoch 685/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2934e-04 - val_loss: 3.3539e-04\n",
      "Epoch 686/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2935e-04 - val_loss: 3.3589e-04\n",
      "Epoch 687/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2941e-04 - val_loss: 3.3637e-04\n",
      "Epoch 688/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2957e-04 - val_loss: 3.3621e-04\n",
      "Epoch 689/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2927e-04 - val_loss: 3.3565e-04\n",
      "Epoch 690/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2914e-04 - val_loss: 3.3695e-04\n",
      "Epoch 691/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2920e-04 - val_loss: 3.3583e-04\n",
      "Epoch 692/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2908e-04 - val_loss: 3.3667e-04\n",
      "Epoch 693/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2934e-04 - val_loss: 3.3527e-04\n",
      "Epoch 694/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2897e-04 - val_loss: 3.3683e-04\n",
      "Epoch 695/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2915e-04 - val_loss: 3.3671e-04\n",
      "Epoch 696/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2889e-04 - val_loss: 3.3537e-04\n",
      "Epoch 697/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2912e-04 - val_loss: 3.3688e-04\n",
      "Epoch 698/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2901e-04 - val_loss: 3.3572e-04\n",
      "Epoch 699/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2906e-04 - val_loss: 3.3562e-04\n",
      "Epoch 700/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2882e-04 - val_loss: 3.3503e-04\n",
      "Epoch 701/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2899e-04 - val_loss: 3.3518e-04\n",
      "Epoch 702/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2876e-04 - val_loss: 3.3590e-04\n",
      "Epoch 703/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2859e-04 - val_loss: 3.3600e-04\n",
      "Epoch 704/1000\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 3.2885e-04 - val_loss: 3.3474e-04\n",
      "Epoch 705/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2875e-04 - val_loss: 3.3633e-04\n",
      "Epoch 706/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2877e-04 - val_loss: 3.3618e-04\n",
      "Epoch 707/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2873e-04 - val_loss: 3.3608e-04\n",
      "Epoch 708/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2896e-04 - val_loss: 3.3542e-04\n",
      "Epoch 709/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2841e-04 - val_loss: 3.3520e-04\n",
      "Epoch 710/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2856e-04 - val_loss: 3.3487e-04\n",
      "Epoch 711/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2858e-04 - val_loss: 3.3474e-04\n",
      "Epoch 712/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2865e-04 - val_loss: 3.3617e-04\n",
      "Epoch 713/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2844e-04 - val_loss: 3.3587e-04\n",
      "Epoch 714/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2862e-04 - val_loss: 3.3456e-04\n",
      "Epoch 715/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2836e-04 - val_loss: 3.3461e-04\n",
      "Epoch 716/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2843e-04 - val_loss: 3.3462e-04\n",
      "Epoch 717/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2866e-04 - val_loss: 3.3453e-04\n",
      "Epoch 718/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2830e-04 - val_loss: 3.3511e-04\n",
      "Epoch 719/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2850e-04 - val_loss: 3.3510e-04\n",
      "Epoch 720/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2813e-04 - val_loss: 3.3460e-04\n",
      "Epoch 721/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2828e-04 - val_loss: 3.3500e-04\n",
      "Epoch 722/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2826e-04 - val_loss: 3.3515e-04\n",
      "Epoch 723/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2815e-04 - val_loss: 3.3460e-04\n",
      "Epoch 724/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2802e-04 - val_loss: 3.3506e-04\n",
      "Epoch 725/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2818e-04 - val_loss: 3.3442e-04\n",
      "Epoch 726/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2795e-04 - val_loss: 3.3433e-04\n",
      "Epoch 727/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2831e-04 - val_loss: 3.3440e-04\n",
      "Epoch 728/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2811e-04 - val_loss: 3.3386e-04\n",
      "Epoch 729/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2802e-04 - val_loss: 3.3475e-04\n",
      "Epoch 730/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2803e-04 - val_loss: 3.3466e-04\n",
      "Epoch 731/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2801e-04 - val_loss: 3.3403e-04\n",
      "Epoch 732/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2810e-04 - val_loss: 3.3441e-04\n",
      "Epoch 733/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2769e-04 - val_loss: 3.3377e-04\n",
      "Epoch 734/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2790e-04 - val_loss: 3.3447e-04\n",
      "Epoch 735/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2823e-04 - val_loss: 3.3523e-04\n",
      "Epoch 736/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2768e-04 - val_loss: 3.3469e-04\n",
      "Epoch 737/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2784e-04 - val_loss: 3.3469e-04\n",
      "Epoch 738/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2766e-04 - val_loss: 3.3563e-04\n",
      "Epoch 739/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2790e-04 - val_loss: 3.3433e-04\n",
      "Epoch 740/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2757e-04 - val_loss: 3.3580e-04\n",
      "Epoch 741/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2769e-04 - val_loss: 3.3394e-04\n",
      "Epoch 742/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2773e-04 - val_loss: 3.3416e-04\n",
      "Epoch 743/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2798e-04 - val_loss: 3.3427e-04\n",
      "Epoch 744/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2751e-04 - val_loss: 3.3438e-04\n",
      "Epoch 745/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2757e-04 - val_loss: 3.3397e-04\n",
      "Epoch 746/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2755e-04 - val_loss: 3.3453e-04\n",
      "Epoch 747/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2736e-04 - val_loss: 3.3422e-04\n",
      "Epoch 748/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2771e-04 - val_loss: 3.3452e-04\n",
      "Epoch 749/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2752e-04 - val_loss: 3.3456e-04\n",
      "Epoch 750/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2767e-04 - val_loss: 3.3522e-04\n",
      "Epoch 751/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2737e-04 - val_loss: 3.3438e-04\n",
      "Epoch 752/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2718e-04 - val_loss: 3.3475e-04\n",
      "Epoch 753/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2741e-04 - val_loss: 3.3396e-04\n",
      "Epoch 754/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2760e-04 - val_loss: 3.3403e-04\n",
      "Epoch 755/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2724e-04 - val_loss: 3.3428e-04\n",
      "Epoch 756/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2782e-04 - val_loss: 3.3345e-04\n",
      "Epoch 757/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2707e-04 - val_loss: 3.3367e-04\n",
      "Epoch 758/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2711e-04 - val_loss: 3.3381e-04\n",
      "Epoch 759/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2714e-04 - val_loss: 3.3341e-04\n",
      "Epoch 760/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2720e-04 - val_loss: 3.3360e-04\n",
      "Epoch 761/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2698e-04 - val_loss: 3.3428e-04\n",
      "Epoch 762/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2711e-04 - val_loss: 3.3342e-04\n",
      "Epoch 763/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2674e-04 - val_loss: 3.3423e-04\n",
      "Epoch 764/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2729e-04 - val_loss: 3.3412e-04\n",
      "Epoch 765/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2697e-04 - val_loss: 3.3306e-04\n",
      "Epoch 766/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2664e-04 - val_loss: 3.3407e-04\n",
      "Epoch 767/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2695e-04 - val_loss: 3.3355e-04\n",
      "Epoch 768/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2678e-04 - val_loss: 3.3404e-04\n",
      "Epoch 769/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2706e-04 - val_loss: 3.3367e-04\n",
      "Epoch 770/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2676e-04 - val_loss: 3.3465e-04\n",
      "Epoch 771/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2703e-04 - val_loss: 3.3431e-04\n",
      "Epoch 772/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2671e-04 - val_loss: 3.3347e-04\n",
      "Epoch 773/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2665e-04 - val_loss: 3.3358e-04\n",
      "Epoch 774/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2673e-04 - val_loss: 3.3411e-04\n",
      "Epoch 775/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2665e-04 - val_loss: 3.3386e-04\n",
      "Epoch 776/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2681e-04 - val_loss: 3.3327e-04\n",
      "Epoch 777/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2659e-04 - val_loss: 3.3323e-04\n",
      "Epoch 778/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2653e-04 - val_loss: 3.3335e-04\n",
      "Epoch 779/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2644e-04 - val_loss: 3.3318e-04\n",
      "Epoch 780/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2658e-04 - val_loss: 3.3331e-04\n",
      "Epoch 781/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2673e-04 - val_loss: 3.3348e-04\n",
      "Epoch 782/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2688e-04 - val_loss: 3.3384e-04\n",
      "Epoch 783/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2645e-04 - val_loss: 3.3457e-04\n",
      "Epoch 784/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2668e-04 - val_loss: 3.3313e-04\n",
      "Epoch 785/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2632e-04 - val_loss: 3.3312e-04\n",
      "Epoch 786/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2644e-04 - val_loss: 3.3294e-04\n",
      "Epoch 787/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2628e-04 - val_loss: 3.3332e-04\n",
      "Epoch 788/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2624e-04 - val_loss: 3.3310e-04\n",
      "Epoch 789/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2618e-04 - val_loss: 3.3355e-04\n",
      "Epoch 790/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2622e-04 - val_loss: 3.3327e-04\n",
      "Epoch 791/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2607e-04 - val_loss: 3.3336e-04\n",
      "Epoch 792/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2596e-04 - val_loss: 3.3408e-04\n",
      "Epoch 793/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2609e-04 - val_loss: 3.3304e-04\n",
      "Epoch 794/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2604e-04 - val_loss: 3.3371e-04\n",
      "Epoch 795/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2606e-04 - val_loss: 3.3334e-04\n",
      "Epoch 796/1000\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 3.2604e-04 - val_loss: 3.3238e-04\n",
      "Epoch 797/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2586e-04 - val_loss: 3.3318e-04\n",
      "Epoch 798/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2606e-04 - val_loss: 3.3309e-04\n",
      "Epoch 799/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2634e-04 - val_loss: 3.3286e-04\n",
      "Epoch 800/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2601e-04 - val_loss: 3.3278e-04\n",
      "Epoch 801/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2598e-04 - val_loss: 3.3321e-04\n",
      "Epoch 802/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2589e-04 - val_loss: 3.3325e-04\n",
      "Epoch 803/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2573e-04 - val_loss: 3.3294e-04\n",
      "Epoch 804/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2585e-04 - val_loss: 3.3332e-04\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2617e-04 - val_loss: 3.3306e-04\n",
      "Epoch 806/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2587e-04 - val_loss: 3.3303e-04\n",
      "Epoch 807/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2606e-04 - val_loss: 3.3434e-04\n",
      "Epoch 808/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2577e-04 - val_loss: 3.3252e-04\n",
      "Epoch 809/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2576e-04 - val_loss: 3.3237e-04\n",
      "Epoch 810/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2566e-04 - val_loss: 3.3295e-04\n",
      "Epoch 811/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2578e-04 - val_loss: 3.3236e-04\n",
      "Epoch 812/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2576e-04 - val_loss: 3.3328e-04\n",
      "Epoch 813/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2561e-04 - val_loss: 3.3280e-04\n",
      "Epoch 814/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2555e-04 - val_loss: 3.3294e-04\n",
      "Epoch 815/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2548e-04 - val_loss: 3.3306e-04\n",
      "Epoch 816/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2553e-04 - val_loss: 3.3245e-04\n",
      "Epoch 817/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2541e-04 - val_loss: 3.3183e-04\n",
      "Epoch 818/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2545e-04 - val_loss: 3.3222e-04\n",
      "Epoch 819/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2559e-04 - val_loss: 3.3381e-04\n",
      "Epoch 820/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2572e-04 - val_loss: 3.3308e-04\n",
      "Epoch 821/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2547e-04 - val_loss: 3.3206e-04\n",
      "Epoch 822/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2539e-04 - val_loss: 3.3261e-04\n",
      "Epoch 823/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2550e-04 - val_loss: 3.3200e-04\n",
      "Epoch 824/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2542e-04 - val_loss: 3.3266e-04\n",
      "Epoch 825/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2523e-04 - val_loss: 3.3216e-04\n",
      "Epoch 826/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2528e-04 - val_loss: 3.3209e-04\n",
      "Epoch 827/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2512e-04 - val_loss: 3.3217e-04\n",
      "Epoch 828/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2511e-04 - val_loss: 3.3215e-04\n",
      "Epoch 829/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2495e-04 - val_loss: 3.3157e-04\n",
      "Epoch 830/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2515e-04 - val_loss: 3.3198e-04\n",
      "Epoch 831/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2509e-04 - val_loss: 3.3245e-04\n",
      "Epoch 832/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2511e-04 - val_loss: 3.3356e-04\n",
      "Epoch 833/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2509e-04 - val_loss: 3.3309e-04\n",
      "Epoch 834/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2510e-04 - val_loss: 3.3229e-04\n",
      "Epoch 835/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2508e-04 - val_loss: 3.3498e-04\n",
      "Epoch 836/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2502e-04 - val_loss: 3.3212e-04\n",
      "Epoch 837/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2495e-04 - val_loss: 3.3241e-04\n",
      "Epoch 838/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2468e-04 - val_loss: 3.3229e-04\n",
      "Epoch 839/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2494e-04 - val_loss: 3.3271e-04\n",
      "Epoch 840/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2489e-04 - val_loss: 3.3202e-04\n",
      "Epoch 841/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2514e-04 - val_loss: 3.3260e-04\n",
      "Epoch 842/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2481e-04 - val_loss: 3.3235e-04\n",
      "Epoch 843/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2464e-04 - val_loss: 3.3226e-04\n",
      "Epoch 844/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2471e-04 - val_loss: 3.3281e-04\n",
      "Epoch 845/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2472e-04 - val_loss: 3.3171e-04\n",
      "Epoch 846/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2476e-04 - val_loss: 3.3159e-04\n",
      "Epoch 847/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2481e-04 - val_loss: 3.3265e-04\n",
      "Epoch 848/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2494e-04 - val_loss: 3.3121e-04\n",
      "Epoch 849/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2469e-04 - val_loss: 3.3206e-04\n",
      "Epoch 850/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2437e-04 - val_loss: 3.3174e-04\n",
      "Epoch 851/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2459e-04 - val_loss: 3.3167e-04\n",
      "Epoch 852/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2453e-04 - val_loss: 3.3350e-04\n",
      "Epoch 853/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2460e-04 - val_loss: 3.3227e-04\n",
      "Epoch 854/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2440e-04 - val_loss: 3.3242e-04\n",
      "Epoch 855/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2445e-04 - val_loss: 3.3186e-04\n",
      "Epoch 856/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2431e-04 - val_loss: 3.3241e-04\n",
      "Epoch 857/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2489e-04 - val_loss: 3.3179e-04\n",
      "Epoch 858/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2441e-04 - val_loss: 3.3304e-04\n",
      "Epoch 859/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2421e-04 - val_loss: 3.3131e-04\n",
      "Epoch 860/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2417e-04 - val_loss: 3.3235e-04\n",
      "Epoch 861/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2448e-04 - val_loss: 3.3165e-04\n",
      "Epoch 862/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2419e-04 - val_loss: 3.3126e-04\n",
      "Epoch 863/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2415e-04 - val_loss: 3.3112e-04\n",
      "Epoch 864/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2425e-04 - val_loss: 3.3162e-04\n",
      "Epoch 865/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2403e-04 - val_loss: 3.3111e-04\n",
      "Epoch 866/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2409e-04 - val_loss: 3.3215e-04\n",
      "Epoch 867/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2428e-04 - val_loss: 3.3105e-04\n",
      "Epoch 868/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2431e-04 - val_loss: 3.3091e-04\n",
      "Epoch 869/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2404e-04 - val_loss: 3.3184e-04\n",
      "Epoch 870/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2415e-04 - val_loss: 3.3116e-04\n",
      "Epoch 871/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2423e-04 - val_loss: 3.3220e-04\n",
      "Epoch 872/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2374e-04 - val_loss: 3.3116e-04\n",
      "Epoch 873/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2430e-04 - val_loss: 3.3097e-04\n",
      "Epoch 874/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2422e-04 - val_loss: 3.3117e-04\n",
      "Epoch 875/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2394e-04 - val_loss: 3.3035e-04\n",
      "Epoch 876/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2387e-04 - val_loss: 3.3185e-04\n",
      "Epoch 877/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2383e-04 - val_loss: 3.3210e-04\n",
      "Epoch 878/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2404e-04 - val_loss: 3.3146e-04\n",
      "Epoch 879/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2380e-04 - val_loss: 3.3123e-04\n",
      "Epoch 880/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2372e-04 - val_loss: 3.3169e-04\n",
      "Epoch 881/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2370e-04 - val_loss: 3.3169e-04\n",
      "Epoch 882/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2389e-04 - val_loss: 3.3126e-04\n",
      "Epoch 883/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2363e-04 - val_loss: 3.3110e-04\n",
      "Epoch 884/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2349e-04 - val_loss: 3.3125e-04\n",
      "Epoch 885/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2376e-04 - val_loss: 3.3150e-04\n",
      "Epoch 886/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2346e-04 - val_loss: 3.3117e-04\n",
      "Epoch 887/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2376e-04 - val_loss: 3.3069e-04\n",
      "Epoch 888/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2343e-04 - val_loss: 3.3035e-04\n",
      "Epoch 889/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2340e-04 - val_loss: 3.3163e-04\n",
      "Epoch 890/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2352e-04 - val_loss: 3.3040e-04\n",
      "Epoch 891/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2361e-04 - val_loss: 3.3095e-04\n",
      "Epoch 892/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2337e-04 - val_loss: 3.3034e-04\n",
      "Epoch 893/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2362e-04 - val_loss: 3.3178e-04\n",
      "Epoch 894/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2338e-04 - val_loss: 3.3084e-04\n",
      "Epoch 895/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2338e-04 - val_loss: 3.3086e-04\n",
      "Epoch 896/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2339e-04 - val_loss: 3.3233e-04\n",
      "Epoch 897/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2353e-04 - val_loss: 3.3135e-04\n",
      "Epoch 898/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2318e-04 - val_loss: 3.3122e-04\n",
      "Epoch 899/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2311e-04 - val_loss: 3.3037e-04\n",
      "Epoch 900/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2324e-04 - val_loss: 3.3017e-04\n",
      "Epoch 901/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2319e-04 - val_loss: 3.3017e-04\n",
      "Epoch 902/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2302e-04 - val_loss: 3.3142e-04\n",
      "Epoch 903/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2303e-04 - val_loss: 3.3026e-04\n",
      "Epoch 904/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2325e-04 - val_loss: 3.3130e-04\n",
      "Epoch 905/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2317e-04 - val_loss: 3.3055e-04\n",
      "Epoch 906/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2317e-04 - val_loss: 3.3052e-04\n",
      "Epoch 907/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2301e-04 - val_loss: 3.3141e-04\n",
      "Epoch 908/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2305e-04 - val_loss: 3.3017e-04\n",
      "Epoch 909/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2318e-04 - val_loss: 3.3137e-04\n",
      "Epoch 910/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2281e-04 - val_loss: 3.3104e-04\n",
      "Epoch 911/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2298e-04 - val_loss: 3.3281e-04\n",
      "Epoch 912/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2329e-04 - val_loss: 3.3029e-04\n",
      "Epoch 913/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2293e-04 - val_loss: 3.3085e-04\n",
      "Epoch 914/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2302e-04 - val_loss: 3.3022e-04\n",
      "Epoch 915/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2266e-04 - val_loss: 3.2994e-04\n",
      "Epoch 916/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2287e-04 - val_loss: 3.2999e-04\n",
      "Epoch 917/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2297e-04 - val_loss: 3.3074e-04\n",
      "Epoch 918/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2275e-04 - val_loss: 3.2937e-04\n",
      "Epoch 919/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2280e-04 - val_loss: 3.2959e-04\n",
      "Epoch 920/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2284e-04 - val_loss: 3.2985e-04\n",
      "Epoch 921/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2294e-04 - val_loss: 3.3018e-04\n",
      "Epoch 922/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2270e-04 - val_loss: 3.3015e-04\n",
      "Epoch 923/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2250e-04 - val_loss: 3.3104e-04\n",
      "Epoch 924/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2245e-04 - val_loss: 3.2950e-04\n",
      "Epoch 925/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2294e-04 - val_loss: 3.2995e-04\n",
      "Epoch 926/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2257e-04 - val_loss: 3.3089e-04\n",
      "Epoch 927/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2254e-04 - val_loss: 3.2952e-04\n",
      "Epoch 928/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2238e-04 - val_loss: 3.3033e-04\n",
      "Epoch 929/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2258e-04 - val_loss: 3.3004e-04\n",
      "Epoch 930/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2244e-04 - val_loss: 3.3005e-04\n",
      "Epoch 931/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2236e-04 - val_loss: 3.3067e-04\n",
      "Epoch 932/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2219e-04 - val_loss: 3.2981e-04\n",
      "Epoch 933/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2253e-04 - val_loss: 3.3146e-04\n",
      "Epoch 934/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2252e-04 - val_loss: 3.3007e-04\n",
      "Epoch 935/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2251e-04 - val_loss: 3.2989e-04\n",
      "Epoch 936/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2252e-04 - val_loss: 3.3006e-04\n",
      "Epoch 937/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2239e-04 - val_loss: 3.3003e-04\n",
      "Epoch 938/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2203e-04 - val_loss: 3.2950e-04\n",
      "Epoch 939/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2206e-04 - val_loss: 3.3091e-04\n",
      "Epoch 940/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2239e-04 - val_loss: 3.2958e-04\n",
      "Epoch 941/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2253e-04 - val_loss: 3.3048e-04\n",
      "Epoch 942/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2219e-04 - val_loss: 3.2977e-04\n",
      "Epoch 943/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2219e-04 - val_loss: 3.3034e-04\n",
      "Epoch 944/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2237e-04 - val_loss: 3.2967e-04\n",
      "Epoch 945/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2213e-04 - val_loss: 3.3025e-04\n",
      "Epoch 946/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2205e-04 - val_loss: 3.3005e-04\n",
      "Epoch 947/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2231e-04 - val_loss: 3.3107e-04\n",
      "Epoch 948/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2218e-04 - val_loss: 3.2965e-04\n",
      "Epoch 949/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2191e-04 - val_loss: 3.2971e-04\n",
      "Epoch 950/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2207e-04 - val_loss: 3.3107e-04\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2200e-04 - val_loss: 3.3010e-04\n",
      "Epoch 952/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2173e-04 - val_loss: 3.2957e-04\n",
      "Epoch 953/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2207e-04 - val_loss: 3.2964e-04\n",
      "Epoch 954/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2171e-04 - val_loss: 3.2944e-04\n",
      "Epoch 955/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2241e-04 - val_loss: 3.2905e-04\n",
      "Epoch 956/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2175e-04 - val_loss: 3.2971e-04\n",
      "Epoch 957/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2202e-04 - val_loss: 3.3145e-04\n",
      "Epoch 958/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2176e-04 - val_loss: 3.2922e-04\n",
      "Epoch 959/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2181e-04 - val_loss: 3.2957e-04\n",
      "Epoch 960/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2154e-04 - val_loss: 3.3082e-04\n",
      "Epoch 961/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2170e-04 - val_loss: 3.2956e-04\n",
      "Epoch 962/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2175e-04 - val_loss: 3.2987e-04\n",
      "Epoch 963/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2153e-04 - val_loss: 3.2926e-04\n",
      "Epoch 964/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2173e-04 - val_loss: 3.2989e-04\n",
      "Epoch 965/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2166e-04 - val_loss: 3.2897e-04\n",
      "Epoch 966/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2167e-04 - val_loss: 3.2987e-04\n",
      "Epoch 967/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2185e-04 - val_loss: 3.2943e-04\n",
      "Epoch 968/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2169e-04 - val_loss: 3.2898e-04\n",
      "Epoch 969/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2152e-04 - val_loss: 3.2957e-04\n",
      "Epoch 970/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2150e-04 - val_loss: 3.2928e-04\n",
      "Epoch 971/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2136e-04 - val_loss: 3.3045e-04\n",
      "Epoch 972/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2156e-04 - val_loss: 3.2911e-04\n",
      "Epoch 973/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2132e-04 - val_loss: 3.2910e-04\n",
      "Epoch 974/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2118e-04 - val_loss: 3.2933e-04\n",
      "Epoch 975/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2123e-04 - val_loss: 3.2927e-04\n",
      "Epoch 976/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2137e-04 - val_loss: 3.2890e-04\n",
      "Epoch 977/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2150e-04 - val_loss: 3.2975e-04\n",
      "Epoch 978/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2171e-04 - val_loss: 3.2950e-04\n",
      "Epoch 979/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2118e-04 - val_loss: 3.2941e-04\n",
      "Epoch 980/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2105e-04 - val_loss: 3.2912e-04\n",
      "Epoch 981/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2098e-04 - val_loss: 3.2922e-04\n",
      "Epoch 982/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2126e-04 - val_loss: 3.2868e-04\n",
      "Epoch 983/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2110e-04 - val_loss: 3.2980e-04\n",
      "Epoch 984/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2110e-04 - val_loss: 3.2994e-04\n",
      "Epoch 985/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2121e-04 - val_loss: 3.2936e-04\n",
      "Epoch 986/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2128e-04 - val_loss: 3.2866e-04\n",
      "Epoch 987/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2118e-04 - val_loss: 3.2948e-04\n",
      "Epoch 988/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2097e-04 - val_loss: 3.2872e-04\n",
      "Epoch 989/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2082e-04 - val_loss: 3.2898e-04\n",
      "Epoch 990/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2099e-04 - val_loss: 3.2910e-04\n",
      "Epoch 991/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2082e-04 - val_loss: 3.2846e-04\n",
      "Epoch 992/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2102e-04 - val_loss: 3.2922e-04\n",
      "Epoch 993/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2088e-04 - val_loss: 3.2910e-04\n",
      "Epoch 994/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2080e-04 - val_loss: 3.2876e-04\n",
      "Epoch 995/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2082e-04 - val_loss: 3.2900e-04\n",
      "Epoch 996/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2107e-04 - val_loss: 3.2791e-04\n",
      "Epoch 997/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2071e-04 - val_loss: 3.2844e-04\n",
      "Epoch 998/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2061e-04 - val_loss: 3.2922e-04\n",
      "Epoch 999/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2078e-04 - val_loss: 3.2910e-04\n",
      "Epoch 1000/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2079e-04 - val_loss: 3.2839e-04\n",
      "INFO:tensorflow:Assets written to: AET_CF_Trial_11/models/saved_model_11_LSP_AET_CF_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: AET_CF_Trial_11/models/saved_model_11_LSP_AET_CF_1/assets\n",
      "100%|███████████████████████████████████████████| 2/2 [43:07<00:00, 1293.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Template to copy and paste\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# New folder name\n",
    "folder_name = \"AET_CF_Trial_11\"\n",
    "\n",
    "# Check if the folder exists. If not, create it.\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for counts in tqdm(range(2)):  # this determines the number of epoch sets\n",
    "    # Open a file for this epoch set to write outputs\n",
    "    name = \"11_LSP_AET_CF_\"\n",
    "    output_path = os.path.join(folder_name, f\"11_LSP_AET_CF_Predictions_{counts}.txt\")\n",
    "    with open(output_path, \"w\") as file:\n",
    "        # Autoencoder training\n",
    "        history = autoencoder.fit(X_train_f, X_train_f, batch_size=256,\n",
    "                                  epochs=1000, validation_data=(X_valid_f, X_valid_f), verbose=1)\n",
    "        \n",
    "        # Convert history object to dataframe and plot rates\n",
    "        training_history = pd.DataFrame(history.history)\n",
    "        plt.plot(training_history)\n",
    "        file_name_0 = os.path.join(folder_name, name + \"Training_History\" + str(counts))\n",
    "        training_history.to_pickle(file_name_0)\n",
    "        file_name_1 = os.path.join(folder_name, name + \"Training_History\" + str(counts) + \".png\")\n",
    "        plt.savefig(file_name_1, dpi=300)\n",
    "        plt.clf()\n",
    "\n",
    "        # Read in latent layer\n",
    "        dr_model = tf.keras.models.Model(inputs=autoencoder.get_layer('ae_input').input,\n",
    "                                         outputs=autoencoder.get_layer('ae_latent').output)\n",
    "        # Write the model summary to the file\n",
    "        dr_model.summary(print_fn=lambda x: file.write(x + '\\n'))\n",
    "\n",
    "        # Define batch size for processing validation data\n",
    "        batch_size = 32\n",
    "\n",
    "        # Initialize lists to hold prediction results\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "\n",
    "        # Process validation data in batches\n",
    "        for batch_start in range(0, len(X_valid_f), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(X_valid_f))\n",
    "            X_batch = np.array(X_valid_f.iloc[batch_start:batch_end])\n",
    "            y_batch = y_valid_f[batch_start:batch_end]\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            op_batch = dr_model.predict(X_batch, verbose=0)\n",
    "\n",
    "            # Process and store the results\n",
    "            for i, op in enumerate(op_batch):\n",
    "                z.append(y_batch[i])\n",
    "                x.append(op[0])\n",
    "                y.append(op[1])\n",
    "                file.write(f\"Prediction {batch_start + i}: {op}\\n\")\n",
    "\n",
    "        # Construct and save the data frame\n",
    "        df = pd.DataFrame()\n",
    "        df['x'] = x\n",
    "        df['y'] = y\n",
    "        df['z'] = [\"trajectory-\" + str(k) for k in z]\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        fig = sns.scatterplot(x='x', y='y', hue='z', data=df, s=10)\n",
    "        file_name_2 = os.path.join(folder_name, name + str(counts) + \".png\")\n",
    "        fig.figure.savefig(file_name_2, dpi=300)\n",
    "        plt.clf()\n",
    "\n",
    "        file_name_3 = os.path.join(folder_name, name + 'Predictions' + str(counts))\n",
    "        df.to_pickle(file_name_3)\n",
    "\n",
    "        # Save the model in a subfolder within Trial folder\n",
    "        model_folder = os.path.join(folder_name, 'models')\n",
    "        if not os.path.exists(model_folder):\n",
    "            os.makedirs(model_folder)\n",
    "        file_name = os.path.join(model_folder, 'saved_model_' + name + str(counts))\n",
    "        autoencoder.save(file_name)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67e1ecf3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Template to copy and paste\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# New folder name\n",
    "folder_name = \"AET_CF_Trial_#\"\n",
    "\n",
    "# Check if the folder exists. If not, create it.\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "for counts in tqdm(range(59)):  # this determines the number of epoch sets\n",
    "    # Open a file for this epoch set to write outputs\n",
    "    name = \"#_LSP_AET_CF_\"\n",
    "    output_path = os.path.join(folder_name, f\"#_LSP_AET_CF_Predictions_{counts}.txt\")\n",
    "    with open(output_path, \"w\") as file:\n",
    "        # Autoencoder training\n",
    "        history = autoencoder.fit(X_train_f, X_train_f, batch_size=256,\n",
    "                                  epochs=1000, validation_data=(X_valid_f, X_valid_f), verbose=1)\n",
    "        \n",
    "        # Convert history object to dataframe and plot rates\n",
    "        training_history = pd.DataFrame(history.history)\n",
    "        plt.plot(training_history)\n",
    "        file_name_0 = os.path.join(folder_name, name + \"_Training_History\" + str(counts))\n",
    "        training_history.to_pickle(file_name_0)\n",
    "        file_name_1 = os.path.join(folder_name, name + str(counts) + \".png\")\n",
    "        plt.savefig(file_name_1, dpi=300)\n",
    "        plt.clf()\n",
    "\n",
    "        # Read in latent layer\n",
    "        dr_model = tf.keras.models.Model(inputs=autoencoder.get_layer('ae_input').input,\n",
    "                                         outputs=autoencoder.get_layer('ae_latent').output)\n",
    "        # Write the model summary to the file\n",
    "        dr_model.summary(print_fn=lambda x: file.write(x + '\\n'))\n",
    "\n",
    "        # Define batch size for processing validation data\n",
    "        batch_size = 32\n",
    "\n",
    "        # Initialize lists to hold prediction results\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "\n",
    "        # Process validation data in batches\n",
    "        for batch_start in range(0, len(X_valid_f), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(X_valid_f))\n",
    "            X_batch = np.array(X_valid_f.iloc[batch_start:batch_end])\n",
    "            y_batch = y_valid_f[batch_start:batch_end]\n",
    "\n",
    "            # Make predictions for this batch\n",
    "            op_batch = dr_model.predict(X_batch, verbose=0)\n",
    "\n",
    "            # Process and store the results\n",
    "            for i, op in enumerate(op_batch):\n",
    "                z.append(y_batch[i])\n",
    "                x.append(op[0])\n",
    "                y.append(op[1])\n",
    "                file.write(f\"Prediction {batch_start + i}: {op}\\n\")\n",
    "\n",
    "        # Construct and save the data frame\n",
    "        df = pd.DataFrame()\n",
    "        df['x'] = x\n",
    "        df['y'] = y\n",
    "        df['z'] = [\"trajectory-\" + str(k) for k in z]\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        fig = sns.scatterplot(x='x', y='y', hue='z', data=df, s=10)\n",
    "        file_name_2 = os.path.join(folder_name, name + str(counts) + \".png\")\n",
    "        fig.figure.savefig(file_name_2, dpi=300)\n",
    "        plt.clf()\n",
    "\n",
    "        file_name_3 = os.path.join(folder_name, '#_LSP_AET_CF_Predictions' + str(counts))\n",
    "        df.to_pickle(file_name_3)\n",
    "\n",
    "        # Save the model in a subfolder within Trial folder\n",
    "        model_folder = os.path.join(folder_name, 'models')\n",
    "        if not os.path.exists(model_folder):\n",
    "            os.makedirs(model_folder)\n",
    "        file_name = os.path.join(model_folder, 'saved_model_#_LSP_AET_CF_' + str(counts))\n",
    "        autoencoder.save(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d093fec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Save index list\n",
    "shuffled_index_train = X_train_f.index.to_list()\n",
    "shuffled_index_valid = X_valid_f.index.to_list()\n",
    "\n",
    "# Save shuffled indices of the training data\n",
    "with open(f\"{folder_name}/shufftrain.npy\", \"wb\") as file:\n",
    "    np.save(file, shuffled_index_train)\n",
    "\n",
    "# Save shuffled indices of the validation data\n",
    "with open(f\"{folder_name}/shuffval.npy\", \"wb\") as file:\n",
    "    np.save(file, shuffled_index_valid)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
