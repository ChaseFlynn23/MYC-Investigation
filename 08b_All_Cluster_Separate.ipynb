{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4b8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import glob\n",
    "import sklearn \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras_tuner import BayesianOptimization, HyperParameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de346bd2",
   "metadata": {},
   "source": [
    "***\n",
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name_1 = 'AET_CF_Trial_12'\n",
    "file_name_1 = '12_LSP_AET_CF_Predictions56'\n",
    "\n",
    "folder_name_2 = 'AET_CF_All_Cluster_Trial_1'\n",
    "if not os.path.exists(folder_name_2):\n",
    "    os.makedirs(folder_name_2)\n",
    "file_name_2 = '1_LSP_AET_CF_'\n",
    "\n",
    "folder_name_3 = 'AET_CF_1_Cluster_Trial_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8267ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and plot the original data set\n",
    "latent = pd.read_pickle(f'{folder_name_1}/{file_name_1}')\n",
    "latent = latent.replace({'trajectory-0.0': 0, 'trajectory-1.0': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007b5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'index' column as the new index\n",
    "latent.set_index('index', inplace=True)\n",
    "\n",
    "# Step 3: Remove the name of the new index\n",
    "latent.index.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f68216",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c1818",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "plt.scatter (latent.x,latent.y, c=latent.z, cmap=\"coolwarm\", s = 1, alpha=1)\n",
    "plt.title('Filtered, epoch set = 56', fontsize = 20)\n",
    "plt.xlabel('x', fontsize = 16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize=14)\n",
    "# plt.savefig(\"56_data.png\", dpi = 300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e5dfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the trajectory identity column for further processing\n",
    "latent_n = latent.drop(['z'], axis = 1)\n",
    "print(latent_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca35deda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_knn_distances(latent_n, k=4):\n",
    "    \"\"\"\n",
    "    Plot the k-nearest neighbors distance for each point in the dataset to help\n",
    "    determine a good 'eps' value for DBSCAN.\n",
    "\n",
    "    Parameters:\n",
    "    - data: The dataset (as a numpy array or similar).\n",
    "    - k: The number of neighbors to consider (typically the same as 'min_samples' in DBSCAN).\n",
    "    \"\"\"\n",
    "    # Compute the nearest neighbors\n",
    "    nn = NearestNeighbors(n_neighbors=k).fit(latent_n)\n",
    "    distances, _ = nn.kneighbors(latent_n)\n",
    "\n",
    "    # Sort and plot the distances\n",
    "    sorted_distances = np.sort(distances[:, k-1], axis=0)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(sorted_distances)\n",
    "    plt.xlabel('Points sorted by distance to the {}-th nearest neighbor'.format(k))\n",
    "    plt.ylabel('{}-th nearest neighbor distance'.format(k))\n",
    "    plt.title('K-Nearest Neighbors Distance Plot')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Then call the function with your data\n",
    "# plot_knn_distances(df55.values, k=4) \n",
    "\n",
    "\n",
    "plot_knn_distances(latent.values, k=4)  # Adjust 'k' as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d805773",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DBSCAN(eps=0.015, min_samples=60).fit_predict(latent_n)\n",
    "\n",
    "plt.rcParams['font.size'] = '18'\n",
    "plt.figure(figsize=(18,10))\n",
    "\n",
    "# Scatter plot assigning to a variable\n",
    "scatter = plt.scatter(latent_n.iloc[:,0], latent_n.iloc[:,1], c=y_pred, s=1)\n",
    "\n",
    "# Creating a legend\n",
    "unique_labels = np.unique(y_pred)\n",
    "# Filter out the noise label (-1) if present\n",
    "unique_labels = unique_labels[unique_labels != -1]\n",
    "legend_labels = ['Cluster {}'.format(lbl) for lbl in unique_labels]\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=legend_labels, loc='upper right')\n",
    "\n",
    "# Setting labels, titles, and ticks\n",
    "plt.xlabel('x', fontsize=16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.title('DBSCAN Clustering of the Latent Layer Representation of the Input data')\n",
    "\n",
    "# Print the number of clusters\n",
    "print('Number of clusters: {}'.format(len(unique_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f92fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# latent_n is DataFrame after removing the 'z' column\n",
    "# latent is the original DataFrame with the 'z' column\n",
    "\n",
    "# Add the cluster labels to your DataFrame\n",
    "latent_n['cluster'] = y_pred\n",
    "latent['cluster'] = y_pred\n",
    "\n",
    "# Reattach the 'z' column\n",
    "latent_n['z'] = latent['z']\n",
    "\n",
    "# Group by cluster and trajectory identity, then count the occurrences\n",
    "cluster_trajectory_count = latent_n.groupby(['cluster', 'z']).size().reset_index(name='count')\n",
    "\n",
    "print(cluster_trajectory_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d963e976",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 0 is WT and 1 is D132H\n",
    "cluster_trajectory_count['z'] = cluster_trajectory_count['z'].replace({0: 'WT', 1: 'D132H'})\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='cluster', y='count', hue='z', data=cluster_trajectory_count)\n",
    "\n",
    "# Setting labels and title\n",
    "plt.xlabel('Cluster Number')\n",
    "plt.ylabel('Number of Frames')\n",
    "plt.title('Number of WT and D132H Frames in Each Cluster')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Trajectory Identity')\n",
    "\n",
    "# Annotate each bar with its count\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, 9), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e425c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661f00be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the first 2 columns\n",
    "latent.drop(['x', 'y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a00b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7d91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load recluster data\n",
    "# recluster = pd.read_csv(f'{folder_name_2}/recluster.csv', index_col=0)\n",
    "y_valid_f = pd.read_csv(f'{folder_name_1}/y_valid_f.csv', index_col=0)\n",
    "X_valid_f = pd.read_csv(f'{folder_name_1}/X_valid_f.csv', index_col=0)\n",
    "X_train_f = pd.read_csv(f'{folder_name_1}/X_train_f.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f841e41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the original data\n",
    "original_data = pd.read_csv(f'{folder_name_1}/X_valid_f.csv', index_col=0)\n",
    "\n",
    "# Assuming 'latent_n' is a DataFrame with cluster information\n",
    "unique_clusters = latent_n['cluster'].unique()\n",
    "\n",
    "for cluster_number in unique_clusters:\n",
    "    # Select indices of the current cluster\n",
    "    selected_cluster_indices = latent_n[latent_n['cluster'] == cluster_number].index\n",
    "\n",
    "    # Filter the data for the current cluster using loc for label-based indexing\n",
    "    filtered_data = original_data.loc[selected_cluster_indices]\n",
    "\n",
    "    # Save the filtered data for the current cluster\n",
    "    filtered_data.to_csv(f'{folder_name_2}/Recluster_Latent_{cluster_number}.csv')\n",
    "\n",
    "    # Save indices of the filtered data for the current cluster\n",
    "    # Assuming 'latent' is defined and has the relevant indices\n",
    "    latent[latent['cluster'] == cluster_number].to_csv(f'{folder_name_2}/Recluster_Index_{cluster_number}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d930e12",
   "metadata": {},
   "source": [
    "# Latent Space of Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f3ddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading autoencoder model from second round of training\n",
    "model_path = f'{folder_name_3}/models/saved_model_1_LSP_AET_CF_Trial_1'\n",
    "autoencoder = tf.keras.models.load_model(model_path)\n",
    "\n",
    "dr_model = tf.keras.models.Model(inputs=autoencoder.get_layer('ae_input').input,\n",
    "                                 outputs=autoencoder.get_layer('ae_latent').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822c71e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = [1, 2, 3]  # Replace with desired clusters\n",
    "\n",
    "for cluster in clusters:\n",
    "    # Load the data for the current cluster\n",
    "    latent_file = f'{folder_name_2}Recluster_Latent_{cluster}.csv'\n",
    "    index_file = f'{folder_name_2}Recluster_Index_{cluster}.csv'\n",
    "\n",
    "    latent_data = pd.read_csv(latent_file)\n",
    "    index_data = pd.read_csv(index_file, header=None, names=['z', 'cluster'], index_col=0)\n",
    "\n",
    "    # Convert the data to numpy array if necessary\n",
    "    X_batch = latent_data.values\n",
    "\n",
    "    # Generate latent space representations\n",
    "    latent_representations = dr_model.predict(X_batch)\n",
    "\n",
    "    # Create DataFrame for visualization and saving\n",
    "    df = pd.DataFrame(latent_representations, columns=['x', 'y'])\n",
    "    df['z'] = index_data['z']\n",
    "    df['cluster'] = index_data['cluster']\n",
    "\n",
    "    # Visualization and saving .png file\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x='x', y='y', hue='cluster', data=df, s=10, palette='viridis')\n",
    "    plt.title(f'Latent Space Representation - Cluster {cluster}')\n",
    "    plt.legend(title='Cluster')\n",
    "    png_path = os.path.join(folder_name_2, f'1_LSP_AET_CF_Cluster_{cluster}.png')\n",
    "    plt.savefig(png_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Saving the data in pickle format\n",
    "    pickle_path = os.path.join(folder_name_2, f'1_LSP_AET_CF_Cluster_{cluster}.pkl')\n",
    "    df.to_pickle(pickle_path)\n",
    "\n",
    "print(\"Processing and saving completed for all specified clusters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc3c8c",
   "metadata": {},
   "source": [
    "# Clustering round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b79715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'AET_CF_All_Cluster_Trial_1'\n",
    "file_name = '1_LSP_AET_CF_Predictions56'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea60608",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c9bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in and plot the original data set\n",
    "latent = pd.read_pickle(f'{folder_name}/{file_name}')\n",
    "latent = latent.replace({'trajectory0': 0, 'trajectory1': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1115a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97658aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,12))\n",
    "plt.scatter (latent.x,latent.y, c=latent.z, cmap=\"coolwarm\", s = 1, alpha=1)\n",
    "plt.title('Filtered, epoch set = 56', fontsize = 20)\n",
    "plt.xlabel('x', fontsize = 16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize=14)\n",
    "# plt.savefig(\"56_data.png\", dpi = 300)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad021d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the trajectory identity column for further processing\n",
    "latent_n = latent.drop(['z', 'index'], axis = 1)\n",
    "print(latent_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ef756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DBSCAN(eps=0.015, min_samples=60).fit_predict(latent_n)\n",
    "plt.rcParams['font.size'] = '18'\n",
    "plt.figure(figsize=(18,10))\n",
    "plt.scatter(latent_n.iloc[:,0], latent_n.iloc[:,1], c=y_pred,s = 1)\n",
    "plt.xlabel('x', fontsize = 16)\n",
    "plt.ylabel('y', fontsize=16)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.title('DBSCAN Clustering of the Latent Layer Representation of the Input data')\n",
    "print('Number of clusters: {}'.format(len(set(y_pred[np.where(y_pred != -1)]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3128a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the cluster labels to your DataFrame\n",
    "latent_n['cluster'] = y_pred\n",
    "\n",
    "# Reattach the 'z' column\n",
    "latent_n['z'] = latent['z']\n",
    "\n",
    "# Group by cluster and trajectory identity, then count the occurrences\n",
    "cluster_trajectory_count = latent_n.groupby(['cluster', 'z']).size().reset_index(name='count')\n",
    "\n",
    "print(cluster_trajectory_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de50ec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 is WT and 1 is D132H\n",
    "cluster_trajectory_count['z'] = cluster_trajectory_count['z'].replace({0: 'WT', 1: 'D132H'})\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(x='cluster', y='count', hue='z', data=cluster_trajectory_count)\n",
    "\n",
    "# Setting labels and title\n",
    "plt.xlabel('Cluster Number')\n",
    "plt.ylabel('Number of Frames')\n",
    "plt.title('Number of WT and D132H Frames in Each Cluster')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Trajectory Identity')\n",
    "\n",
    "# Annotate each bar with its count\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                ha = 'center', va = 'center', \n",
    "                xytext = (0, 9), \n",
    "                textcoords = 'offset points')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d558fba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
