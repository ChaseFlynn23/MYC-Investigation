{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d4fe347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-20 15:03:21.271542: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-20 15:03:21.271588: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-20 15:03:21.272944: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-20 15:03:21.385891: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-20 15:03:22.699239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import glob\n",
    "import sklearn \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras_tuner import BayesianOptimization, HyperParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abbebb37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.3249</td>\n",
       "      <td>9.6718</td>\n",
       "      <td>6.0082</td>\n",
       "      <td>9.6574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3105</td>\n",
       "      <td>10.6216</td>\n",
       "      <td>5.9996</td>\n",
       "      <td>11.2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7233</td>\n",
       "      <td>11.4243</td>\n",
       "      <td>7.3021</td>\n",
       "      <td>11.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.4864</td>\n",
       "      <td>10.7079</td>\n",
       "      <td>6.4156</td>\n",
       "      <td>10.7262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4673</td>\n",
       "      <td>12.0023</td>\n",
       "      <td>6.3573</td>\n",
       "      <td>11.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>4.9712</td>\n",
       "      <td>8.9677</td>\n",
       "      <td>10.1179</td>\n",
       "      <td>8.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>4.8021</td>\n",
       "      <td>9.0623</td>\n",
       "      <td>10.1026</td>\n",
       "      <td>8.6752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>5.9590</td>\n",
       "      <td>10.3438</td>\n",
       "      <td>8.6309</td>\n",
       "      <td>9.4556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>4.3996</td>\n",
       "      <td>10.3760</td>\n",
       "      <td>9.5901</td>\n",
       "      <td>9.3513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>5.2675</td>\n",
       "      <td>10.8606</td>\n",
       "      <td>8.6371</td>\n",
       "      <td>9.7884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            7       20       26       27\n",
       "0      6.3249   9.6718   6.0082   9.6574\n",
       "1      6.3105  10.6216   5.9996  11.2509\n",
       "2      5.7233  11.4243   7.3021  11.5329\n",
       "3      5.4864  10.7079   6.4156  10.7262\n",
       "4      5.4673  12.0023   6.3573  11.2367\n",
       "...       ...      ...      ...      ...\n",
       "39995  4.9712   8.9677  10.1179   8.9430\n",
       "39996  4.8021   9.0623  10.1026   8.6752\n",
       "39997  5.9590  10.3438   8.6309   9.4556\n",
       "39998  4.3996  10.3760   9.5901   9.3513\n",
       "39999  5.2675  10.8606   8.6371   9.7884\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>19</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.3049</td>\n",
       "      <td>30.7508</td>\n",
       "      <td>24.7567</td>\n",
       "      <td>23.1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.4792</td>\n",
       "      <td>28.1640</td>\n",
       "      <td>23.8363</td>\n",
       "      <td>23.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.5636</td>\n",
       "      <td>30.2936</td>\n",
       "      <td>24.8655</td>\n",
       "      <td>23.4604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.4733</td>\n",
       "      <td>29.5746</td>\n",
       "      <td>21.3842</td>\n",
       "      <td>22.6630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0147</td>\n",
       "      <td>27.5496</td>\n",
       "      <td>23.8249</td>\n",
       "      <td>22.3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>14.7258</td>\n",
       "      <td>8.4287</td>\n",
       "      <td>24.3534</td>\n",
       "      <td>22.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>15.5602</td>\n",
       "      <td>7.1757</td>\n",
       "      <td>24.9417</td>\n",
       "      <td>24.1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>15.4532</td>\n",
       "      <td>7.1490</td>\n",
       "      <td>23.8513</td>\n",
       "      <td>27.4276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>15.1188</td>\n",
       "      <td>7.5725</td>\n",
       "      <td>25.4096</td>\n",
       "      <td>26.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>15.4409</td>\n",
       "      <td>7.2976</td>\n",
       "      <td>26.2683</td>\n",
       "      <td>24.6460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            16       19       29       30\n",
       "0      17.3049  30.7508  24.7567  23.1634\n",
       "1      22.4792  28.1640  23.8363  23.2798\n",
       "2      25.5636  30.2936  24.8655  23.4604\n",
       "3      26.4733  29.5746  21.3842  22.6630\n",
       "4      24.0147  27.5496  23.8249  22.3185\n",
       "...        ...      ...      ...      ...\n",
       "39995  14.7258   8.4287  24.3534  22.6400\n",
       "39996  15.5602   7.1757  24.9417  24.1508\n",
       "39997  15.4532   7.1490  23.8513  27.4276\n",
       "39998  15.1188   7.5725  25.4096  26.8701\n",
       "39999  15.4409   7.2976  26.2683  24.6460\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.2374</td>\n",
       "      <td>40.1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.5602</td>\n",
       "      <td>36.3229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.4329</td>\n",
       "      <td>41.2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.1207</td>\n",
       "      <td>39.2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.6335</td>\n",
       "      <td>38.7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>16.9755</td>\n",
       "      <td>31.9599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>17.0192</td>\n",
       "      <td>29.9824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>18.5272</td>\n",
       "      <td>29.4126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>17.1766</td>\n",
       "      <td>32.6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>17.7794</td>\n",
       "      <td>33.5279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             9       21\n",
       "0      14.2374  40.1886\n",
       "1      14.5602  36.3229\n",
       "2      17.4329  41.2223\n",
       "3      20.1207  39.2809\n",
       "4      15.6335  38.7009\n",
       "...        ...      ...\n",
       "39995  16.9755  31.9599\n",
       "39996  17.0192  29.9824\n",
       "39997  18.5272  29.4126\n",
       "39998  17.1766  32.6983\n",
       "39999  17.7794  33.5279\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------\n",
      "D132H for window size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.6253</td>\n",
       "      <td>11.4558</td>\n",
       "      <td>7.0366</td>\n",
       "      <td>10.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6219</td>\n",
       "      <td>11.7791</td>\n",
       "      <td>6.8272</td>\n",
       "      <td>10.8156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3355</td>\n",
       "      <td>9.9860</td>\n",
       "      <td>6.2585</td>\n",
       "      <td>9.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7119</td>\n",
       "      <td>8.4264</td>\n",
       "      <td>5.8994</td>\n",
       "      <td>8.1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.7166</td>\n",
       "      <td>9.3508</td>\n",
       "      <td>6.4404</td>\n",
       "      <td>10.1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>4.6642</td>\n",
       "      <td>10.3721</td>\n",
       "      <td>10.9673</td>\n",
       "      <td>9.8788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>4.7521</td>\n",
       "      <td>11.6737</td>\n",
       "      <td>10.7638</td>\n",
       "      <td>9.5196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>4.5160</td>\n",
       "      <td>9.7824</td>\n",
       "      <td>10.9669</td>\n",
       "      <td>9.6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>4.8358</td>\n",
       "      <td>7.8161</td>\n",
       "      <td>10.7679</td>\n",
       "      <td>9.6355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>4.5663</td>\n",
       "      <td>10.1266</td>\n",
       "      <td>10.9913</td>\n",
       "      <td>9.2231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            7       20       26       27\n",
       "0      5.6253  11.4558   7.0366  10.8265\n",
       "1      5.6219  11.7791   6.8272  10.8156\n",
       "2      6.3355   9.9860   6.2585   9.7506\n",
       "3      4.7119   8.4264   5.8994   8.1239\n",
       "4      7.7166   9.3508   6.4404  10.1599\n",
       "...       ...      ...      ...      ...\n",
       "39995  4.6642  10.3721  10.9673   9.8788\n",
       "39996  4.7521  11.6737  10.7638   9.5196\n",
       "39997  4.5160   9.7824  10.9669   9.6701\n",
       "39998  4.8358   7.8161  10.7679   9.6355\n",
       "39999  4.5663  10.1266  10.9913   9.2231\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D132H for window size = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>19</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.3721</td>\n",
       "      <td>29.6048</td>\n",
       "      <td>24.1730</td>\n",
       "      <td>23.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.4543</td>\n",
       "      <td>28.2314</td>\n",
       "      <td>25.1477</td>\n",
       "      <td>23.0454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.1972</td>\n",
       "      <td>29.2049</td>\n",
       "      <td>23.6181</td>\n",
       "      <td>18.1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.6381</td>\n",
       "      <td>27.5069</td>\n",
       "      <td>25.6890</td>\n",
       "      <td>20.3013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.8374</td>\n",
       "      <td>29.7816</td>\n",
       "      <td>23.7772</td>\n",
       "      <td>20.6936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>15.4144</td>\n",
       "      <td>12.4362</td>\n",
       "      <td>7.2937</td>\n",
       "      <td>12.2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>15.0391</td>\n",
       "      <td>12.2133</td>\n",
       "      <td>7.2107</td>\n",
       "      <td>13.3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>15.5238</td>\n",
       "      <td>12.2077</td>\n",
       "      <td>7.7544</td>\n",
       "      <td>12.6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>15.9725</td>\n",
       "      <td>12.2538</td>\n",
       "      <td>7.3585</td>\n",
       "      <td>12.1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>15.6850</td>\n",
       "      <td>12.3831</td>\n",
       "      <td>7.2522</td>\n",
       "      <td>12.8442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            16       19       29       30\n",
       "0      16.3721  29.6048  24.1730  23.9425\n",
       "1      15.4543  28.2314  25.1477  23.0454\n",
       "2      13.1972  29.2049  23.6181  18.1444\n",
       "3      15.6381  27.5069  25.6890  20.3013\n",
       "4      18.8374  29.7816  23.7772  20.6936\n",
       "...        ...      ...      ...      ...\n",
       "39995  15.4144  12.4362   7.2937  12.2014\n",
       "39996  15.0391  12.2133   7.2107  13.3563\n",
       "39997  15.5238  12.2077   7.7544  12.6172\n",
       "39998  15.9725  12.2538   7.3585  12.1032\n",
       "39999  15.6850  12.3831   7.2522  12.8442\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D132H for window size = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4055</td>\n",
       "      <td>41.6856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0150</td>\n",
       "      <td>40.2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0081</td>\n",
       "      <td>41.7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.6520</td>\n",
       "      <td>40.4408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.7450</td>\n",
       "      <td>38.0932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>14.0324</td>\n",
       "      <td>23.2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>14.9455</td>\n",
       "      <td>22.4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>14.0516</td>\n",
       "      <td>22.7481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>14.0350</td>\n",
       "      <td>23.5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>14.3382</td>\n",
       "      <td>22.8859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             9       21\n",
       "0      13.4055  41.6856\n",
       "1      12.0150  40.2262\n",
       "2      17.0081  41.7220\n",
       "3      15.6520  40.4408\n",
       "4      20.7450  38.0932\n",
       "...        ...      ...\n",
       "39995  14.0324  23.2605\n",
       "39996  14.9455  22.4160\n",
       "39997  14.0516  22.7481\n",
       "39998  14.0350  23.5958\n",
       "39999  14.3382  22.8859\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data import\n",
    "wt_filtered = ['wt_filtered_lcc_3_50.lccdata', 'wt_filtered_2_lcc_12_50.lccdata', 'wt_filtered_lcc_20_50.lccdata']\n",
    "\n",
    "# filtered wt LCC data import\n",
    "wt_f_var_names = ['wt_3f', 'wt_12f', 'wt_20f']\n",
    "\n",
    "for var, file in zip(wt_f_var_names, wt_filtered):\n",
    "    globals()[var] = pd.read_csv(file, sep='\\t').drop(columns='Unnamed: 0')\n",
    "\n",
    "# filtered mutant LCC data import\n",
    "D132H_filtered = ['D132H_filtered_lcc_3_50.lccdata', 'D132H_filtered_2_lcc_12_50.lccdata', 'D132H_filtered_lcc_20_50.lccdata']\n",
    "D132H_f_var_names = ['D132H_3f', 'D132H_12f', 'D132H_20f']\n",
    "\n",
    "for var, file in zip(D132H_f_var_names, D132H_filtered):\n",
    "    globals()[var] = pd.read_csv(file, sep='\\t').drop(columns='Unnamed: 0')\n",
    "\n",
    "# Visualization of dataset\n",
    "print('WT for window size = 3')\n",
    "display(wt_3f)\n",
    "print('WT for window size = 12')\n",
    "display(wt_12f)\n",
    "print('WT for window size = 20')\n",
    "display(wt_20f)\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------')\n",
    "print('D132H for window size = 3')\n",
    "display(D132H_3f)\n",
    "print('D132H for window size = 12')\n",
    "display(D132H_12f)\n",
    "print('D132H for window size = 20')\n",
    "display(D132H_20f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26bbd12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concateneate wt and mutant dataframes and rename columns\n",
    "\n",
    "wt_f = pd.concat([wt_12f, wt_20f, wt_3f], axis = 1)\n",
    "    \n",
    "D132H_f = pd.concat([D132H_12f, D132H_20f, D132H_3f], axis = 1)\n",
    "\n",
    "colnames = [*range(0,10)]\n",
    "colnames\n",
    "wt_f.columns = colnames\n",
    "D132H_f.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c62a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered wt data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.3049</td>\n",
       "      <td>30.7508</td>\n",
       "      <td>24.7567</td>\n",
       "      <td>23.1634</td>\n",
       "      <td>14.2374</td>\n",
       "      <td>40.1886</td>\n",
       "      <td>6.3249</td>\n",
       "      <td>9.6718</td>\n",
       "      <td>6.0082</td>\n",
       "      <td>9.6574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.4792</td>\n",
       "      <td>28.1640</td>\n",
       "      <td>23.8363</td>\n",
       "      <td>23.2798</td>\n",
       "      <td>14.5602</td>\n",
       "      <td>36.3229</td>\n",
       "      <td>6.3105</td>\n",
       "      <td>10.6216</td>\n",
       "      <td>5.9996</td>\n",
       "      <td>11.2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.5636</td>\n",
       "      <td>30.2936</td>\n",
       "      <td>24.8655</td>\n",
       "      <td>23.4604</td>\n",
       "      <td>17.4329</td>\n",
       "      <td>41.2223</td>\n",
       "      <td>5.7233</td>\n",
       "      <td>11.4243</td>\n",
       "      <td>7.3021</td>\n",
       "      <td>11.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26.4733</td>\n",
       "      <td>29.5746</td>\n",
       "      <td>21.3842</td>\n",
       "      <td>22.6630</td>\n",
       "      <td>20.1207</td>\n",
       "      <td>39.2809</td>\n",
       "      <td>5.4864</td>\n",
       "      <td>10.7079</td>\n",
       "      <td>6.4156</td>\n",
       "      <td>10.7262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0147</td>\n",
       "      <td>27.5496</td>\n",
       "      <td>23.8249</td>\n",
       "      <td>22.3185</td>\n",
       "      <td>15.6335</td>\n",
       "      <td>38.7009</td>\n",
       "      <td>5.4673</td>\n",
       "      <td>12.0023</td>\n",
       "      <td>6.3573</td>\n",
       "      <td>11.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>14.7258</td>\n",
       "      <td>8.4287</td>\n",
       "      <td>24.3534</td>\n",
       "      <td>22.6400</td>\n",
       "      <td>16.9755</td>\n",
       "      <td>31.9599</td>\n",
       "      <td>4.9712</td>\n",
       "      <td>8.9677</td>\n",
       "      <td>10.1179</td>\n",
       "      <td>8.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>15.5602</td>\n",
       "      <td>7.1757</td>\n",
       "      <td>24.9417</td>\n",
       "      <td>24.1508</td>\n",
       "      <td>17.0192</td>\n",
       "      <td>29.9824</td>\n",
       "      <td>4.8021</td>\n",
       "      <td>9.0623</td>\n",
       "      <td>10.1026</td>\n",
       "      <td>8.6752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>15.4532</td>\n",
       "      <td>7.1490</td>\n",
       "      <td>23.8513</td>\n",
       "      <td>27.4276</td>\n",
       "      <td>18.5272</td>\n",
       "      <td>29.4126</td>\n",
       "      <td>5.9590</td>\n",
       "      <td>10.3438</td>\n",
       "      <td>8.6309</td>\n",
       "      <td>9.4556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>15.1188</td>\n",
       "      <td>7.5725</td>\n",
       "      <td>25.4096</td>\n",
       "      <td>26.8701</td>\n",
       "      <td>17.1766</td>\n",
       "      <td>32.6983</td>\n",
       "      <td>4.3996</td>\n",
       "      <td>10.3760</td>\n",
       "      <td>9.5901</td>\n",
       "      <td>9.3513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>15.4409</td>\n",
       "      <td>7.2976</td>\n",
       "      <td>26.2683</td>\n",
       "      <td>24.6460</td>\n",
       "      <td>17.7794</td>\n",
       "      <td>33.5279</td>\n",
       "      <td>5.2675</td>\n",
       "      <td>10.8606</td>\n",
       "      <td>8.6371</td>\n",
       "      <td>9.7884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2        3        4        5       6        7  \\\n",
       "0      17.3049  30.7508  24.7567  23.1634  14.2374  40.1886  6.3249   9.6718   \n",
       "1      22.4792  28.1640  23.8363  23.2798  14.5602  36.3229  6.3105  10.6216   \n",
       "2      25.5636  30.2936  24.8655  23.4604  17.4329  41.2223  5.7233  11.4243   \n",
       "3      26.4733  29.5746  21.3842  22.6630  20.1207  39.2809  5.4864  10.7079   \n",
       "4      24.0147  27.5496  23.8249  22.3185  15.6335  38.7009  5.4673  12.0023   \n",
       "...        ...      ...      ...      ...      ...      ...     ...      ...   \n",
       "39995  14.7258   8.4287  24.3534  22.6400  16.9755  31.9599  4.9712   8.9677   \n",
       "39996  15.5602   7.1757  24.9417  24.1508  17.0192  29.9824  4.8021   9.0623   \n",
       "39997  15.4532   7.1490  23.8513  27.4276  18.5272  29.4126  5.9590  10.3438   \n",
       "39998  15.1188   7.5725  25.4096  26.8701  17.1766  32.6983  4.3996  10.3760   \n",
       "39999  15.4409   7.2976  26.2683  24.6460  17.7794  33.5279  5.2675  10.8606   \n",
       "\n",
       "             8        9  \n",
       "0       6.0082   9.6574  \n",
       "1       5.9996  11.2509  \n",
       "2       7.3021  11.5329  \n",
       "3       6.4156  10.7262  \n",
       "4       6.3573  11.2367  \n",
       "...        ...      ...  \n",
       "39995  10.1179   8.9430  \n",
       "39996  10.1026   8.6752  \n",
       "39997   8.6309   9.4556  \n",
       "39998   9.5901   9.3513  \n",
       "39999   8.6371   9.7884  \n",
       "\n",
       "[40000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------\n",
      "Filtered D132H data\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.3721</td>\n",
       "      <td>29.6048</td>\n",
       "      <td>24.1730</td>\n",
       "      <td>23.9425</td>\n",
       "      <td>13.4055</td>\n",
       "      <td>41.6856</td>\n",
       "      <td>5.6253</td>\n",
       "      <td>11.4558</td>\n",
       "      <td>7.0366</td>\n",
       "      <td>10.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.4543</td>\n",
       "      <td>28.2314</td>\n",
       "      <td>25.1477</td>\n",
       "      <td>23.0454</td>\n",
       "      <td>12.0150</td>\n",
       "      <td>40.2262</td>\n",
       "      <td>5.6219</td>\n",
       "      <td>11.7791</td>\n",
       "      <td>6.8272</td>\n",
       "      <td>10.8156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.1972</td>\n",
       "      <td>29.2049</td>\n",
       "      <td>23.6181</td>\n",
       "      <td>18.1444</td>\n",
       "      <td>17.0081</td>\n",
       "      <td>41.7220</td>\n",
       "      <td>6.3355</td>\n",
       "      <td>9.9860</td>\n",
       "      <td>6.2585</td>\n",
       "      <td>9.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.6381</td>\n",
       "      <td>27.5069</td>\n",
       "      <td>25.6890</td>\n",
       "      <td>20.3013</td>\n",
       "      <td>15.6520</td>\n",
       "      <td>40.4408</td>\n",
       "      <td>4.7119</td>\n",
       "      <td>8.4264</td>\n",
       "      <td>5.8994</td>\n",
       "      <td>8.1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.8374</td>\n",
       "      <td>29.7816</td>\n",
       "      <td>23.7772</td>\n",
       "      <td>20.6936</td>\n",
       "      <td>20.7450</td>\n",
       "      <td>38.0932</td>\n",
       "      <td>7.7166</td>\n",
       "      <td>9.3508</td>\n",
       "      <td>6.4404</td>\n",
       "      <td>10.1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>15.4144</td>\n",
       "      <td>12.4362</td>\n",
       "      <td>7.2937</td>\n",
       "      <td>12.2014</td>\n",
       "      <td>14.0324</td>\n",
       "      <td>23.2605</td>\n",
       "      <td>4.6642</td>\n",
       "      <td>10.3721</td>\n",
       "      <td>10.9673</td>\n",
       "      <td>9.8788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>15.0391</td>\n",
       "      <td>12.2133</td>\n",
       "      <td>7.2107</td>\n",
       "      <td>13.3563</td>\n",
       "      <td>14.9455</td>\n",
       "      <td>22.4160</td>\n",
       "      <td>4.7521</td>\n",
       "      <td>11.6737</td>\n",
       "      <td>10.7638</td>\n",
       "      <td>9.5196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>15.5238</td>\n",
       "      <td>12.2077</td>\n",
       "      <td>7.7544</td>\n",
       "      <td>12.6172</td>\n",
       "      <td>14.0516</td>\n",
       "      <td>22.7481</td>\n",
       "      <td>4.5160</td>\n",
       "      <td>9.7824</td>\n",
       "      <td>10.9669</td>\n",
       "      <td>9.6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>15.9725</td>\n",
       "      <td>12.2538</td>\n",
       "      <td>7.3585</td>\n",
       "      <td>12.1032</td>\n",
       "      <td>14.0350</td>\n",
       "      <td>23.5958</td>\n",
       "      <td>4.8358</td>\n",
       "      <td>7.8161</td>\n",
       "      <td>10.7679</td>\n",
       "      <td>9.6355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>15.6850</td>\n",
       "      <td>12.3831</td>\n",
       "      <td>7.2522</td>\n",
       "      <td>12.8442</td>\n",
       "      <td>14.3382</td>\n",
       "      <td>22.8859</td>\n",
       "      <td>4.5663</td>\n",
       "      <td>10.1266</td>\n",
       "      <td>10.9913</td>\n",
       "      <td>9.2231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0        1        2        3        4        5       6        7  \\\n",
       "0      16.3721  29.6048  24.1730  23.9425  13.4055  41.6856  5.6253  11.4558   \n",
       "1      15.4543  28.2314  25.1477  23.0454  12.0150  40.2262  5.6219  11.7791   \n",
       "2      13.1972  29.2049  23.6181  18.1444  17.0081  41.7220  6.3355   9.9860   \n",
       "3      15.6381  27.5069  25.6890  20.3013  15.6520  40.4408  4.7119   8.4264   \n",
       "4      18.8374  29.7816  23.7772  20.6936  20.7450  38.0932  7.7166   9.3508   \n",
       "...        ...      ...      ...      ...      ...      ...     ...      ...   \n",
       "39995  15.4144  12.4362   7.2937  12.2014  14.0324  23.2605  4.6642  10.3721   \n",
       "39996  15.0391  12.2133   7.2107  13.3563  14.9455  22.4160  4.7521  11.6737   \n",
       "39997  15.5238  12.2077   7.7544  12.6172  14.0516  22.7481  4.5160   9.7824   \n",
       "39998  15.9725  12.2538   7.3585  12.1032  14.0350  23.5958  4.8358   7.8161   \n",
       "39999  15.6850  12.3831   7.2522  12.8442  14.3382  22.8859  4.5663  10.1266   \n",
       "\n",
       "             8        9  \n",
       "0       7.0366  10.8265  \n",
       "1       6.8272  10.8156  \n",
       "2       6.2585   9.7506  \n",
       "3       5.8994   8.1239  \n",
       "4       6.4404  10.1599  \n",
       "...        ...      ...  \n",
       "39995  10.9673   9.8788  \n",
       "39996  10.7638   9.5196  \n",
       "39997  10.9669   9.6701  \n",
       "39998  10.7679   9.6355  \n",
       "39999  10.9913   9.2231  \n",
       "\n",
       "[40000 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of dataset\n",
    "print('Filtered wt data')\n",
    "display(wt_f)\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------')\n",
    "print('Filtered D132H data')\n",
    "display(D132H_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47be684f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum WT Value:\n",
      "56.1035\n",
      "Maximum Mutant Value:\n",
      "49.7189\n"
     ]
    }
   ],
   "source": [
    "max_value_wt = wt_f.max().max()\n",
    "print('Maximum WT Value:')\n",
    "print(max_value_wt)\n",
    "\n",
    "max_value_m = D132H_f.max().max()\n",
    "print('Maximum Mutant Value:')\n",
    "print(max_value_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0898115a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre processing\n",
    "\n",
    "def preprocessing(wt, mutant):\n",
    "    \n",
    "    wt_label = np.zeros(len(wt)) # Set wt labels to 0\n",
    "    \n",
    "    mutant_label = np.ones(len(mutant))\n",
    "    \n",
    "    # Concatenate data frames and label arrays\n",
    "\n",
    "    X_train_full = pd.concat([wt.reset_index(), mutant.reset_index()])\n",
    "    y_train_full = np.concatenate((wt_label, mutant_label))\n",
    "    \n",
    "    #Drop index column and normalise training data\n",
    "    X_train_full = X_train_full.drop(columns = 'index')\n",
    "    \n",
    "    X_train_full= X_train_full.div(100) ## When changed from 100 to 56.1035, errors generated.\n",
    "    \n",
    "    # Separate training and validation sets and print relevant shapes\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, stratify=y_train_full, test_size=0.2)\n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(X_valid.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_valid.shape)\n",
    "    \n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f8198e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 10)\n",
      "(16000, 10)\n",
      "(64000,)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_f, X_valid_f, y_train_f, y_valid_f = preprocessing(wt_f, D132H_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "134de7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Training Value:\n",
      "0.556025\n",
      "Maximum Validation Value:\n",
      "0.561035\n"
     ]
    }
   ],
   "source": [
    "max_t_value = X_train_f.max().max()\n",
    "print('Maximum Training Value:')\n",
    "print(max_t_value)\n",
    "\n",
    "max_v_value = X_valid_f.max().max()\n",
    "print('Maximum Validation Value:')\n",
    "print(max_v_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0acb1156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracking for the best overall validation loss and hyperparameters\n",
    "best_overall = {\n",
    "    'loss': float('inf'),\n",
    "    'hyperparameters': None,\n",
    "    'step': None,\n",
    "    'details': {}  # A dictionary to store detailed hyperparameters for easy access\n",
    "}\n",
    "\n",
    "# Function to update the overall best with results from a new tuning step\n",
    "def update_best_overall(tuner, step, additional_details=None):\n",
    "    global best_overall\n",
    "    best_hp = tuner.get_best_hyperparameters()[0]\n",
    "    best_loss = tuner.oracle.get_best_trials(1)[0].score  # Adjust based on how you retrieve best score\n",
    "    \n",
    "    # Update if the current step's best loss is better than the global best loss\n",
    "    if best_loss < best_overall['loss']:\n",
    "        best_overall['loss'] = best_loss\n",
    "        best_overall['hyperparameters'] = best_hp\n",
    "        best_overall['step'] = step\n",
    "        if additional_details:\n",
    "            best_overall['details'][step] = additional_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8286e898",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from AE_Tuning_MO/AET_Nodes_Layers_MO/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Building & Tuning the AE Hyperparameters: Nodes and Layers\n",
    "def build_autoencoder(hp):\n",
    "    input_shape = X_train_f.shape[1:]  \n",
    "\n",
    "    # Encoder\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "    x = encoder_input\n",
    "    encoder_layers = []\n",
    "    # Define encoder layers and store their sizes\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):  \n",
    "        layer_size = hp.Int(f'nodes_{i}', min_value=16, max_value=336, step=16)\n",
    "        x = layers.Dense(layer_size, activation=keras.layers.LeakyReLU(alpha=0.01))(x)\n",
    "        encoder_layers.append(layer_size)  # Store layer size\n",
    "\n",
    "    # Latent space\n",
    "    latent_space = layers.Dense(2)(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = latent_space\n",
    "    for layer_size in reversed(encoder_layers):  # Reverse the order of encoder layers for decoder\n",
    "        x = layers.Dense(layer_size, activation=keras.layers.LeakyReLU(alpha=0.01))(x)\n",
    "\n",
    "    decoder_output = layers.Dense(input_shape[0], activation='linear')(x)\n",
    "\n",
    "    # Autoencoder model\n",
    "    autoencoder = models.Model(encoder_input, decoder_output)\n",
    "\n",
    "    # Compile model\n",
    "    autoencoder.compile(optimizer=optimizers.Adam(learning_rate=0.005), loss='mse')\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Prepare Keras Tuner with Bayesian Optimization\n",
    "tuner = BayesianOptimization(\n",
    "    build_autoencoder,\n",
    "    objective='val_loss',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=2,\n",
    "    num_initial_points=10,      # Number of initial random trials before beginning targeted opt\n",
    "    directory='AE_Tuning_MO',\n",
    "    project_name='AET_Nodes_Layers_MO'\n",
    ")\n",
    "\n",
    "# Start tuning\n",
    "tuner.search(\n",
    "    X_train_f, X_train_f,\n",
    "    epochs=50,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_valid_f, X_valid_f)  \n",
    ")\n",
    "\n",
    "# Retrieve the best hyperparameters after tuning\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# After nodes and layers tuning is complete\n",
    "update_best_overall(tuner, 'nodes_layers', additional_details={\n",
    "    'num_layers': best_hp.get('num_layers'),\n",
    "    'nodes_per_layer': [best_hp.get(f'nodes_{i}') for i in range(best_hp.get('num_layers'))]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd0f081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 10)]              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 160)               1760      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 224)               36064     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 160)               36000     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 112)               18032     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 226       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 112)               336       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 160)               18080     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 224)               36064     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 160)               36000     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                1610      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 184172 (719.42 KB)\n",
      "Trainable params: 184172 (719.42 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Get the best model and print summary\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b75afe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 1\n",
      "Hyperparameters:\n",
      "num_layers: 4\n",
      "nodes_0: 160\n",
      "nodes_1: 224\n",
      "nodes_2: 160\n",
      "nodes_3: 112\n",
      "nodes_4: 192\n",
      "Validation Loss: 0.00032502248359378427\n",
      "\n",
      "Rank: 2\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "nodes_0: 80\n",
      "nodes_1: 304\n",
      "nodes_2: 144\n",
      "nodes_3: 32\n",
      "nodes_4: 144\n",
      "Validation Loss: 0.0003251514135627076\n",
      "\n",
      "Rank: 3\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "nodes_0: 208\n",
      "nodes_1: 304\n",
      "nodes_2: 112\n",
      "nodes_3: 240\n",
      "nodes_4: 64\n",
      "Validation Loss: 0.00032790773548185825\n",
      "\n",
      "Rank: 4\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "nodes_0: 320\n",
      "nodes_1: 288\n",
      "nodes_2: 336\n",
      "nodes_3: 96\n",
      "nodes_4: 192\n",
      "Validation Loss: 0.0003294930065749213\n",
      "\n",
      "Rank: 5\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "nodes_0: 240\n",
      "nodes_1: 240\n",
      "nodes_2: 240\n",
      "nodes_3: 80\n",
      "nodes_4: 192\n",
      "Validation Loss: 0.0003300193347968161\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch the full details of the top 5 trials\n",
    "top_trials = tuner.oracle.get_best_trials(num_trials=5)\n",
    "\n",
    "# Print the details of the top 5 trials\n",
    "for i, trial in enumerate(top_trials):\n",
    "    print(f\"Rank: {i+1}\")\n",
    "    print(\"Hyperparameters:\")\n",
    "    for hp, value in trial.hyperparameters.values.items():\n",
    "        print(f\"{hp}: {value}\")\n",
    "    \n",
    "    # Include the validation loss for each model\n",
    "    val_loss = trial.score\n",
    "    print(f\"Validation Loss: {val_loss}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdc63bef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 04m 43s]\n",
      "val_loss: 7.932871248783613e-09\n",
      "\n",
      "Best val_loss So Far: 2.423600875545162e-09\n",
      "Total elapsed time: 01h 34m 42s\n"
     ]
    }
   ],
   "source": [
    "# Tuning Batch Size and Learning Rate\n",
    "# 'tuner' is the previous tuner instance\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Retrieve best number of layers and nodes per layer\n",
    "best_num_layers = best_hp.get('num_layers')\n",
    "best_nodes_per_layer = [best_hp.get(f'nodes_{i}') for i in range(best_num_layers)]\n",
    "\n",
    "\n",
    "def build_autoencoder_for_tuning(hp):\n",
    "    input_shape = X_train_f.shape[1:]  \n",
    "\n",
    "    # Encoder\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "    x = encoder_input\n",
    "    \n",
    "    # Fixed architecture from previous tuning\n",
    "    for i in range(best_num_layers):  \n",
    "        layer_size = best_nodes_per_layer[i]\n",
    "        x = layers.Dense(layer_size, activation=keras.layers.LeakyReLU(alpha=0.01))(x) \n",
    "\n",
    "    # Latent space\n",
    "    latent_space = layers.Dense(2)(x)\n",
    "\n",
    "    # Decoder (mirroring the encoder)\n",
    "    for layer_size in reversed(best_nodes_per_layer):\n",
    "        x = layers.Dense(layer_size, activation=keras.layers.LeakyReLU(alpha=0.01))(x)  \n",
    "\n",
    "    decoder_output = layers.Dense(input_shape[0], activation='linear')(x)\n",
    "\n",
    "    # Autoencoder model\n",
    "    autoencoder = models.Model(encoder_input, decoder_output)\n",
    "\n",
    "    # Hyperparameters for optimizer: learning rate\n",
    "    lr = hp.Float('learning_rate', min_value=1e-5, max_value=1e-2, sampling='log')\n",
    "    batch_size = hp.Int('batch_size', min_value=32, max_value=528, step=16)\n",
    "    \n",
    "    # Compile the model\n",
    "    autoencoder.compile(optimizer=optimizers.Adam(learning_rate=lr), loss='mse')\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Set up a new tuner instance for the extended search\n",
    "batch_size_tuner = BayesianOptimization(\n",
    "    build_autoencoder_for_tuning,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    num_initial_points=5,\n",
    "    directory='AE_Tuning_MO',\n",
    "    project_name='AET_LR_BS_MO'\n",
    ")\n",
    "\n",
    "# Start the new tuning session\n",
    "batch_size_tuner.search(\n",
    "    X_train_f, X_train_f,  \n",
    "    validation_data=(X_valid_f, X_valid_f),  \n",
    "    epochs=50\n",
    ")\n",
    "\n",
    "# Retrieve the best hyperparameters after batch size and learning rate tuning\n",
    "best_batch_lr_hp = batch_size_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# After batch size and learning rate tuning is complete\n",
    "update_best_overall(batch_size_tuner, 'batch_size_lr', additional_details={\n",
    "    'batch_size': best_batch_lr_hp.get('batch_size'),\n",
    "    'learning_rate': best_batch_lr_hp.get('learning_rate')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bb0e2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best batch size: 368\n",
      "Best learning rate: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# Fetching the best hyperparameters after the search is completed\n",
    "best_hp = batch_size_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Retrieve and print best batch size & learning rate\n",
    "best_batch_size = best_hp.get('batch_size')\n",
    "best_learning_rate = best_hp.get('learning_rate')\n",
    "\n",
    "print(f\"Best batch size: {best_batch_size}\")\n",
    "print(f\"Best learning rate: {best_learning_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15ceb3d0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 01m 02s]\n",
      "val_loss: 0.00010340098378947005\n",
      "\n",
      "Best val_loss So Far: 8.485481117759264e-08\n",
      "Total elapsed time: 00h 51m 39s\n"
     ]
    }
   ],
   "source": [
    "# Testing Activation Functions\n",
    "# 'tuner' is tuner instance for architecture\n",
    "best_architecture_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# 'batch_size_tuner' tuner instance for batch size and learning rate\n",
    "best_batch_lr_hp = batch_size_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Retrieve best architecture hyperparameters\n",
    "best_num_layers = best_architecture_hp.get('num_layers')\n",
    "best_nodes_per_layer = [best_architecture_hp.get(f'nodes_{i}') for i in range(best_num_layers)]\n",
    "\n",
    "# Retrieve best batch size and learning rate\n",
    "best_batch_size = best_batch_lr_hp.get('batch_size')\n",
    "best_learning_rate = best_batch_lr_hp.get('learning_rate')\n",
    "\n",
    "\n",
    "def build_autoencoder_for_activation_tuning(hp):\n",
    "    input_shape = X_train_f.shape[1:]  \n",
    "\n",
    "    # Encoder\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "    x = encoder_input\n",
    "    \n",
    "    # List to hold activation functions for each layer in the encoder\n",
    "    activation_functions = []\n",
    "\n",
    "    # Architecture based on previous tuning\n",
    "    for i in range(best_num_layers):  \n",
    "        layer_size = best_nodes_per_layer[i]\n",
    "        # Define hyperparameter for activation function for each layer in the encoder\n",
    "        activation_choice = hp.Choice(f'encoder_activation_{i}', values=['relu', 'sigmoid', 'tanh', 'LeakyReLU'])\n",
    "        activation_functions.append(activation_choice)\n",
    "\n",
    "        if activation_choice == 'LeakyReLU':\n",
    "            x = layers.Dense(layer_size)(x)\n",
    "            x = layers.LeakyReLU(alpha=0.01)(x)\n",
    "        else:\n",
    "            x = layers.Dense(layer_size, activation=activation_choice)(x)\n",
    "\n",
    "    # Latent space\n",
    "    latent_space = layers.Dense(2)(x)  # Assuming a latent space size of 2\n",
    "\n",
    "    # Decoder (mirroring the encoder with symmetrical activation functions)\n",
    "    for i, layer_size in enumerate(reversed(best_nodes_per_layer)):\n",
    "        # Retrieve activation function symmetrically\n",
    "        activation_choice = activation_functions[-(i + 1)]\n",
    "\n",
    "        if activation_choice == 'LeakyReLU':\n",
    "            x = layers.Dense(layer_size)(x)\n",
    "            x = layers.LeakyReLU(alpha=0.01)(x)\n",
    "        else:\n",
    "            x = layers.Dense(layer_size, activation=activation_choice)(x)\n",
    "\n",
    "    decoder_output = layers.Dense(input_shape[0], activation='linear')(x)\n",
    "\n",
    "    # Autoencoder model\n",
    "    autoencoder = models.Model(encoder_input, decoder_output)\n",
    "\n",
    "    # Compile the model with fixed learning rate from previous tuning\n",
    "    autoencoder.compile(optimizer=optimizers.Adam(learning_rate=best_learning_rate), loss='mse')\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# Set up a new tuner instance for the activation function search\n",
    "activation_tuner = BayesianOptimization(\n",
    "    build_autoencoder_for_activation_tuning,\n",
    "    objective='val_loss',\n",
    "    max_trials=50,     \n",
    "    executions_per_trial=1,\n",
    "    num_initial_points=10,\n",
    "    directory='AE_Tuning_MO',\n",
    "    project_name='AET_AF_MO'\n",
    ")\n",
    "\n",
    "# Start the new tuning session with fixed batch size\n",
    "activation_tuner.search(\n",
    "    X_train_f, X_train_f,  \n",
    "    validation_data=(X_valid_f, X_valid_f),  \n",
    "    epochs=50,\n",
    "    batch_size=best_batch_size  # Fixed batch size from previous tuning\n",
    ")\n",
    "\n",
    "# Retrieve the best hyperparameters after activation function tuning\n",
    "best_activation_hp = activation_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# After activation function tuning is complete\n",
    "update_best_overall(activation_tuner, 'activation', additional_details={\n",
    "    'activations': [best_activation_hp.get(f'encoder_activation_{i}') for i in range(best_num_layers)]\n",
    "})"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2391b875",
   "metadata": {},
   "source": [
    "# Model Summary & Results\n",
    "best_hp = activation_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Build the best model\n",
    "best_model = build_autoencoder_for_activation_tuning(best_hp)\n",
    "\n",
    "# Compile a list of the best activation functions\n",
    "best_activations = [best_hp.get(f'activation_{i}') for i in range(best_num_layers)]\n",
    "\n",
    "# Print the optimal combination of activation functions\n",
    "print(\"Best activation functions per layer:\")\n",
    "for i, activation in enumerate(best_activations):\n",
    "    print(f\"Layer {i+1}: {activation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e584993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 9 Complete [00h 00m 58s]\n",
      "val_loss: 0.6441479921340942\n",
      "\n",
      "Best val_loss So Far: 2.041889501924743e-07\n",
      "Total elapsed time: 00h 08m 37s\n"
     ]
    }
   ],
   "source": [
    "# Tuning Loss Function and Optimizer\n",
    "# 'tuner' is tuner instance for architecture\n",
    "best_architecture_hp = tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# 'batch_size_tuner' is tuner instance for batch size and learning rate\n",
    "best_batch_lr_hp = batch_size_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# 'activation_tuner' is tuner instance for activation\n",
    "best_activation_hp = activation_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Retrieve best architecture hyperparameters\n",
    "best_num_layers = best_architecture_hp.get('num_layers')\n",
    "best_nodes_per_layer = [best_architecture_hp.get(f'nodes_{i}') for i in range(best_num_layers)]\n",
    "\n",
    "# Retrieve the best activation functions for each layer from the activation tuner\n",
    "best_activations = [best_activation_hp.get(f'encoder_activation_{i}') for i in range(best_num_layers)]\n",
    "\n",
    "# Retrieve best batch size and learning rate\n",
    "best_batch_size = best_batch_lr_hp.get('batch_size')\n",
    "best_learning_rate = best_batch_lr_hp.get('learning_rate')\n",
    "\n",
    "def build_autoencoder_for_final_tuning(hp):\n",
    "    input_shape = X_train_f.shape[1:]\n",
    "\n",
    "    # Encoder\n",
    "    encoder_input = keras.Input(shape=input_shape)\n",
    "    x = encoder_input\n",
    "    \n",
    "    # Architecture based on previous tuning, with symmetrical activation functions\n",
    "    for i in range(best_num_layers):  \n",
    "        layer_size = best_nodes_per_layer[i]\n",
    "        activation_choice = best_activations[i]  # Use best activation from the activation tuner\n",
    "\n",
    "        if activation_choice == 'LeakyReLU':\n",
    "            x = layers.Dense(layer_size)(x)\n",
    "            x = layers.LeakyReLU(alpha=0.01)(x)\n",
    "        else:\n",
    "            x = layers.Dense(layer_size, activation=activation_choice)(x)\n",
    "\n",
    "    # Latent space\n",
    "    latent_space = layers.Dense(2)(x)\n",
    "\n",
    "    # Decoder (mirroring the encoder)\n",
    "    for i, layer_size in enumerate(reversed(best_nodes_per_layer)):\n",
    "        activation_choice = best_activations[-(i + 1)]  # Retrieve activation function symmetrically\n",
    "\n",
    "        if activation_choice == 'LeakyReLU':\n",
    "            x = layers.Dense(layer_size)(x)\n",
    "            x = layers.LeakyReLU(alpha=0.01)(x)\n",
    "        else:\n",
    "            x = layers.Dense(layer_size, activation=activation_choice)(x)\n",
    "\n",
    "    decoder_output = layers.Dense(input_shape[0], activation='linear')(x)\n",
    "\n",
    "    # Autoencoder model\n",
    "    autoencoder = models.Model(encoder_input, decoder_output)\n",
    "\n",
    "    # Hyperparameters for optimizer and loss function\n",
    "    optimizer_name = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop'])\n",
    "    loss_function = hp.Choice('loss_function', values=['mse', 'binary_crossentropy', 'mae'])\n",
    "\n",
    "    # Compile the model with hyperparameters\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = optimizers.Adam(learning_rate=best_learning_rate)\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = optimizers.SGD(learning_rate=best_learning_rate)\n",
    "    elif optimizer_name == 'rmsprop':\n",
    "        optimizer = optimizers.RMSprop(learning_rate=best_learning_rate)\n",
    "    \n",
    "    autoencoder.compile(optimizer=optimizer, loss=loss_function)\n",
    "\n",
    "    return autoencoder\n",
    "\n",
    "# New tuner instance for the loss function and optimizer search\n",
    "final_tuner = BayesianOptimization(\n",
    "    build_autoencoder_for_final_tuning,\n",
    "    objective='val_loss',\n",
    "    max_trials=50,\n",
    "    executions_per_trial=1,\n",
    "    num_initial_points=10,\n",
    "    directory='AE_Tuning_MO',\n",
    "    project_name='AET_LF_Opt_MO'\n",
    ")\n",
    "\n",
    "# Start new tuning session with fixed batch size\n",
    "final_tuner.search(\n",
    "    X_train_f, X_train_f,\n",
    "    validation_data=(X_valid_f, X_valid_f),\n",
    "    epochs=50,\n",
    "    batch_size=best_batch_size  # Fixed batch size from previous tuning\n",
    ")\n",
    "\n",
    "# Retrieve the best hyperparameters after loss function and optimizer tuning\n",
    "best_final_hyperparams = final_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# After loss function and optimizer tuning is complete\n",
    "update_best_overall(final_tuner, 'loss_optimizer', additional_details={\n",
    "    'loss_function': best_final_hyperparams.get('loss_function'),\n",
    "    'optimizer': best_final_hyperparams.get('optimizer')\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7dd2010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Loss Function: mse\n",
      "Best Optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "# Fetch the best hyperparameters after the final tuning session\n",
    "best_final_hp = final_tuner.get_best_hyperparameters()[0]\n",
    "\n",
    "# Retrieve the best loss function and optimizer\n",
    "best_loss_function = best_final_hp.get('loss_function')\n",
    "best_optimizer = best_final_hp.get('optimizer')\n",
    "\n",
    "# Print the results\n",
    "print(f\"Best Loss Function: {best_loss_function}\")\n",
    "print(f\"Best Optimizer: {best_optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6768eb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best global validation loss achieved at step: batch_size_lr\n",
      "With Validation Loss: 2.423600875545162e-09\n",
      "Best Hyperparameters:\n",
      "batch_size: 368\n",
      "learning_rate: 1e-05\n"
     ]
    }
   ],
   "source": [
    "# Print Best Global Validation Loss and Hyperparameters\n",
    "print(f\"Best global validation loss achieved at step: {best_overall['step']}\")\n",
    "print(f\"With Validation Loss: {best_overall['loss']}\")\n",
    "\n",
    "# Printing details depending on the step\n",
    "if best_overall['step'] in best_overall['details']:\n",
    "    print(\"Best Hyperparameters:\")\n",
    "    for key, value in best_overall['details'][best_overall['step']].items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeac7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
