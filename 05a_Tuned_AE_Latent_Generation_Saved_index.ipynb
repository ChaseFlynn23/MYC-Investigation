{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09327dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 15:07:08.550221: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-28 15:07:08.550265: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-28 15:07:08.550299: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-28 15:07:08.559075: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-28 15:07:09.593787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import glob\n",
    "import sklearn \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers, models, optimizers\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, Callback\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from keras_tuner import BayesianOptimization, HyperParameters\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5e0bf33",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.3249</td>\n",
       "      <td>9.6718</td>\n",
       "      <td>6.0082</td>\n",
       "      <td>9.6574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3105</td>\n",
       "      <td>10.6216</td>\n",
       "      <td>5.9996</td>\n",
       "      <td>11.2509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.7233</td>\n",
       "      <td>11.4243</td>\n",
       "      <td>7.3021</td>\n",
       "      <td>11.5329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.4864</td>\n",
       "      <td>10.7079</td>\n",
       "      <td>6.4156</td>\n",
       "      <td>10.7262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4673</td>\n",
       "      <td>12.0023</td>\n",
       "      <td>6.3573</td>\n",
       "      <td>11.2367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>4.9712</td>\n",
       "      <td>8.9677</td>\n",
       "      <td>10.1179</td>\n",
       "      <td>8.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>4.8021</td>\n",
       "      <td>9.0623</td>\n",
       "      <td>10.1026</td>\n",
       "      <td>8.6752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>5.9590</td>\n",
       "      <td>10.3438</td>\n",
       "      <td>8.6309</td>\n",
       "      <td>9.4556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>4.3996</td>\n",
       "      <td>10.3760</td>\n",
       "      <td>9.5901</td>\n",
       "      <td>9.3513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>5.2675</td>\n",
       "      <td>10.8606</td>\n",
       "      <td>8.6371</td>\n",
       "      <td>9.7884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            7       20       26       27\n",
       "0      6.3249   9.6718   6.0082   9.6574\n",
       "1      6.3105  10.6216   5.9996  11.2509\n",
       "2      5.7233  11.4243   7.3021  11.5329\n",
       "3      5.4864  10.7079   6.4156  10.7262\n",
       "4      5.4673  12.0023   6.3573  11.2367\n",
       "...       ...      ...      ...      ...\n",
       "39995  4.9712   8.9677  10.1179   8.9430\n",
       "39996  4.8021   9.0623  10.1026   8.6752\n",
       "39997  5.9590  10.3438   8.6309   9.4556\n",
       "39998  4.3996  10.3760   9.5901   9.3513\n",
       "39999  5.2675  10.8606   8.6371   9.7884\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.9702</td>\n",
       "      <td>17.3049</td>\n",
       "      <td>22.7152</td>\n",
       "      <td>30.7508</td>\n",
       "      <td>24.7567</td>\n",
       "      <td>23.1634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.2704</td>\n",
       "      <td>22.4792</td>\n",
       "      <td>22.4227</td>\n",
       "      <td>28.1640</td>\n",
       "      <td>23.8363</td>\n",
       "      <td>23.2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.8551</td>\n",
       "      <td>25.5636</td>\n",
       "      <td>24.6903</td>\n",
       "      <td>30.2936</td>\n",
       "      <td>24.8655</td>\n",
       "      <td>23.4604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.3881</td>\n",
       "      <td>26.4733</td>\n",
       "      <td>24.4458</td>\n",
       "      <td>29.5746</td>\n",
       "      <td>21.3842</td>\n",
       "      <td>22.6630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.2788</td>\n",
       "      <td>24.0147</td>\n",
       "      <td>23.2922</td>\n",
       "      <td>27.5496</td>\n",
       "      <td>23.8249</td>\n",
       "      <td>22.3185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>19.7170</td>\n",
       "      <td>14.7258</td>\n",
       "      <td>12.9418</td>\n",
       "      <td>8.4287</td>\n",
       "      <td>24.3534</td>\n",
       "      <td>22.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>17.8741</td>\n",
       "      <td>15.5602</td>\n",
       "      <td>12.3054</td>\n",
       "      <td>7.1757</td>\n",
       "      <td>24.9417</td>\n",
       "      <td>24.1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>17.2324</td>\n",
       "      <td>15.4532</td>\n",
       "      <td>12.3721</td>\n",
       "      <td>7.1490</td>\n",
       "      <td>23.8513</td>\n",
       "      <td>27.4276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>17.0120</td>\n",
       "      <td>15.1188</td>\n",
       "      <td>13.4625</td>\n",
       "      <td>7.5725</td>\n",
       "      <td>25.4096</td>\n",
       "      <td>26.8701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>16.6571</td>\n",
       "      <td>15.4409</td>\n",
       "      <td>13.2021</td>\n",
       "      <td>7.2976</td>\n",
       "      <td>26.2683</td>\n",
       "      <td>24.6460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             6       16       17       19       29       30\n",
       "0      14.9702  17.3049  22.7152  30.7508  24.7567  23.1634\n",
       "1      13.2704  22.4792  22.4227  28.1640  23.8363  23.2798\n",
       "2      13.8551  25.5636  24.6903  30.2936  24.8655  23.4604\n",
       "3      12.3881  26.4733  24.4458  29.5746  21.3842  22.6630\n",
       "4      14.2788  24.0147  23.2922  27.5496  23.8249  22.3185\n",
       "...        ...      ...      ...      ...      ...      ...\n",
       "39995  19.7170  14.7258  12.9418   8.4287  24.3534  22.6400\n",
       "39996  17.8741  15.5602  12.3054   7.1757  24.9417  24.1508\n",
       "39997  17.2324  15.4532  12.3721   7.1490  23.8513  27.4276\n",
       "39998  17.0120  15.1188  13.4625   7.5725  25.4096  26.8701\n",
       "39999  16.6571  15.4409  13.2021   7.2976  26.2683  24.6460\n",
       "\n",
       "[40000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WT for window size = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.2374</td>\n",
       "      <td>40.1886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.5602</td>\n",
       "      <td>36.3229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.4329</td>\n",
       "      <td>41.2223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20.1207</td>\n",
       "      <td>39.2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.6335</td>\n",
       "      <td>38.7009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>16.9755</td>\n",
       "      <td>31.9599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>17.0192</td>\n",
       "      <td>29.9824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>18.5272</td>\n",
       "      <td>29.4126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>17.1766</td>\n",
       "      <td>32.6983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>17.7794</td>\n",
       "      <td>33.5279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             9       21\n",
       "0      14.2374  40.1886\n",
       "1      14.5602  36.3229\n",
       "2      17.4329  41.2223\n",
       "3      20.1207  39.2809\n",
       "4      15.6335  38.7009\n",
       "...        ...      ...\n",
       "39995  16.9755  31.9599\n",
       "39996  17.0192  29.9824\n",
       "39997  18.5272  29.4126\n",
       "39998  17.1766  32.6983\n",
       "39999  17.7794  33.5279\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---------------------------------\n",
      "D132H for window size = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>20</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.6253</td>\n",
       "      <td>11.4558</td>\n",
       "      <td>7.0366</td>\n",
       "      <td>10.8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.6219</td>\n",
       "      <td>11.7791</td>\n",
       "      <td>6.8272</td>\n",
       "      <td>10.8156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.3355</td>\n",
       "      <td>9.9860</td>\n",
       "      <td>6.2585</td>\n",
       "      <td>9.7506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7119</td>\n",
       "      <td>8.4264</td>\n",
       "      <td>5.8994</td>\n",
       "      <td>8.1239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.7166</td>\n",
       "      <td>9.3508</td>\n",
       "      <td>6.4404</td>\n",
       "      <td>10.1599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>4.6642</td>\n",
       "      <td>10.3721</td>\n",
       "      <td>10.9673</td>\n",
       "      <td>9.8788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>4.7521</td>\n",
       "      <td>11.6737</td>\n",
       "      <td>10.7638</td>\n",
       "      <td>9.5196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>4.5160</td>\n",
       "      <td>9.7824</td>\n",
       "      <td>10.9669</td>\n",
       "      <td>9.6701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>4.8358</td>\n",
       "      <td>7.8161</td>\n",
       "      <td>10.7679</td>\n",
       "      <td>9.6355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>4.5663</td>\n",
       "      <td>10.1266</td>\n",
       "      <td>10.9913</td>\n",
       "      <td>9.2231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            7       20       26       27\n",
       "0      5.6253  11.4558   7.0366  10.8265\n",
       "1      5.6219  11.7791   6.8272  10.8156\n",
       "2      6.3355   9.9860   6.2585   9.7506\n",
       "3      4.7119   8.4264   5.8994   8.1239\n",
       "4      7.7166   9.3508   6.4404  10.1599\n",
       "...       ...      ...      ...      ...\n",
       "39995  4.6642  10.3721  10.9673   9.8788\n",
       "39996  4.7521  11.6737  10.7638   9.5196\n",
       "39997  4.5160   9.7824  10.9669   9.6701\n",
       "39998  4.8358   7.8161  10.7679   9.6355\n",
       "39999  4.5663  10.1266  10.9913   9.2231\n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D132H for window size = 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>19</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.9958</td>\n",
       "      <td>16.3721</td>\n",
       "      <td>20.6416</td>\n",
       "      <td>29.6048</td>\n",
       "      <td>24.1730</td>\n",
       "      <td>23.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0499</td>\n",
       "      <td>15.4543</td>\n",
       "      <td>20.4593</td>\n",
       "      <td>28.2314</td>\n",
       "      <td>25.1477</td>\n",
       "      <td>23.0454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.5011</td>\n",
       "      <td>13.1972</td>\n",
       "      <td>16.8349</td>\n",
       "      <td>29.2049</td>\n",
       "      <td>23.6181</td>\n",
       "      <td>18.1444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.6412</td>\n",
       "      <td>15.6381</td>\n",
       "      <td>18.6334</td>\n",
       "      <td>27.5069</td>\n",
       "      <td>25.6890</td>\n",
       "      <td>20.3013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.5941</td>\n",
       "      <td>18.8374</td>\n",
       "      <td>20.8179</td>\n",
       "      <td>29.7816</td>\n",
       "      <td>23.7772</td>\n",
       "      <td>20.6936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>13.3469</td>\n",
       "      <td>15.4144</td>\n",
       "      <td>13.0795</td>\n",
       "      <td>12.4362</td>\n",
       "      <td>7.2937</td>\n",
       "      <td>12.2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>13.3072</td>\n",
       "      <td>15.0391</td>\n",
       "      <td>12.4597</td>\n",
       "      <td>12.2133</td>\n",
       "      <td>7.2107</td>\n",
       "      <td>13.3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>13.4729</td>\n",
       "      <td>15.5238</td>\n",
       "      <td>12.5300</td>\n",
       "      <td>12.2077</td>\n",
       "      <td>7.7544</td>\n",
       "      <td>12.6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>12.8318</td>\n",
       "      <td>15.9725</td>\n",
       "      <td>13.9111</td>\n",
       "      <td>12.2538</td>\n",
       "      <td>7.3585</td>\n",
       "      <td>12.1032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>13.2777</td>\n",
       "      <td>15.6850</td>\n",
       "      <td>13.5851</td>\n",
       "      <td>12.3831</td>\n",
       "      <td>7.2522</td>\n",
       "      <td>12.8442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             6       16       17       19       29       30\n",
       "0      14.9958  16.3721  20.6416  29.6048  24.1730  23.9425\n",
       "1      15.0499  15.4543  20.4593  28.2314  25.1477  23.0454\n",
       "2      16.5011  13.1972  16.8349  29.2049  23.6181  18.1444\n",
       "3      13.6412  15.6381  18.6334  27.5069  25.6890  20.3013\n",
       "4      16.5941  18.8374  20.8179  29.7816  23.7772  20.6936\n",
       "...        ...      ...      ...      ...      ...      ...\n",
       "39995  13.3469  15.4144  13.0795  12.4362   7.2937  12.2014\n",
       "39996  13.3072  15.0391  12.4597  12.2133   7.2107  13.3563\n",
       "39997  13.4729  15.5238  12.5300  12.2077   7.7544  12.6172\n",
       "39998  12.8318  15.9725  13.9111  12.2538   7.3585  12.1032\n",
       "39999  13.2777  15.6850  13.5851  12.3831   7.2522  12.8442\n",
       "\n",
       "[40000 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D132H for window size = 20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.4055</td>\n",
       "      <td>41.6856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.0150</td>\n",
       "      <td>40.2262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.0081</td>\n",
       "      <td>41.7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.6520</td>\n",
       "      <td>40.4408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.7450</td>\n",
       "      <td>38.0932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>14.0324</td>\n",
       "      <td>23.2605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>14.9455</td>\n",
       "      <td>22.4160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>14.0516</td>\n",
       "      <td>22.7481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>14.0350</td>\n",
       "      <td>23.5958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>14.3382</td>\n",
       "      <td>22.8859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             9       21\n",
       "0      13.4055  41.6856\n",
       "1      12.0150  40.2262\n",
       "2      17.0081  41.7220\n",
       "3      15.6520  40.4408\n",
       "4      20.7450  38.0932\n",
       "...        ...      ...\n",
       "39995  14.0324  23.2605\n",
       "39996  14.9455  22.4160\n",
       "39997  14.0516  22.7481\n",
       "39998  14.0350  23.5958\n",
       "39999  14.3382  22.8859\n",
       "\n",
       "[40000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data import\n",
    "wt_filtered = ['wt_filtered_lcc_3_50.lccdata', 'wt_filtered_lcc_12_50.lccdata', 'wt_filtered_lcc_20_50.lccdata']\n",
    "\n",
    "# filtered wt LCC data import\n",
    "wt_f_var_names = ['wt_3f', 'wt_12f', 'wt_20f']\n",
    "\n",
    "for var, file in zip(wt_f_var_names, wt_filtered):\n",
    "    globals()[var] = pd.read_csv(file, sep='\\t').drop(columns='Unnamed: 0')\n",
    "\n",
    "# filtered mutant LCC data import\n",
    "D132H_filtered = ['D132H_filtered_lcc_3_50.lccdata', 'D132H_filtered_lcc_12_50.lccdata', 'D132H_filtered_lcc_20_50.lccdata']\n",
    "D132H_f_var_names = ['D132H_3f', 'D132H_12f', 'D132H_20f']\n",
    "\n",
    "for var, file in zip(D132H_f_var_names, D132H_filtered):\n",
    "    globals()[var] = pd.read_csv(file, sep='\\t').drop(columns='Unnamed: 0')\n",
    "    \n",
    "# Visualization of dataset\n",
    "print('WT for window size = 3')\n",
    "display(wt_3f)\n",
    "print('WT for window size = 12')\n",
    "display(wt_12f)\n",
    "print('WT for window size = 20')\n",
    "display(wt_20f)\n",
    "\n",
    "print('\\n')\n",
    "print('---------------------------------')\n",
    "print('D132H for window size = 3')\n",
    "display(D132H_3f)\n",
    "print('D132H for window size = 12')\n",
    "display(D132H_12f)\n",
    "print('D132H for window size = 20')\n",
    "display(D132H_20f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc552490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concateneate wt and mutant dataframes and rename columns\n",
    "\n",
    "wt_f = pd.concat([wt_3f, wt_12f, wt_20f], axis = 1)\n",
    "    \n",
    "D132H_f = pd.concat([D132H_3f, D132H_12f, D132H_20f], axis = 1)\n",
    "D132H_f.index = range(40000, 40000 + len(D132H_f)) # Modifying index of D132H so that there are no duplicate indices\n",
    "\n",
    "colnames = [*range(0,12)]\n",
    "colnames\n",
    "wt_f.columns = colnames\n",
    "D132H_f.columns = colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa0b2f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(wt, mutant):\n",
    "    \n",
    "    wt_label = np.zeros(len(wt))  # Set wt labels to 0\n",
    "    mutant_label = np.ones(len(mutant))  # Set mutant labels to 1\n",
    "\n",
    "    # Create label dataframes with indices\n",
    "    wt_label_df = pd.DataFrame({'class': wt_label})\n",
    "    mutant_label_df = pd.DataFrame({'class': mutant_label}, index=range(40000, 40000 + len(mutant)))\n",
    "\n",
    "    # Concatenate data frames and label dataframes\n",
    "    X_train_full = pd.concat([wt, mutant])\n",
    "    y_train_full_df = pd.concat([wt_label_df, mutant_label_df])\n",
    "\n",
    "    # Normalize training data\n",
    "    X_train_full = X_train_full.div(100)  # Adjust as necessary\n",
    "\n",
    "    # Separate training and validation sets\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full_df, stratify=y_train_full_df['class'], test_size=0.2)\n",
    "\n",
    "    print(X_train.shape)\n",
    "    print(X_valid.shape)\n",
    "    print(y_train.shape)\n",
    "    print(y_valid.shape)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3072ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64000, 12)\n",
      "(16000, 12)\n",
      "(64000, 1)\n",
      "(16000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train_f, X_valid_f, y_train_f, y_valid_f = preprocessing(wt_f, D132H_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f91c758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get autoencoder model\n",
    "def get_ae(train_data, LeReLU_alpha=0.01):\n",
    "    \n",
    "    #Input layer\n",
    "    input_layer = Input(shape=(train_data.shape[1]), name='ae_input')\n",
    "    \n",
    "    encoder = Dense(336, activation=LeakyReLU(alpha=LeReLU_alpha), name='e1')(input_layer)\n",
    "    encoder = Dense(208, activation=LeakyReLU(alpha=LeReLU_alpha), name='e2')(encoder)\n",
    "    encoder = Dense(240, activation=LeakyReLU(alpha=LeReLU_alpha), name='e3')(encoder)\n",
    "\n",
    "    encoded = Dense(2, activation=LeakyReLU(alpha=LeReLU_alpha), name='ae_latent')(encoder)\n",
    "    \n",
    "    decoder = Dense(240, activation=LeakyReLU(alpha=LeReLU_alpha), name='d1')(encoded)\n",
    "    decoder = Dense(208, activation=LeakyReLU(alpha=LeReLU_alpha), name='d2')(decoder)\n",
    "    decoder = Dense(336, activation=LeakyReLU(alpha=LeReLU_alpha), name='d3')(decoder)\n",
    "\n",
    "    output_layer = Dense(train_data.shape[1], activation=LeakyReLU(alpha=LeReLU_alpha), name='ae_output')(decoder)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f15476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-28 15:07:25.249448: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "# Get ae for filtered data\n",
    "autoencoder = get_ae(X_train_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0364035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " ae_input (InputLayer)       [(None, 12)]              0         \n",
      "                                                                 \n",
      " e1 (Dense)                  (None, 336)               4368      \n",
      "                                                                 \n",
      " e2 (Dense)                  (None, 208)               70096     \n",
      "                                                                 \n",
      " e3 (Dense)                  (None, 240)               50160     \n",
      "                                                                 \n",
      " ae_latent (Dense)           (None, 2)                 482       \n",
      "                                                                 \n",
      " d1 (Dense)                  (None, 240)               720       \n",
      "                                                                 \n",
      " d2 (Dense)                  (None, 208)               50128     \n",
      "                                                                 \n",
      " d3 (Dense)                  (None, 336)               70224     \n",
      "                                                                 \n",
      " ae_output (Dense)           (None, 12)                4044      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 250222 (977.43 KB)\n",
      "Trainable params: 250222 (977.43 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Print summary of ae model\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a20e45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "autoencoder.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam(learning_rate = 0.00001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1088d8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"AET_CF_Trial_14\"\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "name = \"14_LSP_AET_CF_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ac9dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_f.to_csv(f'{folder_name}/X_train_f.csv')\n",
    "y_train_f.to_csv(f'{folder_name}/y_train_f.csv')\n",
    "\n",
    "X_valid_f.to_csv(f'{folder_name}/X_valid_f.csv')\n",
    "y_valid_f.to_csv(f'{folder_name}/y_valid_f.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe077b70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                    | 0/57 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 0.0201 - val_loss: 0.0159\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 26/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.8734e-04 - val_loss: 9.8017e-04\n",
      "Epoch 27/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.6991e-04 - val_loss: 9.6505e-04\n",
      "Epoch 28/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.5758e-04 - val_loss: 9.5443e-04\n",
      "Epoch 29/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.4823e-04 - val_loss: 9.4668e-04\n",
      "Epoch 30/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.4051e-04 - val_loss: 9.3925e-04\n",
      "Epoch 31/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.3408e-04 - val_loss: 9.3370e-04\n",
      "Epoch 32/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.2818e-04 - val_loss: 9.2831e-04\n",
      "Epoch 33/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.2296e-04 - val_loss: 9.2248e-04\n",
      "Epoch 34/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.1787e-04 - val_loss: 9.1870e-04\n",
      "Epoch 35/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.1341e-04 - val_loss: 9.1394e-04\n",
      "Epoch 36/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.0914e-04 - val_loss: 9.1009e-04\n",
      "Epoch 37/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.0544e-04 - val_loss: 9.0564e-04\n",
      "Epoch 38/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 9.0169e-04 - val_loss: 9.0192e-04\n",
      "Epoch 39/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.9838e-04 - val_loss: 8.9861e-04\n",
      "Epoch 40/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.9474e-04 - val_loss: 8.9545e-04\n",
      "Epoch 41/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.9152e-04 - val_loss: 8.9156e-04\n",
      "Epoch 42/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.8796e-04 - val_loss: 8.8868e-04\n",
      "Epoch 43/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.8478e-04 - val_loss: 8.8522e-04\n",
      "Epoch 44/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.8180e-04 - val_loss: 8.8331e-04\n",
      "Epoch 45/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.7868e-04 - val_loss: 8.7964e-04\n",
      "Epoch 46/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.7607e-04 - val_loss: 8.7636e-04\n",
      "Epoch 47/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.7324e-04 - val_loss: 8.7374e-04\n",
      "Epoch 48/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.7055e-04 - val_loss: 8.7136e-04\n",
      "Epoch 49/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.6814e-04 - val_loss: 8.6848e-04\n",
      "Epoch 50/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.6563e-04 - val_loss: 8.6589e-04\n",
      "Epoch 51/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.6338e-04 - val_loss: 8.6384e-04\n",
      "Epoch 52/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.6099e-04 - val_loss: 8.6141e-04\n",
      "Epoch 53/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.5854e-04 - val_loss: 8.5907e-04\n",
      "Epoch 54/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.5609e-04 - val_loss: 8.5627e-04\n",
      "Epoch 55/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.5351e-04 - val_loss: 8.5365e-04\n",
      "Epoch 56/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.5127e-04 - val_loss: 8.5171e-04\n",
      "Epoch 57/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.4888e-04 - val_loss: 8.4881e-04\n",
      "Epoch 58/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.4653e-04 - val_loss: 8.4689e-04\n",
      "Epoch 59/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.4442e-04 - val_loss: 8.4438e-04\n",
      "Epoch 60/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.4233e-04 - val_loss: 8.4245e-04\n",
      "Epoch 61/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.4046e-04 - val_loss: 8.4042e-04\n",
      "Epoch 62/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.3831e-04 - val_loss: 8.3849e-04\n",
      "Epoch 63/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.3639e-04 - val_loss: 8.3642e-04\n",
      "Epoch 64/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.3443e-04 - val_loss: 8.3461e-04\n",
      "Epoch 65/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.3268e-04 - val_loss: 8.3236e-04\n",
      "Epoch 66/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.3066e-04 - val_loss: 8.3065e-04\n",
      "Epoch 67/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.2884e-04 - val_loss: 8.2895e-04\n",
      "Epoch 68/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.2682e-04 - val_loss: 8.2644e-04\n",
      "Epoch 69/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.2493e-04 - val_loss: 8.2473e-04\n",
      "Epoch 70/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.2280e-04 - val_loss: 8.2193e-04\n",
      "Epoch 71/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.2064e-04 - val_loss: 8.1996e-04\n",
      "Epoch 72/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.1840e-04 - val_loss: 8.1747e-04\n",
      "Epoch 73/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.1604e-04 - val_loss: 8.1558e-04\n",
      "Epoch 74/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.1397e-04 - val_loss: 8.1276e-04\n",
      "Epoch 75/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 8.1164e-04 - val_loss: 8.1027e-04\n",
      "Epoch 76/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 8.0931e-04 - val_loss: 8.0806e-04\n",
      "Epoch 77/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 8.0697e-04 - val_loss: 8.0511e-04\n",
      "Epoch 78/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 8.0426e-04 - val_loss: 8.0324e-04\n",
      "Epoch 79/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 8.0201e-04 - val_loss: 8.0052e-04\n",
      "Epoch 80/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.9947e-04 - val_loss: 7.9771e-04\n",
      "Epoch 81/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.9687e-04 - val_loss: 7.9494e-04\n",
      "Epoch 82/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.9439e-04 - val_loss: 7.9246e-04\n",
      "Epoch 83/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.9142e-04 - val_loss: 7.8899e-04\n",
      "Epoch 84/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.8884e-04 - val_loss: 7.8635e-04\n",
      "Epoch 85/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.8596e-04 - val_loss: 7.8405e-04\n",
      "Epoch 86/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.8306e-04 - val_loss: 7.8089e-04\n",
      "Epoch 87/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.8039e-04 - val_loss: 7.7780e-04\n",
      "Epoch 88/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.7713e-04 - val_loss: 7.7406e-04\n",
      "Epoch 89/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.7115e-04 - val_loss: 7.6455e-04\n",
      "Epoch 90/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.5838e-04 - val_loss: 7.5228e-04\n",
      "Epoch 91/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.4420e-04 - val_loss: 7.2664e-04\n",
      "Epoch 92/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 7.0642e-04 - val_loss: 6.7700e-04\n",
      "Epoch 93/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.4808e-04 - val_loss: 6.2002e-04\n",
      "Epoch 94/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 6.0224e-04 - val_loss: 5.8187e-04\n",
      "Epoch 95/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.6939e-04 - val_loss: 5.5778e-04\n",
      "Epoch 96/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.5096e-04 - val_loss: 5.4526e-04\n",
      "Epoch 97/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.4069e-04 - val_loss: 5.3821e-04\n",
      "Epoch 98/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3446e-04 - val_loss: 5.3279e-04\n",
      "Epoch 99/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.3023e-04 - val_loss: 5.2989e-04\n",
      "Epoch 100/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2713e-04 - val_loss: 5.2724e-04\n",
      "Epoch 101/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2472e-04 - val_loss: 5.2523e-04\n",
      "Epoch 102/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 5.2238e-04 - val_loss: 5.2328e-04\n",
      "Epoch 103/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.2025e-04 - val_loss: 5.2163e-04\n",
      "Epoch 104/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1813e-04 - val_loss: 5.1997e-04\n",
      "Epoch 105/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1627e-04 - val_loss: 5.1828e-04\n",
      "Epoch 106/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1455e-04 - val_loss: 5.1680e-04\n",
      "Epoch 107/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1304e-04 - val_loss: 5.1568e-04\n",
      "Epoch 108/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1170e-04 - val_loss: 5.1449e-04\n",
      "Epoch 109/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.1021e-04 - val_loss: 5.1259e-04\n",
      "Epoch 110/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0878e-04 - val_loss: 5.1159e-04\n",
      "Epoch 111/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0736e-04 - val_loss: 5.0991e-04\n",
      "Epoch 112/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0609e-04 - val_loss: 5.0878e-04\n",
      "Epoch 113/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0473e-04 - val_loss: 5.0749e-04\n",
      "Epoch 114/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0356e-04 - val_loss: 5.0606e-04\n",
      "Epoch 115/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0224e-04 - val_loss: 5.0524e-04\n",
      "Epoch 116/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 5.0090e-04 - val_loss: 5.0386e-04\n",
      "Epoch 117/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9962e-04 - val_loss: 5.0234e-04\n",
      "Epoch 118/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9839e-04 - val_loss: 5.0102e-04\n",
      "Epoch 119/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9683e-04 - val_loss: 4.9949e-04\n",
      "Epoch 120/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9510e-04 - val_loss: 4.9749e-04\n",
      "Epoch 121/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9315e-04 - val_loss: 4.9576e-04\n",
      "Epoch 122/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.9144e-04 - val_loss: 4.9394e-04\n",
      "Epoch 123/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8954e-04 - val_loss: 4.9197e-04\n",
      "Epoch 124/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8745e-04 - val_loss: 4.8953e-04\n",
      "Epoch 125/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8526e-04 - val_loss: 4.8728e-04\n",
      "Epoch 126/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8263e-04 - val_loss: 4.8546e-04\n",
      "Epoch 127/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.8015e-04 - val_loss: 4.8278e-04\n",
      "Epoch 128/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7749e-04 - val_loss: 4.8010e-04\n",
      "Epoch 129/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7505e-04 - val_loss: 4.7766e-04\n",
      "Epoch 130/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7283e-04 - val_loss: 4.7593e-04\n",
      "Epoch 131/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.7095e-04 - val_loss: 4.7437e-04\n",
      "Epoch 132/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6908e-04 - val_loss: 4.7265e-04\n",
      "Epoch 133/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6742e-04 - val_loss: 4.7160e-04\n",
      "Epoch 134/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6590e-04 - val_loss: 4.7003e-04\n",
      "Epoch 135/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6458e-04 - val_loss: 4.6863e-04\n",
      "Epoch 136/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6338e-04 - val_loss: 4.6805e-04\n",
      "Epoch 137/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6221e-04 - val_loss: 4.6705e-04\n",
      "Epoch 138/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6114e-04 - val_loss: 4.6581e-04\n",
      "Epoch 139/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.6004e-04 - val_loss: 4.6548e-04\n",
      "Epoch 140/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5912e-04 - val_loss: 4.6454e-04\n",
      "Epoch 141/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5840e-04 - val_loss: 4.6384e-04\n",
      "Epoch 142/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5753e-04 - val_loss: 4.6271e-04\n",
      "Epoch 143/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5673e-04 - val_loss: 4.6201e-04\n",
      "Epoch 144/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5588e-04 - val_loss: 4.6121e-04\n",
      "Epoch 145/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5520e-04 - val_loss: 4.6049e-04\n",
      "Epoch 146/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5455e-04 - val_loss: 4.5960e-04\n",
      "Epoch 147/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5368e-04 - val_loss: 4.5906e-04\n",
      "Epoch 148/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5312e-04 - val_loss: 4.5937e-04\n",
      "Epoch 149/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5213e-04 - val_loss: 4.5808e-04\n",
      "Epoch 150/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5168e-04 - val_loss: 4.5706e-04\n",
      "Epoch 151/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5098e-04 - val_loss: 4.5681e-04\n",
      "Epoch 152/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.5023e-04 - val_loss: 4.5587e-04\n",
      "Epoch 153/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4958e-04 - val_loss: 4.5526e-04\n",
      "Epoch 154/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4897e-04 - val_loss: 4.5468e-04\n",
      "Epoch 155/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4823e-04 - val_loss: 4.5426e-04\n",
      "Epoch 156/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4771e-04 - val_loss: 4.5352e-04\n",
      "Epoch 157/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4715e-04 - val_loss: 4.5291e-04\n",
      "Epoch 158/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4641e-04 - val_loss: 4.5248e-04\n",
      "Epoch 159/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4571e-04 - val_loss: 4.5151e-04\n",
      "Epoch 160/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4526e-04 - val_loss: 4.5093e-04\n",
      "Epoch 161/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4453e-04 - val_loss: 4.5099e-04\n",
      "Epoch 162/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4402e-04 - val_loss: 4.5006e-04\n",
      "Epoch 163/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4352e-04 - val_loss: 4.4976e-04\n",
      "Epoch 164/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4282e-04 - val_loss: 4.4868e-04\n",
      "Epoch 165/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4234e-04 - val_loss: 4.4829e-04\n",
      "Epoch 166/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4180e-04 - val_loss: 4.4772e-04\n",
      "Epoch 167/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4123e-04 - val_loss: 4.4723e-04\n",
      "Epoch 168/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4060e-04 - val_loss: 4.4677e-04\n",
      "Epoch 169/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.4017e-04 - val_loss: 4.4606e-04\n",
      "Epoch 170/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3973e-04 - val_loss: 4.4561e-04\n",
      "Epoch 171/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3916e-04 - val_loss: 4.4522e-04\n",
      "Epoch 172/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3864e-04 - val_loss: 4.4482e-04\n",
      "Epoch 173/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3816e-04 - val_loss: 4.4416e-04\n",
      "Epoch 174/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3764e-04 - val_loss: 4.4367e-04\n",
      "Epoch 175/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3707e-04 - val_loss: 4.4334e-04\n",
      "Epoch 176/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3661e-04 - val_loss: 4.4276e-04\n",
      "Epoch 177/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3618e-04 - val_loss: 4.4215e-04\n",
      "Epoch 178/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3581e-04 - val_loss: 4.4147e-04\n",
      "Epoch 179/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3527e-04 - val_loss: 4.4115e-04\n",
      "Epoch 180/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3469e-04 - val_loss: 4.4173e-04\n",
      "Epoch 181/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 4.3445e-04 - val_loss: 4.4045e-04\n",
      "Epoch 182/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4.3393e-04 - val_loss: 4.3963e-04\n",
      "Epoch 183/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4.3339e-04 - val_loss: 4.3921e-04\n",
      "Epoch 184/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3316e-04 - val_loss: 4.3886e-04\n",
      "Epoch 185/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3249e-04 - val_loss: 4.3888e-04\n",
      "Epoch 186/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3219e-04 - val_loss: 4.3823e-04\n",
      "Epoch 187/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3174e-04 - val_loss: 4.3801e-04\n",
      "Epoch 188/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3137e-04 - val_loss: 4.3733e-04\n",
      "Epoch 189/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3096e-04 - val_loss: 4.3699e-04\n",
      "Epoch 190/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3047e-04 - val_loss: 4.3655e-04\n",
      "Epoch 191/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.3025e-04 - val_loss: 4.3624e-04\n",
      "Epoch 192/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2986e-04 - val_loss: 4.3571e-04\n",
      "Epoch 193/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2953e-04 - val_loss: 4.3515e-04\n",
      "Epoch 194/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4.2897e-04 - val_loss: 4.3489e-04\n",
      "Epoch 195/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2876e-04 - val_loss: 4.3513e-04\n",
      "Epoch 196/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2837e-04 - val_loss: 4.3496e-04\n",
      "Epoch 197/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2800e-04 - val_loss: 4.3396e-04\n",
      "Epoch 198/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2763e-04 - val_loss: 4.3327e-04\n",
      "Epoch 199/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2722e-04 - val_loss: 4.3323e-04\n",
      "Epoch 200/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4.2684e-04 - val_loss: 4.3302e-04\n",
      "Epoch 201/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2657e-04 - val_loss: 4.3286e-04\n",
      "Epoch 202/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2625e-04 - val_loss: 4.3225e-04\n",
      "Epoch 203/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2585e-04 - val_loss: 4.3170e-04\n",
      "Epoch 204/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2555e-04 - val_loss: 4.3147e-04\n",
      "Epoch 205/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2521e-04 - val_loss: 4.3097e-04\n",
      "Epoch 206/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2492e-04 - val_loss: 4.3064e-04\n",
      "Epoch 207/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2441e-04 - val_loss: 4.3011e-04\n",
      "Epoch 208/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2411e-04 - val_loss: 4.2994e-04\n",
      "Epoch 209/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2381e-04 - val_loss: 4.3036e-04\n",
      "Epoch 210/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2343e-04 - val_loss: 4.2935e-04\n",
      "Epoch 211/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2302e-04 - val_loss: 4.2885e-04\n",
      "Epoch 212/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2269e-04 - val_loss: 4.2862e-04\n",
      "Epoch 213/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2245e-04 - val_loss: 4.2849e-04\n",
      "Epoch 214/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2203e-04 - val_loss: 4.2772e-04\n",
      "Epoch 215/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2169e-04 - val_loss: 4.2829e-04\n",
      "Epoch 216/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2153e-04 - val_loss: 4.2726e-04\n",
      "Epoch 217/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2113e-04 - val_loss: 4.2690e-04\n",
      "Epoch 218/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2093e-04 - val_loss: 4.2645e-04\n",
      "Epoch 219/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2057e-04 - val_loss: 4.2647e-04\n",
      "Epoch 220/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.2021e-04 - val_loss: 4.2605e-04\n",
      "Epoch 221/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1996e-04 - val_loss: 4.2568e-04\n",
      "Epoch 222/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1971e-04 - val_loss: 4.2557e-04\n",
      "Epoch 223/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1935e-04 - val_loss: 4.2503e-04\n",
      "Epoch 224/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1898e-04 - val_loss: 4.2508e-04\n",
      "Epoch 225/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1874e-04 - val_loss: 4.2445e-04\n",
      "Epoch 226/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1842e-04 - val_loss: 4.2426e-04\n",
      "Epoch 227/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1818e-04 - val_loss: 4.2400e-04\n",
      "Epoch 228/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1787e-04 - val_loss: 4.2381e-04\n",
      "Epoch 229/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1749e-04 - val_loss: 4.2317e-04\n",
      "Epoch 230/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1727e-04 - val_loss: 4.2300e-04\n",
      "Epoch 231/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1701e-04 - val_loss: 4.2294e-04\n",
      "Epoch 232/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1680e-04 - val_loss: 4.2269e-04\n",
      "Epoch 233/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1637e-04 - val_loss: 4.2217e-04\n",
      "Epoch 234/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1619e-04 - val_loss: 4.2267e-04\n",
      "Epoch 235/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1593e-04 - val_loss: 4.2192e-04\n",
      "Epoch 236/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1563e-04 - val_loss: 4.2204e-04\n",
      "Epoch 237/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1533e-04 - val_loss: 4.2161e-04\n",
      "Epoch 238/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1507e-04 - val_loss: 4.2204e-04\n",
      "Epoch 239/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1484e-04 - val_loss: 4.2112e-04\n",
      "Epoch 240/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1451e-04 - val_loss: 4.2057e-04\n",
      "Epoch 241/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1442e-04 - val_loss: 4.2036e-04\n",
      "Epoch 242/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1415e-04 - val_loss: 4.1978e-04\n",
      "Epoch 243/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1389e-04 - val_loss: 4.2014e-04\n",
      "Epoch 244/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1359e-04 - val_loss: 4.1974e-04\n",
      "Epoch 245/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1351e-04 - val_loss: 4.1926e-04\n",
      "Epoch 246/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1328e-04 - val_loss: 4.1906e-04\n",
      "Epoch 247/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1277e-04 - val_loss: 4.1897e-04\n",
      "Epoch 248/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1263e-04 - val_loss: 4.1901e-04\n",
      "Epoch 249/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1247e-04 - val_loss: 4.1855e-04\n",
      "Epoch 250/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1215e-04 - val_loss: 4.1831e-04\n",
      "Epoch 251/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1199e-04 - val_loss: 4.1784e-04\n",
      "Epoch 252/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1165e-04 - val_loss: 4.1835e-04\n",
      "Epoch 253/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1149e-04 - val_loss: 4.1789e-04\n",
      "Epoch 254/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1120e-04 - val_loss: 4.1714e-04\n",
      "Epoch 255/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1080e-04 - val_loss: 4.1714e-04\n",
      "Epoch 256/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1081e-04 - val_loss: 4.1690e-04\n",
      "Epoch 257/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1040e-04 - val_loss: 4.1710e-04\n",
      "Epoch 258/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1032e-04 - val_loss: 4.1636e-04\n",
      "Epoch 259/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.1020e-04 - val_loss: 4.1623e-04\n",
      "Epoch 260/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0978e-04 - val_loss: 4.1639e-04\n",
      "Epoch 261/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0953e-04 - val_loss: 4.1560e-04\n",
      "Epoch 262/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0925e-04 - val_loss: 4.1576e-04\n",
      "Epoch 263/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0922e-04 - val_loss: 4.1567e-04\n",
      "Epoch 264/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0887e-04 - val_loss: 4.1511e-04\n",
      "Epoch 265/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0882e-04 - val_loss: 4.1519e-04\n",
      "Epoch 266/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0848e-04 - val_loss: 4.1489e-04\n",
      "Epoch 267/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0844e-04 - val_loss: 4.1448e-04\n",
      "Epoch 268/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0793e-04 - val_loss: 4.1418e-04\n",
      "Epoch 269/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0794e-04 - val_loss: 4.1380e-04\n",
      "Epoch 270/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0752e-04 - val_loss: 4.1423e-04\n",
      "Epoch 271/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0757e-04 - val_loss: 4.1371e-04\n",
      "Epoch 272/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0723e-04 - val_loss: 4.1383e-04\n",
      "Epoch 273/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0710e-04 - val_loss: 4.1359e-04\n",
      "Epoch 274/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0678e-04 - val_loss: 4.1274e-04\n",
      "Epoch 275/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0654e-04 - val_loss: 4.1342e-04\n",
      "Epoch 276/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0645e-04 - val_loss: 4.1264e-04\n",
      "Epoch 277/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0624e-04 - val_loss: 4.1238e-04\n",
      "Epoch 278/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0607e-04 - val_loss: 4.1205e-04\n",
      "Epoch 279/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0586e-04 - val_loss: 4.1169e-04\n",
      "Epoch 280/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0558e-04 - val_loss: 4.1187e-04\n",
      "Epoch 281/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0537e-04 - val_loss: 4.1181e-04\n",
      "Epoch 282/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0517e-04 - val_loss: 4.1143e-04\n",
      "Epoch 283/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0479e-04 - val_loss: 4.1101e-04\n",
      "Epoch 284/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0475e-04 - val_loss: 4.1125e-04\n",
      "Epoch 285/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0467e-04 - val_loss: 4.1116e-04\n",
      "Epoch 286/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0427e-04 - val_loss: 4.1079e-04\n",
      "Epoch 287/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0403e-04 - val_loss: 4.1044e-04\n",
      "Epoch 288/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0398e-04 - val_loss: 4.1022e-04\n",
      "Epoch 289/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0393e-04 - val_loss: 4.0978e-04\n",
      "Epoch 290/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0352e-04 - val_loss: 4.0970e-04\n",
      "Epoch 291/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0329e-04 - val_loss: 4.0975e-04\n",
      "Epoch 292/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0329e-04 - val_loss: 4.0947e-04\n",
      "Epoch 293/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0297e-04 - val_loss: 4.0924e-04\n",
      "Epoch 294/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0286e-04 - val_loss: 4.0916e-04\n",
      "Epoch 295/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0244e-04 - val_loss: 4.0886e-04\n",
      "Epoch 296/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0263e-04 - val_loss: 4.0942e-04\n",
      "Epoch 297/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0224e-04 - val_loss: 4.0854e-04\n",
      "Epoch 298/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0211e-04 - val_loss: 4.0912e-04\n",
      "Epoch 299/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0195e-04 - val_loss: 4.0821e-04\n",
      "Epoch 300/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0167e-04 - val_loss: 4.0815e-04\n",
      "Epoch 301/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0145e-04 - val_loss: 4.0788e-04\n",
      "Epoch 302/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0146e-04 - val_loss: 4.0810e-04\n",
      "Epoch 303/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0112e-04 - val_loss: 4.0807e-04\n",
      "Epoch 304/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0106e-04 - val_loss: 4.0731e-04\n",
      "Epoch 305/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0081e-04 - val_loss: 4.0734e-04\n",
      "Epoch 306/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0058e-04 - val_loss: 4.0697e-04\n",
      "Epoch 307/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0040e-04 - val_loss: 4.0704e-04\n",
      "Epoch 308/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0033e-04 - val_loss: 4.0662e-04\n",
      "Epoch 309/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 4.0005e-04 - val_loss: 4.0670e-04\n",
      "Epoch 310/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 4.0002e-04 - val_loss: 4.0619e-04\n",
      "Epoch 311/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9967e-04 - val_loss: 4.0696e-04\n",
      "Epoch 312/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9952e-04 - val_loss: 4.0581e-04\n",
      "Epoch 313/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9943e-04 - val_loss: 4.0577e-04\n",
      "Epoch 314/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9935e-04 - val_loss: 4.0603e-04\n",
      "Epoch 315/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9907e-04 - val_loss: 4.0545e-04\n",
      "Epoch 316/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9880e-04 - val_loss: 4.0545e-04\n",
      "Epoch 317/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9856e-04 - val_loss: 4.0572e-04\n",
      "Epoch 318/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9865e-04 - val_loss: 4.0479e-04\n",
      "Epoch 319/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9834e-04 - val_loss: 4.0487e-04\n",
      "Epoch 320/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9832e-04 - val_loss: 4.0495e-04\n",
      "Epoch 321/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9823e-04 - val_loss: 4.0471e-04\n",
      "Epoch 322/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9788e-04 - val_loss: 4.0490e-04\n",
      "Epoch 323/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9775e-04 - val_loss: 4.0421e-04\n",
      "Epoch 324/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9767e-04 - val_loss: 4.0426e-04\n",
      "Epoch 325/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9750e-04 - val_loss: 4.0382e-04\n",
      "Epoch 326/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9740e-04 - val_loss: 4.0368e-04\n",
      "Epoch 327/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9719e-04 - val_loss: 4.0452e-04\n",
      "Epoch 328/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9720e-04 - val_loss: 4.0342e-04\n",
      "Epoch 329/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9673e-04 - val_loss: 4.0328e-04\n",
      "Epoch 330/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9673e-04 - val_loss: 4.0338e-04\n",
      "Epoch 331/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9658e-04 - val_loss: 4.0338e-04\n",
      "Epoch 332/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9646e-04 - val_loss: 4.0305e-04\n",
      "Epoch 333/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9626e-04 - val_loss: 4.0301e-04\n",
      "Epoch 334/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9599e-04 - val_loss: 4.0264e-04\n",
      "Epoch 335/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9588e-04 - val_loss: 4.0292e-04\n",
      "Epoch 336/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9564e-04 - val_loss: 4.0222e-04\n",
      "Epoch 337/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9565e-04 - val_loss: 4.0181e-04\n",
      "Epoch 338/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9543e-04 - val_loss: 4.0207e-04\n",
      "Epoch 339/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9555e-04 - val_loss: 4.0152e-04\n",
      "Epoch 340/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9518e-04 - val_loss: 4.0235e-04\n",
      "Epoch 341/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9511e-04 - val_loss: 4.0146e-04\n",
      "Epoch 342/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9485e-04 - val_loss: 4.0183e-04\n",
      "Epoch 343/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9476e-04 - val_loss: 4.0129e-04\n",
      "Epoch 344/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9454e-04 - val_loss: 4.0125e-04\n",
      "Epoch 345/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9452e-04 - val_loss: 4.0109e-04\n",
      "Epoch 346/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9426e-04 - val_loss: 4.0099e-04\n",
      "Epoch 347/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9417e-04 - val_loss: 4.0033e-04\n",
      "Epoch 348/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9401e-04 - val_loss: 4.0023e-04\n",
      "Epoch 349/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9382e-04 - val_loss: 4.0016e-04\n",
      "Epoch 350/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9364e-04 - val_loss: 4.0038e-04\n",
      "Epoch 351/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9373e-04 - val_loss: 4.0061e-04\n",
      "Epoch 352/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9344e-04 - val_loss: 4.0019e-04\n",
      "Epoch 353/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9317e-04 - val_loss: 4.0004e-04\n",
      "Epoch 354/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9317e-04 - val_loss: 4.0081e-04\n",
      "Epoch 355/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9309e-04 - val_loss: 3.9980e-04\n",
      "Epoch 356/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9282e-04 - val_loss: 4.0009e-04\n",
      "Epoch 357/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9288e-04 - val_loss: 3.9987e-04\n",
      "Epoch 358/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9259e-04 - val_loss: 3.9899e-04\n",
      "Epoch 359/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9244e-04 - val_loss: 3.9924e-04\n",
      "Epoch 360/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9226e-04 - val_loss: 3.9899e-04\n",
      "Epoch 361/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9212e-04 - val_loss: 3.9894e-04\n",
      "Epoch 362/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9205e-04 - val_loss: 3.9859e-04\n",
      "Epoch 363/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9160e-04 - val_loss: 3.9864e-04\n",
      "Epoch 364/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9179e-04 - val_loss: 3.9843e-04\n",
      "Epoch 365/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9155e-04 - val_loss: 3.9841e-04\n",
      "Epoch 366/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9158e-04 - val_loss: 3.9813e-04\n",
      "Epoch 367/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9121e-04 - val_loss: 3.9769e-04\n",
      "Epoch 368/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9116e-04 - val_loss: 3.9770e-04\n",
      "Epoch 369/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9098e-04 - val_loss: 3.9804e-04\n",
      "Epoch 370/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9104e-04 - val_loss: 3.9807e-04\n",
      "Epoch 371/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9089e-04 - val_loss: 3.9714e-04\n",
      "Epoch 372/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.9079e-04 - val_loss: 3.9731e-04\n",
      "Epoch 373/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9047e-04 - val_loss: 3.9726e-04\n",
      "Epoch 374/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9042e-04 - val_loss: 3.9696e-04\n",
      "Epoch 375/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9030e-04 - val_loss: 3.9670e-04\n",
      "Epoch 376/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9022e-04 - val_loss: 3.9670e-04\n",
      "Epoch 377/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.9006e-04 - val_loss: 3.9746e-04\n",
      "Epoch 378/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8994e-04 - val_loss: 3.9655e-04\n",
      "Epoch 379/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8983e-04 - val_loss: 3.9658e-04\n",
      "Epoch 380/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8970e-04 - val_loss: 3.9652e-04\n",
      "Epoch 381/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8949e-04 - val_loss: 3.9609e-04\n",
      "Epoch 382/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8924e-04 - val_loss: 3.9613e-04\n",
      "Epoch 383/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8923e-04 - val_loss: 3.9617e-04\n",
      "Epoch 384/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8916e-04 - val_loss: 3.9553e-04\n",
      "Epoch 385/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8913e-04 - val_loss: 3.9535e-04\n",
      "Epoch 386/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8897e-04 - val_loss: 3.9546e-04\n",
      "Epoch 387/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8891e-04 - val_loss: 3.9550e-04\n",
      "Epoch 388/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8871e-04 - val_loss: 3.9569e-04\n",
      "Epoch 389/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8845e-04 - val_loss: 3.9512e-04\n",
      "Epoch 390/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8838e-04 - val_loss: 3.9477e-04\n",
      "Epoch 391/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8832e-04 - val_loss: 3.9517e-04\n",
      "Epoch 392/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8811e-04 - val_loss: 3.9462e-04\n",
      "Epoch 393/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8804e-04 - val_loss: 3.9500e-04\n",
      "Epoch 394/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8786e-04 - val_loss: 3.9526e-04\n",
      "Epoch 395/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8787e-04 - val_loss: 3.9436e-04\n",
      "Epoch 396/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8763e-04 - val_loss: 3.9443e-04\n",
      "Epoch 397/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8746e-04 - val_loss: 3.9437e-04\n",
      "Epoch 398/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8751e-04 - val_loss: 3.9414e-04\n",
      "Epoch 399/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8729e-04 - val_loss: 3.9373e-04\n",
      "Epoch 400/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8723e-04 - val_loss: 3.9384e-04\n",
      "Epoch 401/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8707e-04 - val_loss: 3.9427e-04\n",
      "Epoch 402/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8696e-04 - val_loss: 3.9405e-04\n",
      "Epoch 403/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8692e-04 - val_loss: 3.9351e-04\n",
      "Epoch 404/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8661e-04 - val_loss: 3.9375e-04\n",
      "Epoch 405/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8657e-04 - val_loss: 3.9375e-04\n",
      "Epoch 406/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8647e-04 - val_loss: 3.9353e-04\n",
      "Epoch 407/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8619e-04 - val_loss: 3.9315e-04\n",
      "Epoch 408/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8640e-04 - val_loss: 3.9301e-04\n",
      "Epoch 409/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8619e-04 - val_loss: 3.9296e-04\n",
      "Epoch 410/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8606e-04 - val_loss: 3.9291e-04\n",
      "Epoch 411/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8594e-04 - val_loss: 3.9456e-04\n",
      "Epoch 412/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8584e-04 - val_loss: 3.9255e-04\n",
      "Epoch 413/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8563e-04 - val_loss: 3.9418e-04\n",
      "Epoch 414/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8558e-04 - val_loss: 3.9345e-04\n",
      "Epoch 415/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8539e-04 - val_loss: 3.9202e-04\n",
      "Epoch 416/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8543e-04 - val_loss: 3.9211e-04\n",
      "Epoch 417/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8538e-04 - val_loss: 3.9226e-04\n",
      "Epoch 418/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8503e-04 - val_loss: 3.9168e-04\n",
      "Epoch 419/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8517e-04 - val_loss: 3.9246e-04\n",
      "Epoch 420/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8511e-04 - val_loss: 3.9193e-04\n",
      "Epoch 421/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8483e-04 - val_loss: 3.9155e-04\n",
      "Epoch 422/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8474e-04 - val_loss: 3.9182e-04\n",
      "Epoch 423/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8467e-04 - val_loss: 3.9154e-04\n",
      "Epoch 424/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8447e-04 - val_loss: 3.9140e-04\n",
      "Epoch 425/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8434e-04 - val_loss: 3.9165e-04\n",
      "Epoch 426/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8446e-04 - val_loss: 3.9118e-04\n",
      "Epoch 427/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8417e-04 - val_loss: 3.9100e-04\n",
      "Epoch 428/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.8423e-04 - val_loss: 3.9079e-04\n",
      "Epoch 429/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.8405e-04 - val_loss: 3.9130e-04\n",
      "Epoch 430/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8413e-04 - val_loss: 3.9092e-04\n",
      "Epoch 431/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8394e-04 - val_loss: 3.9095e-04\n",
      "Epoch 432/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8378e-04 - val_loss: 3.9093e-04\n",
      "Epoch 433/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8366e-04 - val_loss: 3.9024e-04\n",
      "Epoch 434/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8359e-04 - val_loss: 3.9033e-04\n",
      "Epoch 435/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8355e-04 - val_loss: 3.9072e-04\n",
      "Epoch 436/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8334e-04 - val_loss: 3.9065e-04\n",
      "Epoch 437/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8315e-04 - val_loss: 3.8991e-04\n",
      "Epoch 438/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8312e-04 - val_loss: 3.8984e-04\n",
      "Epoch 439/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8303e-04 - val_loss: 3.8978e-04\n",
      "Epoch 440/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8289e-04 - val_loss: 3.8987e-04\n",
      "Epoch 441/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8289e-04 - val_loss: 3.8956e-04\n",
      "Epoch 442/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8263e-04 - val_loss: 3.8919e-04\n",
      "Epoch 443/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8257e-04 - val_loss: 3.8969e-04\n",
      "Epoch 444/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8269e-04 - val_loss: 3.8963e-04\n",
      "Epoch 445/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8250e-04 - val_loss: 3.8945e-04\n",
      "Epoch 446/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8231e-04 - val_loss: 3.8923e-04\n",
      "Epoch 447/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8235e-04 - val_loss: 3.8944e-04\n",
      "Epoch 448/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8229e-04 - val_loss: 3.8853e-04\n",
      "Epoch 449/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8213e-04 - val_loss: 3.8918e-04\n",
      "Epoch 450/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8215e-04 - val_loss: 3.8884e-04\n",
      "Epoch 451/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8191e-04 - val_loss: 3.8855e-04\n",
      "Epoch 452/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8199e-04 - val_loss: 3.8947e-04\n",
      "Epoch 453/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8173e-04 - val_loss: 3.8874e-04\n",
      "Epoch 454/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8150e-04 - val_loss: 3.8864e-04\n",
      "Epoch 455/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8151e-04 - val_loss: 3.8859e-04\n",
      "Epoch 456/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8125e-04 - val_loss: 3.8841e-04\n",
      "Epoch 457/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8148e-04 - val_loss: 3.8806e-04\n",
      "Epoch 458/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8121e-04 - val_loss: 3.8888e-04\n",
      "Epoch 459/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8143e-04 - val_loss: 3.8933e-04\n",
      "Epoch 460/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8111e-04 - val_loss: 3.8807e-04\n",
      "Epoch 461/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8095e-04 - val_loss: 3.8823e-04\n",
      "Epoch 462/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8087e-04 - val_loss: 3.8761e-04\n",
      "Epoch 463/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8083e-04 - val_loss: 3.8737e-04\n",
      "Epoch 464/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8066e-04 - val_loss: 3.8739e-04\n",
      "Epoch 465/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.8056e-04 - val_loss: 3.8762e-04\n",
      "Epoch 466/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8061e-04 - val_loss: 3.8733e-04\n",
      "Epoch 467/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8052e-04 - val_loss: 3.8715e-04\n",
      "Epoch 468/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8025e-04 - val_loss: 3.8719e-04\n",
      "Epoch 469/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8028e-04 - val_loss: 3.8698e-04\n",
      "Epoch 470/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8009e-04 - val_loss: 3.8733e-04\n",
      "Epoch 471/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.8013e-04 - val_loss: 3.8727e-04\n",
      "Epoch 472/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7983e-04 - val_loss: 3.8688e-04\n",
      "Epoch 473/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7998e-04 - val_loss: 3.8650e-04\n",
      "Epoch 474/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7988e-04 - val_loss: 3.8647e-04\n",
      "Epoch 475/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7961e-04 - val_loss: 3.8629e-04\n",
      "Epoch 476/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7956e-04 - val_loss: 3.8695e-04\n",
      "Epoch 477/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7952e-04 - val_loss: 3.8644e-04\n",
      "Epoch 478/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7963e-04 - val_loss: 3.8664e-04\n",
      "Epoch 479/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7936e-04 - val_loss: 3.8601e-04\n",
      "Epoch 480/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7919e-04 - val_loss: 3.8621e-04\n",
      "Epoch 481/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7929e-04 - val_loss: 3.8618e-04\n",
      "Epoch 482/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7908e-04 - val_loss: 3.8549e-04\n",
      "Epoch 483/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7901e-04 - val_loss: 3.8599e-04\n",
      "Epoch 484/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7907e-04 - val_loss: 3.8586e-04\n",
      "Epoch 485/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7871e-04 - val_loss: 3.8542e-04\n",
      "Epoch 486/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7874e-04 - val_loss: 3.8648e-04\n",
      "Epoch 487/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7868e-04 - val_loss: 3.8545e-04\n",
      "Epoch 488/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7855e-04 - val_loss: 3.8548e-04\n",
      "Epoch 489/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7848e-04 - val_loss: 3.8555e-04\n",
      "Epoch 490/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7826e-04 - val_loss: 3.8504e-04\n",
      "Epoch 491/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7845e-04 - val_loss: 3.8553e-04\n",
      "Epoch 492/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7818e-04 - val_loss: 3.8485e-04\n",
      "Epoch 493/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7822e-04 - val_loss: 3.8468e-04\n",
      "Epoch 494/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7808e-04 - val_loss: 3.8469e-04\n",
      "Epoch 495/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7790e-04 - val_loss: 3.8501e-04\n",
      "Epoch 496/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7805e-04 - val_loss: 3.8474e-04\n",
      "Epoch 497/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7785e-04 - val_loss: 3.8413e-04\n",
      "Epoch 498/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7773e-04 - val_loss: 3.8417e-04\n",
      "Epoch 499/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7745e-04 - val_loss: 3.8423e-04\n",
      "Epoch 500/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7738e-04 - val_loss: 3.8461e-04\n",
      "Epoch 501/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7754e-04 - val_loss: 3.8397e-04\n",
      "Epoch 502/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7751e-04 - val_loss: 3.8465e-04\n",
      "Epoch 503/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7741e-04 - val_loss: 3.8418e-04\n",
      "Epoch 504/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7721e-04 - val_loss: 3.8387e-04\n",
      "Epoch 505/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7708e-04 - val_loss: 3.8388e-04\n",
      "Epoch 506/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7714e-04 - val_loss: 3.8405e-04\n",
      "Epoch 507/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7691e-04 - val_loss: 3.8411e-04\n",
      "Epoch 508/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7714e-04 - val_loss: 3.8445e-04\n",
      "Epoch 509/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7696e-04 - val_loss: 3.8414e-04\n",
      "Epoch 510/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7677e-04 - val_loss: 3.8398e-04\n",
      "Epoch 511/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7664e-04 - val_loss: 3.8372e-04\n",
      "Epoch 512/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7670e-04 - val_loss: 3.8394e-04\n",
      "Epoch 513/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7665e-04 - val_loss: 3.8300e-04\n",
      "Epoch 514/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7639e-04 - val_loss: 3.8318e-04\n",
      "Epoch 515/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7626e-04 - val_loss: 3.8342e-04\n",
      "Epoch 516/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7630e-04 - val_loss: 3.8283e-04\n",
      "Epoch 517/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.7636e-04 - val_loss: 3.8373e-04\n",
      "Epoch 518/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7621e-04 - val_loss: 3.8258e-04\n",
      "Epoch 519/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7603e-04 - val_loss: 3.8262e-04\n",
      "Epoch 520/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7598e-04 - val_loss: 3.8322e-04\n",
      "Epoch 521/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7586e-04 - val_loss: 3.8243e-04\n",
      "Epoch 522/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7604e-04 - val_loss: 3.8285e-04\n",
      "Epoch 523/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7555e-04 - val_loss: 3.8275e-04\n",
      "Epoch 524/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7575e-04 - val_loss: 3.8250e-04\n",
      "Epoch 525/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7566e-04 - val_loss: 3.8238e-04\n",
      "Epoch 526/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7542e-04 - val_loss: 3.8244e-04\n",
      "Epoch 527/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7546e-04 - val_loss: 3.8233e-04\n",
      "Epoch 528/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7525e-04 - val_loss: 3.8217e-04\n",
      "Epoch 529/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7520e-04 - val_loss: 3.8266e-04\n",
      "Epoch 530/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7535e-04 - val_loss: 3.8232e-04\n",
      "Epoch 531/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7512e-04 - val_loss: 3.8171e-04\n",
      "Epoch 532/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7496e-04 - val_loss: 3.8234e-04\n",
      "Epoch 533/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7505e-04 - val_loss: 3.8182e-04\n",
      "Epoch 534/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7486e-04 - val_loss: 3.8152e-04\n",
      "Epoch 535/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7477e-04 - val_loss: 3.8230e-04\n",
      "Epoch 536/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7490e-04 - val_loss: 3.8265e-04\n",
      "Epoch 537/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7470e-04 - val_loss: 3.8152e-04\n",
      "Epoch 538/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7446e-04 - val_loss: 3.8225e-04\n",
      "Epoch 539/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7462e-04 - val_loss: 3.8150e-04\n",
      "Epoch 540/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7472e-04 - val_loss: 3.8127e-04\n",
      "Epoch 541/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7426e-04 - val_loss: 3.8129e-04\n",
      "Epoch 542/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7423e-04 - val_loss: 3.8103e-04\n",
      "Epoch 543/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7417e-04 - val_loss: 3.8158e-04\n",
      "Epoch 544/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7406e-04 - val_loss: 3.8130e-04\n",
      "Epoch 545/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7389e-04 - val_loss: 3.8087e-04\n",
      "Epoch 546/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7405e-04 - val_loss: 3.8069e-04\n",
      "Epoch 547/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7397e-04 - val_loss: 3.8074e-04\n",
      "Epoch 548/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7389e-04 - val_loss: 3.8060e-04\n",
      "Epoch 549/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7369e-04 - val_loss: 3.8081e-04\n",
      "Epoch 550/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7364e-04 - val_loss: 3.8049e-04\n",
      "Epoch 551/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7358e-04 - val_loss: 3.8058e-04\n",
      "Epoch 552/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7356e-04 - val_loss: 3.8058e-04\n",
      "Epoch 553/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7355e-04 - val_loss: 3.8010e-04\n",
      "Epoch 554/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7345e-04 - val_loss: 3.8070e-04\n",
      "Epoch 555/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7324e-04 - val_loss: 3.8047e-04\n",
      "Epoch 556/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7317e-04 - val_loss: 3.8021e-04\n",
      "Epoch 557/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7314e-04 - val_loss: 3.7998e-04\n",
      "Epoch 558/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7322e-04 - val_loss: 3.8036e-04\n",
      "Epoch 559/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7293e-04 - val_loss: 3.8009e-04\n",
      "Epoch 560/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7290e-04 - val_loss: 3.8002e-04\n",
      "Epoch 561/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7303e-04 - val_loss: 3.8017e-04\n",
      "Epoch 562/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7292e-04 - val_loss: 3.7961e-04\n",
      "Epoch 563/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7279e-04 - val_loss: 3.7977e-04\n",
      "Epoch 564/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7280e-04 - val_loss: 3.7938e-04\n",
      "Epoch 565/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7249e-04 - val_loss: 3.7959e-04\n",
      "Epoch 566/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7252e-04 - val_loss: 3.7952e-04\n",
      "Epoch 567/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7249e-04 - val_loss: 3.7939e-04\n",
      "Epoch 568/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7249e-04 - val_loss: 3.7985e-04\n",
      "Epoch 569/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7236e-04 - val_loss: 3.7937e-04\n",
      "Epoch 570/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7211e-04 - val_loss: 3.7929e-04\n",
      "Epoch 571/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7213e-04 - val_loss: 3.7907e-04\n",
      "Epoch 572/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7201e-04 - val_loss: 3.7900e-04\n",
      "Epoch 573/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7224e-04 - val_loss: 3.7932e-04\n",
      "Epoch 574/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7208e-04 - val_loss: 3.7872e-04\n",
      "Epoch 575/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7180e-04 - val_loss: 3.7877e-04\n",
      "Epoch 576/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7191e-04 - val_loss: 3.7926e-04\n",
      "Epoch 577/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7179e-04 - val_loss: 3.7843e-04\n",
      "Epoch 578/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7163e-04 - val_loss: 3.7847e-04\n",
      "Epoch 579/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7174e-04 - val_loss: 3.7901e-04\n",
      "Epoch 580/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7155e-04 - val_loss: 3.7911e-04\n",
      "Epoch 581/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7141e-04 - val_loss: 3.7826e-04\n",
      "Epoch 582/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7143e-04 - val_loss: 3.7832e-04\n",
      "Epoch 583/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7137e-04 - val_loss: 3.7838e-04\n",
      "Epoch 584/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7125e-04 - val_loss: 3.7860e-04\n",
      "Epoch 585/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7136e-04 - val_loss: 3.7881e-04\n",
      "Epoch 586/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7107e-04 - val_loss: 3.7794e-04\n",
      "Epoch 587/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7120e-04 - val_loss: 3.7792e-04\n",
      "Epoch 588/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7115e-04 - val_loss: 3.7808e-04\n",
      "Epoch 589/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7093e-04 - val_loss: 3.7795e-04\n",
      "Epoch 590/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7082e-04 - val_loss: 3.7867e-04\n",
      "Epoch 591/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7091e-04 - val_loss: 3.7783e-04\n",
      "Epoch 592/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7095e-04 - val_loss: 3.7791e-04\n",
      "Epoch 593/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7078e-04 - val_loss: 3.7747e-04\n",
      "Epoch 594/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7064e-04 - val_loss: 3.7754e-04\n",
      "Epoch 595/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7056e-04 - val_loss: 3.7713e-04\n",
      "Epoch 596/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7050e-04 - val_loss: 3.7777e-04\n",
      "Epoch 597/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7042e-04 - val_loss: 3.7788e-04\n",
      "Epoch 598/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7065e-04 - val_loss: 3.7747e-04\n",
      "Epoch 599/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7032e-04 - val_loss: 3.7688e-04\n",
      "Epoch 600/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7029e-04 - val_loss: 3.7706e-04\n",
      "Epoch 601/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7021e-04 - val_loss: 3.7786e-04\n",
      "Epoch 602/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7030e-04 - val_loss: 3.7695e-04\n",
      "Epoch 603/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6995e-04 - val_loss: 3.7739e-04\n",
      "Epoch 604/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6975e-04 - val_loss: 3.7767e-04\n",
      "Epoch 605/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.7017e-04 - val_loss: 3.7677e-04\n",
      "Epoch 606/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6982e-04 - val_loss: 3.7660e-04\n",
      "Epoch 607/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6981e-04 - val_loss: 3.7763e-04\n",
      "Epoch 608/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6979e-04 - val_loss: 3.7650e-04\n",
      "Epoch 609/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6954e-04 - val_loss: 3.7694e-04\n",
      "Epoch 610/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6961e-04 - val_loss: 3.7674e-04\n",
      "Epoch 611/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6952e-04 - val_loss: 3.7663e-04\n",
      "Epoch 612/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6944e-04 - val_loss: 3.7760e-04\n",
      "Epoch 613/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6941e-04 - val_loss: 3.7620e-04\n",
      "Epoch 614/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6925e-04 - val_loss: 3.7691e-04\n",
      "Epoch 615/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6932e-04 - val_loss: 3.7600e-04\n",
      "Epoch 616/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6916e-04 - val_loss: 3.7687e-04\n",
      "Epoch 617/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6927e-04 - val_loss: 3.7616e-04\n",
      "Epoch 618/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6897e-04 - val_loss: 3.7702e-04\n",
      "Epoch 619/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6909e-04 - val_loss: 3.7597e-04\n",
      "Epoch 620/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6893e-04 - val_loss: 3.7571e-04\n",
      "Epoch 621/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6877e-04 - val_loss: 3.7621e-04\n",
      "Epoch 622/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6889e-04 - val_loss: 3.7703e-04\n",
      "Epoch 623/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6873e-04 - val_loss: 3.7601e-04\n",
      "Epoch 624/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6856e-04 - val_loss: 3.7628e-04\n",
      "Epoch 625/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6858e-04 - val_loss: 3.7546e-04\n",
      "Epoch 626/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6867e-04 - val_loss: 3.7530e-04\n",
      "Epoch 627/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6848e-04 - val_loss: 3.7608e-04\n",
      "Epoch 628/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6857e-04 - val_loss: 3.7571e-04\n",
      "Epoch 629/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6837e-04 - val_loss: 3.7562e-04\n",
      "Epoch 630/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6829e-04 - val_loss: 3.7591e-04\n",
      "Epoch 631/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6827e-04 - val_loss: 3.7524e-04\n",
      "Epoch 632/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6874e-04 - val_loss: 3.7570e-04\n",
      "Epoch 633/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6825e-04 - val_loss: 3.7509e-04\n",
      "Epoch 634/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6811e-04 - val_loss: 3.7469e-04\n",
      "Epoch 635/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6813e-04 - val_loss: 3.7505e-04\n",
      "Epoch 636/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6804e-04 - val_loss: 3.7526e-04\n",
      "Epoch 637/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6793e-04 - val_loss: 3.7470e-04\n",
      "Epoch 638/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6763e-04 - val_loss: 3.7517e-04\n",
      "Epoch 639/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6779e-04 - val_loss: 3.7518e-04\n",
      "Epoch 640/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6781e-04 - val_loss: 3.7490e-04\n",
      "Epoch 641/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6768e-04 - val_loss: 3.7577e-04\n",
      "Epoch 642/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6776e-04 - val_loss: 3.7510e-04\n",
      "Epoch 643/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6753e-04 - val_loss: 3.7509e-04\n",
      "Epoch 644/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6727e-04 - val_loss: 3.7424e-04\n",
      "Epoch 645/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6758e-04 - val_loss: 3.7465e-04\n",
      "Epoch 646/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6725e-04 - val_loss: 3.7412e-04\n",
      "Epoch 647/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6732e-04 - val_loss: 3.7465e-04\n",
      "Epoch 648/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6715e-04 - val_loss: 3.7444e-04\n",
      "Epoch 649/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6720e-04 - val_loss: 3.7466e-04\n",
      "Epoch 650/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6717e-04 - val_loss: 3.7455e-04\n",
      "Epoch 651/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6720e-04 - val_loss: 3.7428e-04\n",
      "Epoch 652/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6683e-04 - val_loss: 3.7438e-04\n",
      "Epoch 653/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6676e-04 - val_loss: 3.7500e-04\n",
      "Epoch 654/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6696e-04 - val_loss: 3.7433e-04\n",
      "Epoch 655/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6701e-04 - val_loss: 3.7407e-04\n",
      "Epoch 656/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6677e-04 - val_loss: 3.7439e-04\n",
      "Epoch 657/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6668e-04 - val_loss: 3.7350e-04\n",
      "Epoch 658/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6650e-04 - val_loss: 3.7406e-04\n",
      "Epoch 659/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6650e-04 - val_loss: 3.7511e-04\n",
      "Epoch 660/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6677e-04 - val_loss: 3.7436e-04\n",
      "Epoch 661/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6642e-04 - val_loss: 3.7376e-04\n",
      "Epoch 662/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6629e-04 - val_loss: 3.7335e-04\n",
      "Epoch 663/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6631e-04 - val_loss: 3.7372e-04\n",
      "Epoch 664/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6621e-04 - val_loss: 3.7415e-04\n",
      "Epoch 665/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6640e-04 - val_loss: 3.7352e-04\n",
      "Epoch 666/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6634e-04 - val_loss: 3.7390e-04\n",
      "Epoch 667/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6605e-04 - val_loss: 3.7320e-04\n",
      "Epoch 668/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6596e-04 - val_loss: 3.7315e-04\n",
      "Epoch 669/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6576e-04 - val_loss: 3.7319e-04\n",
      "Epoch 670/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6592e-04 - val_loss: 3.7267e-04\n",
      "Epoch 671/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6577e-04 - val_loss: 3.7400e-04\n",
      "Epoch 672/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6587e-04 - val_loss: 3.7377e-04\n",
      "Epoch 673/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6600e-04 - val_loss: 3.7388e-04\n",
      "Epoch 674/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6564e-04 - val_loss: 3.7376e-04\n",
      "Epoch 675/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6566e-04 - val_loss: 3.7275e-04\n",
      "Epoch 676/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6557e-04 - val_loss: 3.7335e-04\n",
      "Epoch 677/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6622e-04 - val_loss: 3.7249e-04\n",
      "Epoch 678/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6551e-04 - val_loss: 3.7274e-04\n",
      "Epoch 679/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6548e-04 - val_loss: 3.7228e-04\n",
      "Epoch 680/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6536e-04 - val_loss: 3.7240e-04\n",
      "Epoch 681/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6509e-04 - val_loss: 3.7296e-04\n",
      "Epoch 682/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6533e-04 - val_loss: 3.7461e-04\n",
      "Epoch 683/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6535e-04 - val_loss: 3.7218e-04\n",
      "Epoch 684/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6524e-04 - val_loss: 3.7286e-04\n",
      "Epoch 685/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6509e-04 - val_loss: 3.7248e-04\n",
      "Epoch 686/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6502e-04 - val_loss: 3.7232e-04\n",
      "Epoch 687/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6504e-04 - val_loss: 3.7248e-04\n",
      "Epoch 688/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6488e-04 - val_loss: 3.7241e-04\n",
      "Epoch 689/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6510e-04 - val_loss: 3.7228e-04\n",
      "Epoch 690/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6484e-04 - val_loss: 3.7234e-04\n",
      "Epoch 691/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6475e-04 - val_loss: 3.7284e-04\n",
      "Epoch 692/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6458e-04 - val_loss: 3.7360e-04\n",
      "Epoch 693/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6462e-04 - val_loss: 3.7192e-04\n",
      "Epoch 694/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6459e-04 - val_loss: 3.7288e-04\n",
      "Epoch 695/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6475e-04 - val_loss: 3.7224e-04\n",
      "Epoch 696/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6431e-04 - val_loss: 3.7221e-04\n",
      "Epoch 697/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6470e-04 - val_loss: 3.7250e-04\n",
      "Epoch 698/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6444e-04 - val_loss: 3.7172e-04\n",
      "Epoch 699/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6434e-04 - val_loss: 3.7215e-04\n",
      "Epoch 700/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6438e-04 - val_loss: 3.7215e-04\n",
      "Epoch 701/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6424e-04 - val_loss: 3.7148e-04\n",
      "Epoch 702/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6430e-04 - val_loss: 3.7145e-04\n",
      "Epoch 703/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6401e-04 - val_loss: 3.7171e-04\n",
      "Epoch 704/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6399e-04 - val_loss: 3.7132e-04\n",
      "Epoch 705/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6403e-04 - val_loss: 3.7177e-04\n",
      "Epoch 706/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6399e-04 - val_loss: 3.7119e-04\n",
      "Epoch 707/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6395e-04 - val_loss: 3.7249e-04\n",
      "Epoch 708/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6406e-04 - val_loss: 3.7160e-04\n",
      "Epoch 709/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6377e-04 - val_loss: 3.7173e-04\n",
      "Epoch 710/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6379e-04 - val_loss: 3.7120e-04\n",
      "Epoch 711/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6375e-04 - val_loss: 3.7220e-04\n",
      "Epoch 712/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6357e-04 - val_loss: 3.7169e-04\n",
      "Epoch 713/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6362e-04 - val_loss: 3.7070e-04\n",
      "Epoch 714/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6393e-04 - val_loss: 3.7138e-04\n",
      "Epoch 715/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6362e-04 - val_loss: 3.7104e-04\n",
      "Epoch 716/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6337e-04 - val_loss: 3.7065e-04\n",
      "Epoch 717/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6342e-04 - val_loss: 3.7079e-04\n",
      "Epoch 718/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6322e-04 - val_loss: 3.7139e-04\n",
      "Epoch 719/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6321e-04 - val_loss: 3.7061e-04\n",
      "Epoch 720/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6317e-04 - val_loss: 3.7235e-04\n",
      "Epoch 721/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6327e-04 - val_loss: 3.7118e-04\n",
      "Epoch 722/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6320e-04 - val_loss: 3.7051e-04\n",
      "Epoch 723/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6291e-04 - val_loss: 3.7068e-04\n",
      "Epoch 724/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6310e-04 - val_loss: 3.7000e-04\n",
      "Epoch 725/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6284e-04 - val_loss: 3.7076e-04\n",
      "Epoch 726/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6294e-04 - val_loss: 3.7047e-04\n",
      "Epoch 727/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6287e-04 - val_loss: 3.7061e-04\n",
      "Epoch 728/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6280e-04 - val_loss: 3.7020e-04\n",
      "Epoch 729/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6276e-04 - val_loss: 3.6997e-04\n",
      "Epoch 730/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6254e-04 - val_loss: 3.7024e-04\n",
      "Epoch 731/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6284e-04 - val_loss: 3.7064e-04\n",
      "Epoch 732/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6239e-04 - val_loss: 3.6983e-04\n",
      "Epoch 733/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6248e-04 - val_loss: 3.6985e-04\n",
      "Epoch 734/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6262e-04 - val_loss: 3.7000e-04\n",
      "Epoch 735/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6234e-04 - val_loss: 3.6980e-04\n",
      "Epoch 736/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6241e-04 - val_loss: 3.7002e-04\n",
      "Epoch 737/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.6233e-04 - val_loss: 3.7017e-04\n",
      "Epoch 738/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6227e-04 - val_loss: 3.7027e-04\n",
      "Epoch 739/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6213e-04 - val_loss: 3.6940e-04\n",
      "Epoch 740/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6236e-04 - val_loss: 3.7030e-04\n",
      "Epoch 741/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6204e-04 - val_loss: 3.6962e-04\n",
      "Epoch 742/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6205e-04 - val_loss: 3.6964e-04\n",
      "Epoch 743/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6196e-04 - val_loss: 3.7068e-04\n",
      "Epoch 744/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6187e-04 - val_loss: 3.6953e-04\n",
      "Epoch 745/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6215e-04 - val_loss: 3.6948e-04\n",
      "Epoch 746/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6206e-04 - val_loss: 3.6918e-04\n",
      "Epoch 747/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6171e-04 - val_loss: 3.6996e-04\n",
      "Epoch 748/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6175e-04 - val_loss: 3.6914e-04\n",
      "Epoch 749/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6180e-04 - val_loss: 3.6913e-04\n",
      "Epoch 750/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6153e-04 - val_loss: 3.6970e-04\n",
      "Epoch 751/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6169e-04 - val_loss: 3.6889e-04\n",
      "Epoch 752/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6178e-04 - val_loss: 3.6861e-04\n",
      "Epoch 753/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6180e-04 - val_loss: 3.6875e-04\n",
      "Epoch 754/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6161e-04 - val_loss: 3.6864e-04\n",
      "Epoch 755/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6135e-04 - val_loss: 3.6893e-04\n",
      "Epoch 756/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6136e-04 - val_loss: 3.6868e-04\n",
      "Epoch 757/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6137e-04 - val_loss: 3.7015e-04\n",
      "Epoch 758/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6141e-04 - val_loss: 3.6937e-04\n",
      "Epoch 759/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6107e-04 - val_loss: 3.6910e-04\n",
      "Epoch 760/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6099e-04 - val_loss: 3.6846e-04\n",
      "Epoch 761/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6117e-04 - val_loss: 3.6811e-04\n",
      "Epoch 762/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6091e-04 - val_loss: 3.6981e-04\n",
      "Epoch 763/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6105e-04 - val_loss: 3.7080e-04\n",
      "Epoch 764/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6100e-04 - val_loss: 3.6864e-04\n",
      "Epoch 765/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6097e-04 - val_loss: 3.6883e-04\n",
      "Epoch 766/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6105e-04 - val_loss: 3.6912e-04\n",
      "Epoch 767/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6123e-04 - val_loss: 3.6809e-04\n",
      "Epoch 768/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6061e-04 - val_loss: 3.6922e-04\n",
      "Epoch 769/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6059e-04 - val_loss: 3.6970e-04\n",
      "Epoch 770/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6061e-04 - val_loss: 3.6832e-04\n",
      "Epoch 771/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6046e-04 - val_loss: 3.6846e-04\n",
      "Epoch 772/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6051e-04 - val_loss: 3.6854e-04\n",
      "Epoch 773/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6059e-04 - val_loss: 3.6882e-04\n",
      "Epoch 774/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6037e-04 - val_loss: 3.6774e-04\n",
      "Epoch 775/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6044e-04 - val_loss: 3.6790e-04\n",
      "Epoch 776/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6046e-04 - val_loss: 3.6764e-04\n",
      "Epoch 777/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6027e-04 - val_loss: 3.6815e-04\n",
      "Epoch 778/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6032e-04 - val_loss: 3.6798e-04\n",
      "Epoch 779/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6021e-04 - val_loss: 3.6851e-04\n",
      "Epoch 780/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6019e-04 - val_loss: 3.6771e-04\n",
      "Epoch 781/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5989e-04 - val_loss: 3.6771e-04\n",
      "Epoch 782/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6015e-04 - val_loss: 3.6755e-04\n",
      "Epoch 783/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.6002e-04 - val_loss: 3.6752e-04\n",
      "Epoch 784/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5980e-04 - val_loss: 3.6795e-04\n",
      "Epoch 785/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5986e-04 - val_loss: 3.6735e-04\n",
      "Epoch 786/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5985e-04 - val_loss: 3.6709e-04\n",
      "Epoch 787/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5973e-04 - val_loss: 3.6755e-04\n",
      "Epoch 788/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5969e-04 - val_loss: 3.6747e-04\n",
      "Epoch 789/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5975e-04 - val_loss: 3.6740e-04\n",
      "Epoch 790/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5959e-04 - val_loss: 3.6787e-04\n",
      "Epoch 791/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5969e-04 - val_loss: 3.6708e-04\n",
      "Epoch 792/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5959e-04 - val_loss: 3.6697e-04\n",
      "Epoch 793/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5961e-04 - val_loss: 3.6722e-04\n",
      "Epoch 794/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5938e-04 - val_loss: 3.6715e-04\n",
      "Epoch 795/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5939e-04 - val_loss: 3.6762e-04\n",
      "Epoch 796/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5950e-04 - val_loss: 3.6688e-04\n",
      "Epoch 797/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5924e-04 - val_loss: 3.6742e-04\n",
      "Epoch 798/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5936e-04 - val_loss: 3.6759e-04\n",
      "Epoch 799/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5922e-04 - val_loss: 3.6693e-04\n",
      "Epoch 800/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5915e-04 - val_loss: 3.6720e-04\n",
      "Epoch 801/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5925e-04 - val_loss: 3.6715e-04\n",
      "Epoch 802/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5910e-04 - val_loss: 3.6749e-04\n",
      "Epoch 803/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5897e-04 - val_loss: 3.6647e-04\n",
      "Epoch 804/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5899e-04 - val_loss: 3.6789e-04\n",
      "Epoch 805/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5918e-04 - val_loss: 3.6671e-04\n",
      "Epoch 806/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5879e-04 - val_loss: 3.6811e-04\n",
      "Epoch 807/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5910e-04 - val_loss: 3.6673e-04\n",
      "Epoch 808/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5864e-04 - val_loss: 3.6640e-04\n",
      "Epoch 809/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5900e-04 - val_loss: 3.6676e-04\n",
      "Epoch 810/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5874e-04 - val_loss: 3.6643e-04\n",
      "Epoch 811/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5860e-04 - val_loss: 3.6687e-04\n",
      "Epoch 812/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5863e-04 - val_loss: 3.6658e-04\n",
      "Epoch 813/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5845e-04 - val_loss: 3.6648e-04\n",
      "Epoch 814/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5851e-04 - val_loss: 3.6617e-04\n",
      "Epoch 815/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5848e-04 - val_loss: 3.6619e-04\n",
      "Epoch 816/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5845e-04 - val_loss: 3.6638e-04\n",
      "Epoch 817/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5818e-04 - val_loss: 3.6626e-04\n",
      "Epoch 818/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5836e-04 - val_loss: 3.6597e-04\n",
      "Epoch 819/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5838e-04 - val_loss: 3.6736e-04\n",
      "Epoch 820/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5825e-04 - val_loss: 3.6600e-04\n",
      "Epoch 821/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5819e-04 - val_loss: 3.6613e-04\n",
      "Epoch 822/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5809e-04 - val_loss: 3.6602e-04\n",
      "Epoch 823/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5810e-04 - val_loss: 3.6615e-04\n",
      "Epoch 824/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5804e-04 - val_loss: 3.6573e-04\n",
      "Epoch 825/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5802e-04 - val_loss: 3.6530e-04\n",
      "Epoch 826/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5798e-04 - val_loss: 3.6555e-04\n",
      "Epoch 827/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5785e-04 - val_loss: 3.6633e-04\n",
      "Epoch 828/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5795e-04 - val_loss: 3.6815e-04\n",
      "Epoch 829/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5798e-04 - val_loss: 3.6613e-04\n",
      "Epoch 830/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5782e-04 - val_loss: 3.6510e-04\n",
      "Epoch 831/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5767e-04 - val_loss: 3.6591e-04\n",
      "Epoch 832/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5767e-04 - val_loss: 3.6580e-04\n",
      "Epoch 833/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5761e-04 - val_loss: 3.6580e-04\n",
      "Epoch 834/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5777e-04 - val_loss: 3.6544e-04\n",
      "Epoch 835/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5773e-04 - val_loss: 3.6546e-04\n",
      "Epoch 836/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5747e-04 - val_loss: 3.6580e-04\n",
      "Epoch 837/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5747e-04 - val_loss: 3.6532e-04\n",
      "Epoch 838/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5734e-04 - val_loss: 3.6523e-04\n",
      "Epoch 839/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5732e-04 - val_loss: 3.6488e-04\n",
      "Epoch 840/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5719e-04 - val_loss: 3.6527e-04\n",
      "Epoch 841/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5734e-04 - val_loss: 3.6534e-04\n",
      "Epoch 842/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5702e-04 - val_loss: 3.6505e-04\n",
      "Epoch 843/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5715e-04 - val_loss: 3.6513e-04\n",
      "Epoch 844/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5723e-04 - val_loss: 3.6549e-04\n",
      "Epoch 845/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5715e-04 - val_loss: 3.6498e-04\n",
      "Epoch 846/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5697e-04 - val_loss: 3.6439e-04\n",
      "Epoch 847/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5689e-04 - val_loss: 3.6528e-04\n",
      "Epoch 848/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5706e-04 - val_loss: 3.6529e-04\n",
      "Epoch 849/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5702e-04 - val_loss: 3.6562e-04\n",
      "Epoch 850/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5699e-04 - val_loss: 3.6495e-04\n",
      "Epoch 851/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5679e-04 - val_loss: 3.6452e-04\n",
      "Epoch 852/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5701e-04 - val_loss: 3.6488e-04\n",
      "Epoch 853/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5667e-04 - val_loss: 3.6567e-04\n",
      "Epoch 854/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5655e-04 - val_loss: 3.6449e-04\n",
      "Epoch 855/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5690e-04 - val_loss: 3.6458e-04\n",
      "Epoch 856/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5658e-04 - val_loss: 3.6459e-04\n",
      "Epoch 857/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5655e-04 - val_loss: 3.6519e-04\n",
      "Epoch 858/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5678e-04 - val_loss: 3.6470e-04\n",
      "Epoch 859/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5637e-04 - val_loss: 3.6413e-04\n",
      "Epoch 860/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5619e-04 - val_loss: 3.6456e-04\n",
      "Epoch 861/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5628e-04 - val_loss: 3.6424e-04\n",
      "Epoch 862/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5645e-04 - val_loss: 3.6477e-04\n",
      "Epoch 863/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5615e-04 - val_loss: 3.6420e-04\n",
      "Epoch 864/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5641e-04 - val_loss: 3.6449e-04\n",
      "Epoch 865/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5631e-04 - val_loss: 3.6526e-04\n",
      "Epoch 866/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5621e-04 - val_loss: 3.6474e-04\n",
      "Epoch 867/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5633e-04 - val_loss: 3.6431e-04\n",
      "Epoch 868/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5637e-04 - val_loss: 3.6389e-04\n",
      "Epoch 869/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5613e-04 - val_loss: 3.6426e-04\n",
      "Epoch 870/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5604e-04 - val_loss: 3.6418e-04\n",
      "Epoch 871/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5585e-04 - val_loss: 3.6431e-04\n",
      "Epoch 872/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5592e-04 - val_loss: 3.6472e-04\n",
      "Epoch 873/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5596e-04 - val_loss: 3.6497e-04\n",
      "Epoch 874/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5582e-04 - val_loss: 3.6486e-04\n",
      "Epoch 875/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5573e-04 - val_loss: 3.6443e-04\n",
      "Epoch 876/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5567e-04 - val_loss: 3.6380e-04\n",
      "Epoch 877/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5610e-04 - val_loss: 3.6422e-04\n",
      "Epoch 878/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5573e-04 - val_loss: 3.6644e-04\n",
      "Epoch 879/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5750e-04 - val_loss: 3.6348e-04\n",
      "Epoch 880/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5596e-04 - val_loss: 3.6371e-04\n",
      "Epoch 881/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5519e-04 - val_loss: 3.6417e-04\n",
      "Epoch 882/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5545e-04 - val_loss: 3.6333e-04\n",
      "Epoch 883/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5562e-04 - val_loss: 3.6333e-04\n",
      "Epoch 884/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5553e-04 - val_loss: 3.6377e-04\n",
      "Epoch 885/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5529e-04 - val_loss: 3.6334e-04\n",
      "Epoch 886/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5514e-04 - val_loss: 3.6407e-04\n",
      "Epoch 887/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5523e-04 - val_loss: 3.6313e-04\n",
      "Epoch 888/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5517e-04 - val_loss: 3.6375e-04\n",
      "Epoch 889/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5524e-04 - val_loss: 3.6482e-04\n",
      "Epoch 890/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5501e-04 - val_loss: 3.6386e-04\n",
      "Epoch 891/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5497e-04 - val_loss: 3.6398e-04\n",
      "Epoch 892/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5506e-04 - val_loss: 3.6324e-04\n",
      "Epoch 893/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5516e-04 - val_loss: 3.6506e-04\n",
      "Epoch 894/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5513e-04 - val_loss: 3.6296e-04\n",
      "Epoch 895/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5497e-04 - val_loss: 3.6395e-04\n",
      "Epoch 896/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5488e-04 - val_loss: 3.6258e-04\n",
      "Epoch 897/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5493e-04 - val_loss: 3.6272e-04\n",
      "Epoch 898/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5503e-04 - val_loss: 3.6280e-04\n",
      "Epoch 899/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5481e-04 - val_loss: 3.6276e-04\n",
      "Epoch 900/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5473e-04 - val_loss: 3.6314e-04\n",
      "Epoch 901/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5462e-04 - val_loss: 3.6356e-04\n",
      "Epoch 902/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5462e-04 - val_loss: 3.6303e-04\n",
      "Epoch 903/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5455e-04 - val_loss: 3.6349e-04\n",
      "Epoch 904/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5445e-04 - val_loss: 3.6260e-04\n",
      "Epoch 905/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5452e-04 - val_loss: 3.6366e-04\n",
      "Epoch 906/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5464e-04 - val_loss: 3.6340e-04\n",
      "Epoch 907/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5442e-04 - val_loss: 3.6250e-04\n",
      "Epoch 908/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5429e-04 - val_loss: 3.6305e-04\n",
      "Epoch 909/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5438e-04 - val_loss: 3.6275e-04\n",
      "Epoch 910/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5415e-04 - val_loss: 3.6302e-04\n",
      "Epoch 911/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5418e-04 - val_loss: 3.6264e-04\n",
      "Epoch 912/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5425e-04 - val_loss: 3.6260e-04\n",
      "Epoch 913/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5420e-04 - val_loss: 3.6229e-04\n",
      "Epoch 914/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5417e-04 - val_loss: 3.6267e-04\n",
      "Epoch 915/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5431e-04 - val_loss: 3.6319e-04\n",
      "Epoch 916/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5402e-04 - val_loss: 3.6316e-04\n",
      "Epoch 917/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5382e-04 - val_loss: 3.6326e-04\n",
      "Epoch 918/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5418e-04 - val_loss: 3.6274e-04\n",
      "Epoch 919/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5402e-04 - val_loss: 3.6386e-04\n",
      "Epoch 920/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5403e-04 - val_loss: 3.6258e-04\n",
      "Epoch 921/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5386e-04 - val_loss: 3.6247e-04\n",
      "Epoch 922/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5378e-04 - val_loss: 3.6237e-04\n",
      "Epoch 923/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5383e-04 - val_loss: 3.6289e-04\n",
      "Epoch 924/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5374e-04 - val_loss: 3.6224e-04\n",
      "Epoch 925/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5381e-04 - val_loss: 3.6219e-04\n",
      "Epoch 926/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5366e-04 - val_loss: 3.6205e-04\n",
      "Epoch 927/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5343e-04 - val_loss: 3.6244e-04\n",
      "Epoch 928/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5357e-04 - val_loss: 3.6256e-04\n",
      "Epoch 929/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5373e-04 - val_loss: 3.6152e-04\n",
      "Epoch 930/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5346e-04 - val_loss: 3.6218e-04\n",
      "Epoch 931/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5339e-04 - val_loss: 3.6202e-04\n",
      "Epoch 932/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5338e-04 - val_loss: 3.6251e-04\n",
      "Epoch 933/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5338e-04 - val_loss: 3.6186e-04\n",
      "Epoch 934/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5367e-04 - val_loss: 3.6201e-04\n",
      "Epoch 935/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5318e-04 - val_loss: 3.6187e-04\n",
      "Epoch 936/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5347e-04 - val_loss: 3.6184e-04\n",
      "Epoch 937/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5348e-04 - val_loss: 3.6174e-04\n",
      "Epoch 938/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5317e-04 - val_loss: 3.6149e-04\n",
      "Epoch 939/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5332e-04 - val_loss: 3.6122e-04\n",
      "Epoch 940/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5304e-04 - val_loss: 3.6133e-04\n",
      "Epoch 941/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5294e-04 - val_loss: 3.6105e-04\n",
      "Epoch 942/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5281e-04 - val_loss: 3.6153e-04\n",
      "Epoch 943/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5297e-04 - val_loss: 3.6175e-04\n",
      "Epoch 944/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5308e-04 - val_loss: 3.6157e-04\n",
      "Epoch 945/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5292e-04 - val_loss: 3.6114e-04\n",
      "Epoch 946/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5292e-04 - val_loss: 3.6133e-04\n",
      "Epoch 947/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5285e-04 - val_loss: 3.6099e-04\n",
      "Epoch 948/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5281e-04 - val_loss: 3.6179e-04\n",
      "Epoch 949/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5290e-04 - val_loss: 3.6224e-04\n",
      "Epoch 950/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5271e-04 - val_loss: 3.6127e-04\n",
      "Epoch 951/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5263e-04 - val_loss: 3.6104e-04\n",
      "Epoch 952/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5277e-04 - val_loss: 3.6138e-04\n",
      "Epoch 953/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5254e-04 - val_loss: 3.6060e-04\n",
      "Epoch 954/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5281e-04 - val_loss: 3.6209e-04\n",
      "Epoch 955/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5243e-04 - val_loss: 3.6086e-04\n",
      "Epoch 956/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5276e-04 - val_loss: 3.6134e-04\n",
      "Epoch 957/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5237e-04 - val_loss: 3.6075e-04\n",
      "Epoch 958/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5234e-04 - val_loss: 3.6104e-04\n",
      "Epoch 959/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5232e-04 - val_loss: 3.6047e-04\n",
      "Epoch 960/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5237e-04 - val_loss: 3.6075e-04\n",
      "Epoch 961/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5238e-04 - val_loss: 3.6151e-04\n",
      "Epoch 962/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5256e-04 - val_loss: 3.6034e-04\n",
      "Epoch 963/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5222e-04 - val_loss: 3.6100e-04\n",
      "Epoch 964/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5214e-04 - val_loss: 3.6068e-04\n",
      "Epoch 965/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5206e-04 - val_loss: 3.6043e-04\n",
      "Epoch 966/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5190e-04 - val_loss: 3.6249e-04\n",
      "Epoch 967/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5226e-04 - val_loss: 3.6166e-04\n",
      "Epoch 968/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5205e-04 - val_loss: 3.6148e-04\n",
      "Epoch 969/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5210e-04 - val_loss: 3.6098e-04\n",
      "Epoch 970/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5206e-04 - val_loss: 3.6117e-04\n",
      "Epoch 971/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5213e-04 - val_loss: 3.6051e-04\n",
      "Epoch 972/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5194e-04 - val_loss: 3.6014e-04\n",
      "Epoch 973/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5194e-04 - val_loss: 3.6116e-04\n",
      "Epoch 974/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5175e-04 - val_loss: 3.6087e-04\n",
      "Epoch 975/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5181e-04 - val_loss: 3.6045e-04\n",
      "Epoch 976/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5209e-04 - val_loss: 3.5998e-04\n",
      "Epoch 977/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5163e-04 - val_loss: 3.6048e-04\n",
      "Epoch 978/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5187e-04 - val_loss: 3.6036e-04\n",
      "Epoch 979/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5164e-04 - val_loss: 3.6013e-04\n",
      "Epoch 980/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5147e-04 - val_loss: 3.6000e-04\n",
      "Epoch 981/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5175e-04 - val_loss: 3.6010e-04\n",
      "Epoch 982/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5147e-04 - val_loss: 3.6058e-04\n",
      "Epoch 983/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5167e-04 - val_loss: 3.6035e-04\n",
      "Epoch 984/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5161e-04 - val_loss: 3.5999e-04\n",
      "Epoch 985/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5148e-04 - val_loss: 3.6032e-04\n",
      "Epoch 986/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5150e-04 - val_loss: 3.5961e-04\n",
      "Epoch 987/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5138e-04 - val_loss: 3.5964e-04\n",
      "Epoch 988/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5123e-04 - val_loss: 3.5985e-04\n",
      "Epoch 989/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5156e-04 - val_loss: 3.5977e-04\n",
      "Epoch 990/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5119e-04 - val_loss: 3.5988e-04\n",
      "Epoch 991/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5112e-04 - val_loss: 3.5982e-04\n",
      "Epoch 992/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5108e-04 - val_loss: 3.5987e-04\n",
      "Epoch 993/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5118e-04 - val_loss: 3.5940e-04\n",
      "Epoch 994/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5112e-04 - val_loss: 3.5935e-04\n",
      "Epoch 995/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5087e-04 - val_loss: 3.6018e-04\n",
      "Epoch 996/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5102e-04 - val_loss: 3.5905e-04\n",
      "Epoch 997/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5093e-04 - val_loss: 3.5954e-04\n",
      "Epoch 998/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5103e-04 - val_loss: 3.5962e-04\n",
      "Epoch 999/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5089e-04 - val_loss: 3.5989e-04\n",
      "Epoch 1000/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5078e-04 - val_loss: 3.5931e-04\n",
      "INFO:tensorflow:Assets written to: AET_CF_Trial_14/models/saved_model_14_LSP_AET_CF_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: AET_CF_Trial_14/models/saved_model_14_LSP_AET_CF_0/assets\n",
      "  2%|▋                                      | 1/57 [22:31<21:01:06, 1351.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5083e-04 - val_loss: 3.5997e-04\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5078e-04 - val_loss: 3.5940e-04\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5058e-04 - val_loss: 3.5952e-04\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.5074e-04 - val_loss: 3.5948e-04\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5070e-04 - val_loss: 3.5865e-04\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5056e-04 - val_loss: 3.5904e-04\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5054e-04 - val_loss: 3.5900e-04\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5082e-04 - val_loss: 3.5932e-04\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5047e-04 - val_loss: 3.5905e-04\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5098e-04 - val_loss: 3.5913e-04\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5044e-04 - val_loss: 3.5953e-04\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5054e-04 - val_loss: 3.5923e-04\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5033e-04 - val_loss: 3.5914e-04\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5029e-04 - val_loss: 3.5942e-04\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5031e-04 - val_loss: 3.5982e-04\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5027e-04 - val_loss: 3.5908e-04\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5030e-04 - val_loss: 3.5848e-04\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5015e-04 - val_loss: 3.5956e-04\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5040e-04 - val_loss: 3.5841e-04\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5004e-04 - val_loss: 3.6012e-04\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4995e-04 - val_loss: 3.5853e-04\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5021e-04 - val_loss: 3.5840e-04\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5007e-04 - val_loss: 3.5990e-04\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5005e-04 - val_loss: 3.6150e-04\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5019e-04 - val_loss: 3.5883e-04\n",
      "Epoch 26/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5002e-04 - val_loss: 3.5839e-04\n",
      "Epoch 27/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4989e-04 - val_loss: 3.5852e-04\n",
      "Epoch 28/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4970e-04 - val_loss: 3.5883e-04\n",
      "Epoch 29/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4983e-04 - val_loss: 3.6016e-04\n",
      "Epoch 30/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4965e-04 - val_loss: 3.5880e-04\n",
      "Epoch 31/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.5001e-04 - val_loss: 3.5856e-04\n",
      "Epoch 32/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4957e-04 - val_loss: 3.5898e-04\n",
      "Epoch 33/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4960e-04 - val_loss: 3.5821e-04\n",
      "Epoch 34/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4949e-04 - val_loss: 3.5830e-04\n",
      "Epoch 35/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4972e-04 - val_loss: 3.5787e-04\n",
      "Epoch 36/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4968e-04 - val_loss: 3.5790e-04\n",
      "Epoch 37/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4952e-04 - val_loss: 3.5821e-04\n",
      "Epoch 38/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4949e-04 - val_loss: 3.6023e-04\n",
      "Epoch 39/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4975e-04 - val_loss: 3.5813e-04\n",
      "Epoch 40/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4964e-04 - val_loss: 3.5773e-04\n",
      "Epoch 41/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4940e-04 - val_loss: 3.5803e-04\n",
      "Epoch 42/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4933e-04 - val_loss: 3.5838e-04\n",
      "Epoch 43/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4961e-04 - val_loss: 3.5764e-04\n",
      "Epoch 44/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4931e-04 - val_loss: 3.5758e-04\n",
      "Epoch 45/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4934e-04 - val_loss: 3.5796e-04\n",
      "Epoch 46/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4912e-04 - val_loss: 3.5815e-04\n",
      "Epoch 47/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4938e-04 - val_loss: 3.5785e-04\n",
      "Epoch 48/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4928e-04 - val_loss: 3.5761e-04\n",
      "Epoch 49/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4914e-04 - val_loss: 3.5843e-04\n",
      "Epoch 50/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4903e-04 - val_loss: 3.5821e-04\n",
      "Epoch 51/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4911e-04 - val_loss: 3.5759e-04\n",
      "Epoch 52/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4898e-04 - val_loss: 3.5817e-04\n",
      "Epoch 53/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4898e-04 - val_loss: 3.5745e-04\n",
      "Epoch 54/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4932e-04 - val_loss: 3.5749e-04\n",
      "Epoch 55/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4893e-04 - val_loss: 3.5712e-04\n",
      "Epoch 56/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4866e-04 - val_loss: 3.5827e-04\n",
      "Epoch 57/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4891e-04 - val_loss: 3.5759e-04\n",
      "Epoch 58/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4888e-04 - val_loss: 3.5773e-04\n",
      "Epoch 59/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4890e-04 - val_loss: 3.5709e-04\n",
      "Epoch 60/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4882e-04 - val_loss: 3.5722e-04\n",
      "Epoch 61/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4878e-04 - val_loss: 3.5769e-04\n",
      "Epoch 62/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4865e-04 - val_loss: 3.5712e-04\n",
      "Epoch 63/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4840e-04 - val_loss: 3.5736e-04\n",
      "Epoch 64/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4858e-04 - val_loss: 3.5719e-04\n",
      "Epoch 65/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4853e-04 - val_loss: 3.5779e-04\n",
      "Epoch 66/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4862e-04 - val_loss: 3.5683e-04\n",
      "Epoch 67/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4866e-04 - val_loss: 3.5717e-04\n",
      "Epoch 68/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4845e-04 - val_loss: 3.5704e-04\n",
      "Epoch 69/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4862e-04 - val_loss: 3.5699e-04\n",
      "Epoch 70/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4847e-04 - val_loss: 3.5759e-04\n",
      "Epoch 71/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4854e-04 - val_loss: 3.5771e-04\n",
      "Epoch 72/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4840e-04 - val_loss: 3.5776e-04\n",
      "Epoch 73/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4844e-04 - val_loss: 3.5668e-04\n",
      "Epoch 74/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4816e-04 - val_loss: 3.5654e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4821e-04 - val_loss: 3.5644e-04\n",
      "Epoch 76/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4801e-04 - val_loss: 3.5665e-04\n",
      "Epoch 77/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4811e-04 - val_loss: 3.5663e-04\n",
      "Epoch 78/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4797e-04 - val_loss: 3.5705e-04\n",
      "Epoch 79/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4793e-04 - val_loss: 3.5665e-04\n",
      "Epoch 80/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4788e-04 - val_loss: 3.5670e-04\n",
      "Epoch 81/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4823e-04 - val_loss: 3.5715e-04\n",
      "Epoch 82/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4802e-04 - val_loss: 3.5706e-04\n",
      "Epoch 83/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4787e-04 - val_loss: 3.5695e-04\n",
      "Epoch 84/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.4802e-04 - val_loss: 3.5647e-04\n",
      "Epoch 85/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4779e-04 - val_loss: 3.5700e-04\n",
      "Epoch 86/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4774e-04 - val_loss: 3.5694e-04\n",
      "Epoch 87/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4782e-04 - val_loss: 3.5635e-04\n",
      "Epoch 88/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4768e-04 - val_loss: 3.5693e-04\n",
      "Epoch 89/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4792e-04 - val_loss: 3.5682e-04\n",
      "Epoch 90/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4773e-04 - val_loss: 3.5626e-04\n",
      "Epoch 91/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4776e-04 - val_loss: 3.5614e-04\n",
      "Epoch 92/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4776e-04 - val_loss: 3.5616e-04\n",
      "Epoch 93/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4801e-04 - val_loss: 3.5681e-04\n",
      "Epoch 94/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4783e-04 - val_loss: 3.5573e-04\n",
      "Epoch 95/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4743e-04 - val_loss: 3.5625e-04\n",
      "Epoch 96/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4732e-04 - val_loss: 3.5653e-04\n",
      "Epoch 97/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4730e-04 - val_loss: 3.5727e-04\n",
      "Epoch 98/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4747e-04 - val_loss: 3.5659e-04\n",
      "Epoch 99/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4757e-04 - val_loss: 3.5619e-04\n",
      "Epoch 100/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4755e-04 - val_loss: 3.5629e-04\n",
      "Epoch 101/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4748e-04 - val_loss: 3.5683e-04\n",
      "Epoch 102/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4724e-04 - val_loss: 3.5596e-04\n",
      "Epoch 103/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4707e-04 - val_loss: 3.5594e-04\n",
      "Epoch 104/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4710e-04 - val_loss: 3.5610e-04\n",
      "Epoch 105/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4711e-04 - val_loss: 3.5666e-04\n",
      "Epoch 106/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4692e-04 - val_loss: 3.5593e-04\n",
      "Epoch 107/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4713e-04 - val_loss: 3.5638e-04\n",
      "Epoch 108/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4708e-04 - val_loss: 3.5661e-04\n",
      "Epoch 109/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4712e-04 - val_loss: 3.5574e-04\n",
      "Epoch 110/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4697e-04 - val_loss: 3.5620e-04\n",
      "Epoch 111/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4705e-04 - val_loss: 3.5583e-04\n",
      "Epoch 112/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4693e-04 - val_loss: 3.5563e-04\n",
      "Epoch 113/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4688e-04 - val_loss: 3.5646e-04\n",
      "Epoch 114/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4702e-04 - val_loss: 3.5622e-04\n",
      "Epoch 115/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4716e-04 - val_loss: 3.5559e-04\n",
      "Epoch 116/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4695e-04 - val_loss: 3.5575e-04\n",
      "Epoch 117/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4670e-04 - val_loss: 3.5608e-04\n",
      "Epoch 118/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4685e-04 - val_loss: 3.5533e-04\n",
      "Epoch 119/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4665e-04 - val_loss: 3.5479e-04\n",
      "Epoch 120/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4666e-04 - val_loss: 3.5566e-04\n",
      "Epoch 121/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4642e-04 - val_loss: 3.5541e-04\n",
      "Epoch 122/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4654e-04 - val_loss: 3.5530e-04\n",
      "Epoch 123/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4651e-04 - val_loss: 3.5568e-04\n",
      "Epoch 124/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4649e-04 - val_loss: 3.5568e-04\n",
      "Epoch 125/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4662e-04 - val_loss: 3.5618e-04\n",
      "Epoch 126/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4648e-04 - val_loss: 3.5695e-04\n",
      "Epoch 127/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4656e-04 - val_loss: 3.5551e-04\n",
      "Epoch 128/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4617e-04 - val_loss: 3.5556e-04\n",
      "Epoch 129/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4862e-04 - val_loss: 3.5583e-04\n",
      "Epoch 130/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4734e-04 - val_loss: 3.5508e-04\n",
      "Epoch 131/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4636e-04 - val_loss: 3.5491e-04\n",
      "Epoch 132/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4606e-04 - val_loss: 3.5505e-04\n",
      "Epoch 133/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4625e-04 - val_loss: 3.5515e-04\n",
      "Epoch 134/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4630e-04 - val_loss: 3.5527e-04\n",
      "Epoch 135/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4638e-04 - val_loss: 3.5499e-04\n",
      "Epoch 136/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4604e-04 - val_loss: 3.5580e-04\n",
      "Epoch 137/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4625e-04 - val_loss: 3.5578e-04\n",
      "Epoch 138/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4633e-04 - val_loss: 3.5553e-04\n",
      "Epoch 139/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4597e-04 - val_loss: 3.5528e-04\n",
      "Epoch 140/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4611e-04 - val_loss: 3.5478e-04\n",
      "Epoch 141/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4606e-04 - val_loss: 3.5481e-04\n",
      "Epoch 142/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4589e-04 - val_loss: 3.5516e-04\n",
      "Epoch 143/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4596e-04 - val_loss: 3.5459e-04\n",
      "Epoch 144/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4585e-04 - val_loss: 3.5548e-04\n",
      "Epoch 145/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4600e-04 - val_loss: 3.5482e-04\n",
      "Epoch 146/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4618e-04 - val_loss: 3.5544e-04\n",
      "Epoch 147/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4591e-04 - val_loss: 3.5494e-04\n",
      "Epoch 148/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4572e-04 - val_loss: 3.5414e-04\n",
      "Epoch 149/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4573e-04 - val_loss: 3.5485e-04\n",
      "Epoch 150/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4572e-04 - val_loss: 3.5544e-04\n",
      "Epoch 151/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4547e-04 - val_loss: 3.5502e-04\n",
      "Epoch 152/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4580e-04 - val_loss: 3.5438e-04\n",
      "Epoch 153/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4569e-04 - val_loss: 3.5459e-04\n",
      "Epoch 154/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4522e-04 - val_loss: 3.5458e-04\n",
      "Epoch 155/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4562e-04 - val_loss: 3.5441e-04\n",
      "Epoch 156/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4566e-04 - val_loss: 3.5419e-04\n",
      "Epoch 157/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4543e-04 - val_loss: 3.5463e-04\n",
      "Epoch 158/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4554e-04 - val_loss: 3.5531e-04\n",
      "Epoch 159/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4541e-04 - val_loss: 3.5427e-04\n",
      "Epoch 160/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4527e-04 - val_loss: 3.5399e-04\n",
      "Epoch 161/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4528e-04 - val_loss: 3.5489e-04\n",
      "Epoch 162/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4529e-04 - val_loss: 3.5555e-04\n",
      "Epoch 163/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4513e-04 - val_loss: 3.5454e-04\n",
      "Epoch 164/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4534e-04 - val_loss: 3.5419e-04\n",
      "Epoch 165/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4501e-04 - val_loss: 3.5486e-04\n",
      "Epoch 166/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4518e-04 - val_loss: 3.5528e-04\n",
      "Epoch 167/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4529e-04 - val_loss: 3.5383e-04\n",
      "Epoch 168/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4487e-04 - val_loss: 3.5382e-04\n",
      "Epoch 169/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4488e-04 - val_loss: 3.5396e-04\n",
      "Epoch 170/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4508e-04 - val_loss: 3.5571e-04\n",
      "Epoch 171/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4512e-04 - val_loss: 3.5432e-04\n",
      "Epoch 172/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4501e-04 - val_loss: 3.5417e-04\n",
      "Epoch 173/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4483e-04 - val_loss: 3.5377e-04\n",
      "Epoch 174/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.4492e-04 - val_loss: 3.5396e-04\n",
      "Epoch 175/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4481e-04 - val_loss: 3.5413e-04\n",
      "Epoch 176/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4493e-04 - val_loss: 3.5440e-04\n",
      "Epoch 177/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4482e-04 - val_loss: 3.5383e-04\n",
      "Epoch 178/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4488e-04 - val_loss: 3.5397e-04\n",
      "Epoch 179/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4455e-04 - val_loss: 3.5440e-04\n",
      "Epoch 180/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4456e-04 - val_loss: 3.5410e-04\n",
      "Epoch 181/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4456e-04 - val_loss: 3.5371e-04\n",
      "Epoch 182/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4476e-04 - val_loss: 3.5413e-04\n",
      "Epoch 183/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4454e-04 - val_loss: 3.5349e-04\n",
      "Epoch 184/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4468e-04 - val_loss: 3.5449e-04\n",
      "Epoch 185/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4455e-04 - val_loss: 3.5340e-04\n",
      "Epoch 186/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4457e-04 - val_loss: 3.5359e-04\n",
      "Epoch 187/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4440e-04 - val_loss: 3.5345e-04\n",
      "Epoch 188/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4434e-04 - val_loss: 3.5367e-04\n",
      "Epoch 189/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4460e-04 - val_loss: 3.5413e-04\n",
      "Epoch 190/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4443e-04 - val_loss: 3.5377e-04\n",
      "Epoch 191/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4419e-04 - val_loss: 3.5392e-04\n",
      "Epoch 192/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4413e-04 - val_loss: 3.5381e-04\n",
      "Epoch 193/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4413e-04 - val_loss: 3.5322e-04\n",
      "Epoch 194/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4415e-04 - val_loss: 3.5457e-04\n",
      "Epoch 195/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4431e-04 - val_loss: 3.5465e-04\n",
      "Epoch 196/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4424e-04 - val_loss: 3.5336e-04\n",
      "Epoch 197/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4394e-04 - val_loss: 3.5353e-04\n",
      "Epoch 198/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4421e-04 - val_loss: 3.5312e-04\n",
      "Epoch 199/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4408e-04 - val_loss: 3.5323e-04\n",
      "Epoch 200/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4414e-04 - val_loss: 3.5346e-04\n",
      "Epoch 201/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4407e-04 - val_loss: 3.5330e-04\n",
      "Epoch 202/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4382e-04 - val_loss: 3.5396e-04\n",
      "Epoch 203/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4393e-04 - val_loss: 3.5320e-04\n",
      "Epoch 204/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4428e-04 - val_loss: 3.5299e-04\n",
      "Epoch 205/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4372e-04 - val_loss: 3.5297e-04\n",
      "Epoch 206/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4378e-04 - val_loss: 3.5349e-04\n",
      "Epoch 207/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4410e-04 - val_loss: 3.5374e-04\n",
      "Epoch 208/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4381e-04 - val_loss: 3.5331e-04\n",
      "Epoch 209/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4373e-04 - val_loss: 3.5345e-04\n",
      "Epoch 210/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4381e-04 - val_loss: 3.5311e-04\n",
      "Epoch 211/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4362e-04 - val_loss: 3.5283e-04\n",
      "Epoch 212/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4382e-04 - val_loss: 3.5323e-04\n",
      "Epoch 213/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4359e-04 - val_loss: 3.5343e-04\n",
      "Epoch 214/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4382e-04 - val_loss: 3.5273e-04\n",
      "Epoch 215/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4350e-04 - val_loss: 3.5257e-04\n",
      "Epoch 216/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4344e-04 - val_loss: 3.5271e-04\n",
      "Epoch 217/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4366e-04 - val_loss: 3.5382e-04\n",
      "Epoch 218/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4342e-04 - val_loss: 3.5299e-04\n",
      "Epoch 219/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4316e-04 - val_loss: 3.5248e-04\n",
      "Epoch 220/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4342e-04 - val_loss: 3.5320e-04\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4332e-04 - val_loss: 3.5284e-04\n",
      "Epoch 222/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4323e-04 - val_loss: 3.5266e-04\n",
      "Epoch 223/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4355e-04 - val_loss: 3.5375e-04\n",
      "Epoch 224/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4316e-04 - val_loss: 3.5266e-04\n",
      "Epoch 225/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4368e-04 - val_loss: 3.5274e-04\n",
      "Epoch 226/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4340e-04 - val_loss: 3.5355e-04\n",
      "Epoch 227/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4330e-04 - val_loss: 3.5262e-04\n",
      "Epoch 228/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4325e-04 - val_loss: 3.5267e-04\n",
      "Epoch 229/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4309e-04 - val_loss: 3.5269e-04\n",
      "Epoch 230/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4293e-04 - val_loss: 3.5304e-04\n",
      "Epoch 231/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4287e-04 - val_loss: 3.5260e-04\n",
      "Epoch 232/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4312e-04 - val_loss: 3.5450e-04\n",
      "Epoch 233/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4285e-04 - val_loss: 3.5241e-04\n",
      "Epoch 234/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4287e-04 - val_loss: 3.5221e-04\n",
      "Epoch 235/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4299e-04 - val_loss: 3.5219e-04\n",
      "Epoch 236/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4299e-04 - val_loss: 3.5234e-04\n",
      "Epoch 237/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4289e-04 - val_loss: 3.5254e-04\n",
      "Epoch 238/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4289e-04 - val_loss: 3.5325e-04\n",
      "Epoch 239/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4297e-04 - val_loss: 3.5185e-04\n",
      "Epoch 240/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4266e-04 - val_loss: 3.5231e-04\n",
      "Epoch 241/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4274e-04 - val_loss: 3.5224e-04\n",
      "Epoch 242/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4271e-04 - val_loss: 3.5251e-04\n",
      "Epoch 243/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4268e-04 - val_loss: 3.5271e-04\n",
      "Epoch 244/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4261e-04 - val_loss: 3.5284e-04\n",
      "Epoch 245/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4249e-04 - val_loss: 3.5317e-04\n",
      "Epoch 246/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4247e-04 - val_loss: 3.5195e-04\n",
      "Epoch 247/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4311e-04 - val_loss: 3.5187e-04\n",
      "Epoch 248/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4260e-04 - val_loss: 3.5430e-04\n",
      "Epoch 249/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4259e-04 - val_loss: 3.5194e-04\n",
      "Epoch 250/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4244e-04 - val_loss: 3.5205e-04\n",
      "Epoch 251/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4233e-04 - val_loss: 3.5270e-04\n",
      "Epoch 252/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4218e-04 - val_loss: 3.5204e-04\n",
      "Epoch 253/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4251e-04 - val_loss: 3.5160e-04\n",
      "Epoch 254/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4221e-04 - val_loss: 3.5293e-04\n",
      "Epoch 255/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4235e-04 - val_loss: 3.5170e-04\n",
      "Epoch 256/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4225e-04 - val_loss: 3.5200e-04\n",
      "Epoch 257/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4209e-04 - val_loss: 3.5191e-04\n",
      "Epoch 258/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4205e-04 - val_loss: 3.5142e-04\n",
      "Epoch 259/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4216e-04 - val_loss: 3.5163e-04\n",
      "Epoch 260/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4219e-04 - val_loss: 3.5174e-04\n",
      "Epoch 261/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4207e-04 - val_loss: 3.5218e-04\n",
      "Epoch 262/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4207e-04 - val_loss: 3.5239e-04\n",
      "Epoch 263/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4233e-04 - val_loss: 3.5273e-04\n",
      "Epoch 264/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.4199e-04 - val_loss: 3.5159e-04\n",
      "Epoch 265/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4197e-04 - val_loss: 3.5248e-04\n",
      "Epoch 266/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4176e-04 - val_loss: 3.5129e-04\n",
      "Epoch 267/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4201e-04 - val_loss: 3.5238e-04\n",
      "Epoch 268/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4181e-04 - val_loss: 3.5150e-04\n",
      "Epoch 269/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4177e-04 - val_loss: 3.5288e-04\n",
      "Epoch 270/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4178e-04 - val_loss: 3.5193e-04\n",
      "Epoch 271/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4154e-04 - val_loss: 3.5177e-04\n",
      "Epoch 272/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4173e-04 - val_loss: 3.5190e-04\n",
      "Epoch 273/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4174e-04 - val_loss: 3.5116e-04\n",
      "Epoch 274/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4168e-04 - val_loss: 3.5117e-04\n",
      "Epoch 275/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4152e-04 - val_loss: 3.5092e-04\n",
      "Epoch 276/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4197e-04 - val_loss: 3.5101e-04\n",
      "Epoch 277/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4148e-04 - val_loss: 3.5091e-04\n",
      "Epoch 278/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4150e-04 - val_loss: 3.5090e-04\n",
      "Epoch 279/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4177e-04 - val_loss: 3.5130e-04\n",
      "Epoch 280/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4164e-04 - val_loss: 3.5092e-04\n",
      "Epoch 281/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4133e-04 - val_loss: 3.5104e-04\n",
      "Epoch 282/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4153e-04 - val_loss: 3.5129e-04\n",
      "Epoch 283/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4136e-04 - val_loss: 3.5095e-04\n",
      "Epoch 284/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4163e-04 - val_loss: 3.5085e-04\n",
      "Epoch 285/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4136e-04 - val_loss: 3.5097e-04\n",
      "Epoch 286/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4133e-04 - val_loss: 3.5150e-04\n",
      "Epoch 287/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4099e-04 - val_loss: 3.5044e-04\n",
      "Epoch 288/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4122e-04 - val_loss: 3.5075e-04\n",
      "Epoch 289/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4113e-04 - val_loss: 3.5085e-04\n",
      "Epoch 290/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4141e-04 - val_loss: 3.5062e-04\n",
      "Epoch 291/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4120e-04 - val_loss: 3.5040e-04\n",
      "Epoch 292/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4103e-04 - val_loss: 3.5107e-04\n",
      "Epoch 293/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4090e-04 - val_loss: 3.5095e-04\n",
      "Epoch 294/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4102e-04 - val_loss: 3.5109e-04\n",
      "Epoch 295/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4110e-04 - val_loss: 3.5122e-04\n",
      "Epoch 296/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4121e-04 - val_loss: 3.5223e-04\n",
      "Epoch 297/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4106e-04 - val_loss: 3.5104e-04\n",
      "Epoch 298/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4118e-04 - val_loss: 3.5043e-04\n",
      "Epoch 299/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4097e-04 - val_loss: 3.5022e-04\n",
      "Epoch 300/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4073e-04 - val_loss: 3.5016e-04\n",
      "Epoch 301/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4105e-04 - val_loss: 3.5028e-04\n",
      "Epoch 302/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4067e-04 - val_loss: 3.5034e-04\n",
      "Epoch 303/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4073e-04 - val_loss: 3.5014e-04\n",
      "Epoch 304/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4085e-04 - val_loss: 3.4983e-04\n",
      "Epoch 305/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4073e-04 - val_loss: 3.5083e-04\n",
      "Epoch 306/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4077e-04 - val_loss: 3.5065e-04\n",
      "Epoch 307/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4094e-04 - val_loss: 3.5009e-04\n",
      "Epoch 308/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4063e-04 - val_loss: 3.5017e-04\n",
      "Epoch 309/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4051e-04 - val_loss: 3.5036e-04\n",
      "Epoch 310/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4054e-04 - val_loss: 3.5052e-04\n",
      "Epoch 311/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4052e-04 - val_loss: 3.5000e-04\n",
      "Epoch 312/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4041e-04 - val_loss: 3.5013e-04\n",
      "Epoch 313/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4054e-04 - val_loss: 3.5083e-04\n",
      "Epoch 314/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4032e-04 - val_loss: 3.5063e-04\n",
      "Epoch 315/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4043e-04 - val_loss: 3.5026e-04\n",
      "Epoch 316/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4033e-04 - val_loss: 3.4943e-04\n",
      "Epoch 317/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.4035e-04 - val_loss: 3.5078e-04\n",
      "Epoch 318/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4023e-04 - val_loss: 3.5005e-04\n",
      "Epoch 319/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4033e-04 - val_loss: 3.4978e-04\n",
      "Epoch 320/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4016e-04 - val_loss: 3.5059e-04\n",
      "Epoch 321/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4017e-04 - val_loss: 3.4945e-04\n",
      "Epoch 322/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4047e-04 - val_loss: 3.4953e-04\n",
      "Epoch 323/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4026e-04 - val_loss: 3.4978e-04\n",
      "Epoch 324/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4023e-04 - val_loss: 3.5019e-04\n",
      "Epoch 325/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4009e-04 - val_loss: 3.5016e-04\n",
      "Epoch 326/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4044e-04 - val_loss: 3.5010e-04\n",
      "Epoch 327/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4048e-04 - val_loss: 3.4966e-04\n",
      "Epoch 328/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4015e-04 - val_loss: 3.4998e-04\n",
      "Epoch 329/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3992e-04 - val_loss: 3.4926e-04\n",
      "Epoch 330/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4006e-04 - val_loss: 3.4998e-04\n",
      "Epoch 331/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3982e-04 - val_loss: 3.4994e-04\n",
      "Epoch 332/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3975e-04 - val_loss: 3.4931e-04\n",
      "Epoch 333/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3988e-04 - val_loss: 3.5007e-04\n",
      "Epoch 334/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.4028e-04 - val_loss: 3.4987e-04\n",
      "Epoch 335/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3970e-04 - val_loss: 3.5036e-04\n",
      "Epoch 336/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3962e-04 - val_loss: 3.4960e-04\n",
      "Epoch 337/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3984e-04 - val_loss: 3.5002e-04\n",
      "Epoch 338/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3968e-04 - val_loss: 3.4987e-04\n",
      "Epoch 339/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3957e-04 - val_loss: 3.5003e-04\n",
      "Epoch 340/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3995e-04 - val_loss: 3.5229e-04\n",
      "Epoch 341/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3977e-04 - val_loss: 3.5086e-04\n",
      "Epoch 342/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3976e-04 - val_loss: 3.4967e-04\n",
      "Epoch 343/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3951e-04 - val_loss: 3.4942e-04\n",
      "Epoch 344/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3945e-04 - val_loss: 3.4985e-04\n",
      "Epoch 345/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3953e-04 - val_loss: 3.4933e-04\n",
      "Epoch 346/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3944e-04 - val_loss: 3.4953e-04\n",
      "Epoch 347/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3943e-04 - val_loss: 3.4963e-04\n",
      "Epoch 348/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3948e-04 - val_loss: 3.4917e-04\n",
      "Epoch 349/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3936e-04 - val_loss: 3.4938e-04\n",
      "Epoch 350/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3938e-04 - val_loss: 3.4936e-04\n",
      "Epoch 351/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3937e-04 - val_loss: 3.4912e-04\n",
      "Epoch 352/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3927e-04 - val_loss: 3.4921e-04\n",
      "Epoch 353/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3922e-04 - val_loss: 3.4982e-04\n",
      "Epoch 354/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3954e-04 - val_loss: 3.4910e-04\n",
      "Epoch 355/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3906e-04 - val_loss: 3.4889e-04\n",
      "Epoch 356/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3949e-04 - val_loss: 3.4940e-04\n",
      "Epoch 357/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3922e-04 - val_loss: 3.4873e-04\n",
      "Epoch 358/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3909e-04 - val_loss: 3.4961e-04\n",
      "Epoch 359/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3880e-04 - val_loss: 3.4839e-04\n",
      "Epoch 360/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3914e-04 - val_loss: 3.4890e-04\n",
      "Epoch 361/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3907e-04 - val_loss: 3.4917e-04\n",
      "Epoch 362/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3899e-04 - val_loss: 3.4860e-04\n",
      "Epoch 363/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3889e-04 - val_loss: 3.4970e-04\n",
      "Epoch 364/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3885e-04 - val_loss: 3.5037e-04\n",
      "Epoch 365/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3906e-04 - val_loss: 3.4999e-04\n",
      "Epoch 366/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3896e-04 - val_loss: 3.4850e-04\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3895e-04 - val_loss: 3.4894e-04\n",
      "Epoch 368/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3891e-04 - val_loss: 3.4905e-04\n",
      "Epoch 369/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3890e-04 - val_loss: 3.4861e-04\n",
      "Epoch 370/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3867e-04 - val_loss: 3.4872e-04\n",
      "Epoch 371/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3871e-04 - val_loss: 3.4903e-04\n",
      "Epoch 372/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3867e-04 - val_loss: 3.4882e-04\n",
      "Epoch 373/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3853e-04 - val_loss: 3.4874e-04\n",
      "Epoch 374/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3871e-04 - val_loss: 3.4856e-04\n",
      "Epoch 375/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3873e-04 - val_loss: 3.4853e-04\n",
      "Epoch 376/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3854e-04 - val_loss: 3.4885e-04\n",
      "Epoch 377/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3858e-04 - val_loss: 3.4923e-04\n",
      "Epoch 378/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3863e-04 - val_loss: 3.4986e-04\n",
      "Epoch 379/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3868e-04 - val_loss: 3.4842e-04\n",
      "Epoch 380/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3854e-04 - val_loss: 3.4836e-04\n",
      "Epoch 381/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3865e-04 - val_loss: 3.4894e-04\n",
      "Epoch 382/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3846e-04 - val_loss: 3.4805e-04\n",
      "Epoch 383/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3832e-04 - val_loss: 3.4791e-04\n",
      "Epoch 384/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3849e-04 - val_loss: 3.4815e-04\n",
      "Epoch 385/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3833e-04 - val_loss: 3.4855e-04\n",
      "Epoch 386/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3830e-04 - val_loss: 3.4803e-04\n",
      "Epoch 387/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3840e-04 - val_loss: 3.4853e-04\n",
      "Epoch 388/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3833e-04 - val_loss: 3.4787e-04\n",
      "Epoch 389/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3857e-04 - val_loss: 3.4903e-04\n",
      "Epoch 390/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3809e-04 - val_loss: 3.4826e-04\n",
      "Epoch 391/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3824e-04 - val_loss: 3.4934e-04\n",
      "Epoch 392/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3815e-04 - val_loss: 3.4994e-04\n",
      "Epoch 393/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3797e-04 - val_loss: 3.4796e-04\n",
      "Epoch 394/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3814e-04 - val_loss: 3.4863e-04\n",
      "Epoch 395/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3841e-04 - val_loss: 3.4830e-04\n",
      "Epoch 396/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3803e-04 - val_loss: 3.4844e-04\n",
      "Epoch 397/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3817e-04 - val_loss: 3.4846e-04\n",
      "Epoch 398/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3799e-04 - val_loss: 3.4787e-04\n",
      "Epoch 399/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3839e-04 - val_loss: 3.4742e-04\n",
      "Epoch 400/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3784e-04 - val_loss: 3.4751e-04\n",
      "Epoch 401/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3798e-04 - val_loss: 3.4795e-04\n",
      "Epoch 402/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3775e-04 - val_loss: 3.4849e-04\n",
      "Epoch 403/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3801e-04 - val_loss: 3.4763e-04\n",
      "Epoch 404/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3772e-04 - val_loss: 3.4747e-04\n",
      "Epoch 405/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3791e-04 - val_loss: 3.4798e-04\n",
      "Epoch 406/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3757e-04 - val_loss: 3.4704e-04\n",
      "Epoch 407/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3793e-04 - val_loss: 3.4766e-04\n",
      "Epoch 408/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3767e-04 - val_loss: 3.4733e-04\n",
      "Epoch 409/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3770e-04 - val_loss: 3.4730e-04\n",
      "Epoch 410/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3774e-04 - val_loss: 3.4766e-04\n",
      "Epoch 411/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3769e-04 - val_loss: 3.4732e-04\n",
      "Epoch 412/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3758e-04 - val_loss: 3.4698e-04\n",
      "Epoch 413/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3760e-04 - val_loss: 3.4738e-04\n",
      "Epoch 414/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3767e-04 - val_loss: 3.4756e-04\n",
      "Epoch 415/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3764e-04 - val_loss: 3.4764e-04\n",
      "Epoch 416/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3752e-04 - val_loss: 3.4720e-04\n",
      "Epoch 417/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3724e-04 - val_loss: 3.4725e-04\n",
      "Epoch 418/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3731e-04 - val_loss: 3.4729e-04\n",
      "Epoch 419/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3753e-04 - val_loss: 3.4724e-04\n",
      "Epoch 420/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3762e-04 - val_loss: 3.4897e-04\n",
      "Epoch 421/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3768e-04 - val_loss: 3.4807e-04\n",
      "Epoch 422/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3745e-04 - val_loss: 3.4725e-04\n",
      "Epoch 423/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3770e-04 - val_loss: 3.4655e-04\n",
      "Epoch 424/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3705e-04 - val_loss: 3.4719e-04\n",
      "Epoch 425/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3728e-04 - val_loss: 3.4751e-04\n",
      "Epoch 426/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3713e-04 - val_loss: 3.4684e-04\n",
      "Epoch 427/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3739e-04 - val_loss: 3.4690e-04\n",
      "Epoch 428/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3713e-04 - val_loss: 3.4692e-04\n",
      "Epoch 429/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3740e-04 - val_loss: 3.4686e-04\n",
      "Epoch 430/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3688e-04 - val_loss: 3.4668e-04\n",
      "Epoch 431/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3714e-04 - val_loss: 3.4775e-04\n",
      "Epoch 432/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3702e-04 - val_loss: 3.4680e-04\n",
      "Epoch 433/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3706e-04 - val_loss: 3.4786e-04\n",
      "Epoch 434/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3686e-04 - val_loss: 3.4691e-04\n",
      "Epoch 435/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3708e-04 - val_loss: 3.4666e-04\n",
      "Epoch 436/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3704e-04 - val_loss: 3.4686e-04\n",
      "Epoch 437/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3683e-04 - val_loss: 3.4711e-04\n",
      "Epoch 438/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3679e-04 - val_loss: 3.4669e-04\n",
      "Epoch 439/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3681e-04 - val_loss: 3.4672e-04\n",
      "Epoch 440/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3676e-04 - val_loss: 3.4728e-04\n",
      "Epoch 441/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3676e-04 - val_loss: 3.4769e-04\n",
      "Epoch 442/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3699e-04 - val_loss: 3.5049e-04\n",
      "Epoch 443/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3686e-04 - val_loss: 3.4654e-04\n",
      "Epoch 444/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3688e-04 - val_loss: 3.4697e-04\n",
      "Epoch 445/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3662e-04 - val_loss: 3.4693e-04\n",
      "Epoch 446/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3671e-04 - val_loss: 3.4656e-04\n",
      "Epoch 447/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3656e-04 - val_loss: 3.4695e-04\n",
      "Epoch 448/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3646e-04 - val_loss: 3.4686e-04\n",
      "Epoch 449/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3664e-04 - val_loss: 3.4662e-04\n",
      "Epoch 450/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3671e-04 - val_loss: 3.4592e-04\n",
      "Epoch 451/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3672e-04 - val_loss: 3.4651e-04\n",
      "Epoch 452/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3646e-04 - val_loss: 3.4707e-04\n",
      "Epoch 453/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3651e-04 - val_loss: 3.4742e-04\n",
      "Epoch 454/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3642e-04 - val_loss: 3.4663e-04\n",
      "Epoch 455/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3645e-04 - val_loss: 3.4677e-04\n",
      "Epoch 456/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3641e-04 - val_loss: 3.4632e-04\n",
      "Epoch 457/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3632e-04 - val_loss: 3.4656e-04\n",
      "Epoch 458/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3625e-04 - val_loss: 3.4662e-04\n",
      "Epoch 459/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3633e-04 - val_loss: 3.4670e-04\n",
      "Epoch 460/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3659e-04 - val_loss: 3.4603e-04\n",
      "Epoch 461/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3641e-04 - val_loss: 3.4648e-04\n",
      "Epoch 462/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3618e-04 - val_loss: 3.4642e-04\n",
      "Epoch 463/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3614e-04 - val_loss: 3.4595e-04\n",
      "Epoch 464/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3611e-04 - val_loss: 3.4611e-04\n",
      "Epoch 465/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3596e-04 - val_loss: 3.4636e-04\n",
      "Epoch 466/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3616e-04 - val_loss: 3.4644e-04\n",
      "Epoch 467/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3608e-04 - val_loss: 3.4635e-04\n",
      "Epoch 468/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3598e-04 - val_loss: 3.4587e-04\n",
      "Epoch 469/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3596e-04 - val_loss: 3.4617e-04\n",
      "Epoch 470/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3603e-04 - val_loss: 3.4576e-04\n",
      "Epoch 471/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3602e-04 - val_loss: 3.4654e-04\n",
      "Epoch 472/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3591e-04 - val_loss: 3.4576e-04\n",
      "Epoch 473/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3578e-04 - val_loss: 3.4650e-04\n",
      "Epoch 474/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3603e-04 - val_loss: 3.4669e-04\n",
      "Epoch 475/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3610e-04 - val_loss: 3.4541e-04\n",
      "Epoch 476/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3614e-04 - val_loss: 3.4596e-04\n",
      "Epoch 477/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3566e-04 - val_loss: 3.4569e-04\n",
      "Epoch 478/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3594e-04 - val_loss: 3.4620e-04\n",
      "Epoch 479/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3565e-04 - val_loss: 3.4580e-04\n",
      "Epoch 480/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3563e-04 - val_loss: 3.4532e-04\n",
      "Epoch 481/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3555e-04 - val_loss: 3.4568e-04\n",
      "Epoch 482/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3581e-04 - val_loss: 3.4567e-04\n",
      "Epoch 483/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3575e-04 - val_loss: 3.4713e-04\n",
      "Epoch 484/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3533e-04 - val_loss: 3.4625e-04\n",
      "Epoch 485/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3561e-04 - val_loss: 3.4545e-04\n",
      "Epoch 486/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3551e-04 - val_loss: 3.4562e-04\n",
      "Epoch 487/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3530e-04 - val_loss: 3.4615e-04\n",
      "Epoch 488/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3570e-04 - val_loss: 3.4620e-04\n",
      "Epoch 489/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3540e-04 - val_loss: 3.4538e-04\n",
      "Epoch 490/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3553e-04 - val_loss: 3.4838e-04\n",
      "Epoch 491/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3532e-04 - val_loss: 3.4536e-04\n",
      "Epoch 492/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3547e-04 - val_loss: 3.4623e-04\n",
      "Epoch 493/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3532e-04 - val_loss: 3.4556e-04\n",
      "Epoch 494/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3526e-04 - val_loss: 3.4569e-04\n",
      "Epoch 495/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3530e-04 - val_loss: 3.4523e-04\n",
      "Epoch 496/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3533e-04 - val_loss: 3.4506e-04\n",
      "Epoch 497/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3541e-04 - val_loss: 3.4510e-04\n",
      "Epoch 498/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3507e-04 - val_loss: 3.4537e-04\n",
      "Epoch 499/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3521e-04 - val_loss: 3.4489e-04\n",
      "Epoch 500/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3508e-04 - val_loss: 3.4636e-04\n",
      "Epoch 501/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3527e-04 - val_loss: 3.4535e-04\n",
      "Epoch 502/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3509e-04 - val_loss: 3.4549e-04\n",
      "Epoch 503/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3498e-04 - val_loss: 3.4513e-04\n",
      "Epoch 504/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3490e-04 - val_loss: 3.4587e-04\n",
      "Epoch 505/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3505e-04 - val_loss: 3.4548e-04\n",
      "Epoch 506/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3498e-04 - val_loss: 3.4559e-04\n",
      "Epoch 507/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3473e-04 - val_loss: 3.4536e-04\n",
      "Epoch 508/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3530e-04 - val_loss: 3.4558e-04\n",
      "Epoch 509/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3504e-04 - val_loss: 3.4529e-04\n",
      "Epoch 510/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3490e-04 - val_loss: 3.4505e-04\n",
      "Epoch 511/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3496e-04 - val_loss: 3.4495e-04\n",
      "Epoch 512/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3488e-04 - val_loss: 3.4474e-04\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3484e-04 - val_loss: 3.4514e-04\n",
      "Epoch 514/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3476e-04 - val_loss: 3.4528e-04\n",
      "Epoch 515/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3478e-04 - val_loss: 3.4510e-04\n",
      "Epoch 516/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3458e-04 - val_loss: 3.4520e-04\n",
      "Epoch 517/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3472e-04 - val_loss: 3.4544e-04\n",
      "Epoch 518/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3444e-04 - val_loss: 3.4538e-04\n",
      "Epoch 519/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3455e-04 - val_loss: 3.4542e-04\n",
      "Epoch 520/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3533e-04 - val_loss: 3.4550e-04\n",
      "Epoch 521/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3455e-04 - val_loss: 3.4542e-04\n",
      "Epoch 522/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3450e-04 - val_loss: 3.4450e-04\n",
      "Epoch 523/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3467e-04 - val_loss: 3.4460e-04\n",
      "Epoch 524/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3432e-04 - val_loss: 3.4518e-04\n",
      "Epoch 525/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3454e-04 - val_loss: 3.4447e-04\n",
      "Epoch 526/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3444e-04 - val_loss: 3.4435e-04\n",
      "Epoch 527/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3438e-04 - val_loss: 3.4541e-04\n",
      "Epoch 528/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3452e-04 - val_loss: 3.4584e-04\n",
      "Epoch 529/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3481e-04 - val_loss: 3.4472e-04\n",
      "Epoch 530/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3439e-04 - val_loss: 3.4481e-04\n",
      "Epoch 531/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3425e-04 - val_loss: 3.4441e-04\n",
      "Epoch 532/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3409e-04 - val_loss: 3.4409e-04\n",
      "Epoch 533/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3411e-04 - val_loss: 3.4461e-04\n",
      "Epoch 534/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3436e-04 - val_loss: 3.4609e-04\n",
      "Epoch 535/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3440e-04 - val_loss: 3.4471e-04\n",
      "Epoch 536/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3417e-04 - val_loss: 3.4527e-04\n",
      "Epoch 537/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3439e-04 - val_loss: 3.4386e-04\n",
      "Epoch 538/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3398e-04 - val_loss: 3.4511e-04\n",
      "Epoch 539/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3431e-04 - val_loss: 3.4535e-04\n",
      "Epoch 540/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3387e-04 - val_loss: 3.4412e-04\n",
      "Epoch 541/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3401e-04 - val_loss: 3.4509e-04\n",
      "Epoch 542/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3407e-04 - val_loss: 3.4420e-04\n",
      "Epoch 543/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3380e-04 - val_loss: 3.4468e-04\n",
      "Epoch 544/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3392e-04 - val_loss: 3.4653e-04\n",
      "Epoch 545/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3406e-04 - val_loss: 3.4433e-04\n",
      "Epoch 546/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3392e-04 - val_loss: 3.4387e-04\n",
      "Epoch 547/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3378e-04 - val_loss: 3.4394e-04\n",
      "Epoch 548/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3374e-04 - val_loss: 3.4392e-04\n",
      "Epoch 549/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3362e-04 - val_loss: 3.4419e-04\n",
      "Epoch 550/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3386e-04 - val_loss: 3.4457e-04\n",
      "Epoch 551/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3359e-04 - val_loss: 3.4571e-04\n",
      "Epoch 552/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3363e-04 - val_loss: 3.4440e-04\n",
      "Epoch 553/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3380e-04 - val_loss: 3.4482e-04\n",
      "Epoch 554/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3378e-04 - val_loss: 3.4423e-04\n",
      "Epoch 555/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3388e-04 - val_loss: 3.4423e-04\n",
      "Epoch 556/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3377e-04 - val_loss: 3.4407e-04\n",
      "Epoch 557/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3347e-04 - val_loss: 3.4413e-04\n",
      "Epoch 558/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3358e-04 - val_loss: 3.4443e-04\n",
      "Epoch 559/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3342e-04 - val_loss: 3.4445e-04\n",
      "Epoch 560/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3352e-04 - val_loss: 3.4403e-04\n",
      "Epoch 561/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3354e-04 - val_loss: 3.4412e-04\n",
      "Epoch 562/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3350e-04 - val_loss: 3.4438e-04\n",
      "Epoch 563/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3347e-04 - val_loss: 3.4390e-04\n",
      "Epoch 564/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3327e-04 - val_loss: 3.4431e-04\n",
      "Epoch 565/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3334e-04 - val_loss: 3.4472e-04\n",
      "Epoch 566/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3339e-04 - val_loss: 3.4446e-04\n",
      "Epoch 567/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3353e-04 - val_loss: 3.4304e-04\n",
      "Epoch 568/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3351e-04 - val_loss: 3.4335e-04\n",
      "Epoch 569/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3335e-04 - val_loss: 3.4332e-04\n",
      "Epoch 570/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3330e-04 - val_loss: 3.4392e-04\n",
      "Epoch 571/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3318e-04 - val_loss: 3.4337e-04\n",
      "Epoch 572/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3320e-04 - val_loss: 3.4300e-04\n",
      "Epoch 573/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3364e-04 - val_loss: 3.4425e-04\n",
      "Epoch 574/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3319e-04 - val_loss: 3.4384e-04\n",
      "Epoch 575/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3334e-04 - val_loss: 3.4481e-04\n",
      "Epoch 576/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3289e-04 - val_loss: 3.4464e-04\n",
      "Epoch 577/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3299e-04 - val_loss: 3.4373e-04\n",
      "Epoch 578/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3315e-04 - val_loss: 3.4337e-04\n",
      "Epoch 579/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3288e-04 - val_loss: 3.4355e-04\n",
      "Epoch 580/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3309e-04 - val_loss: 3.4436e-04\n",
      "Epoch 581/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3300e-04 - val_loss: 3.4370e-04\n",
      "Epoch 582/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3278e-04 - val_loss: 3.4403e-04\n",
      "Epoch 583/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3282e-04 - val_loss: 3.4361e-04\n",
      "Epoch 584/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3268e-04 - val_loss: 3.4314e-04\n",
      "Epoch 585/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3300e-04 - val_loss: 3.4388e-04\n",
      "Epoch 586/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3285e-04 - val_loss: 3.4374e-04\n",
      "Epoch 587/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3278e-04 - val_loss: 3.4334e-04\n",
      "Epoch 588/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3286e-04 - val_loss: 3.4392e-04\n",
      "Epoch 589/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3266e-04 - val_loss: 3.4472e-04\n",
      "Epoch 590/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3273e-04 - val_loss: 3.4388e-04\n",
      "Epoch 591/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3272e-04 - val_loss: 3.4315e-04\n",
      "Epoch 592/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3261e-04 - val_loss: 3.4349e-04\n",
      "Epoch 593/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3244e-04 - val_loss: 3.4357e-04\n",
      "Epoch 594/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3257e-04 - val_loss: 3.4362e-04\n",
      "Epoch 595/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3262e-04 - val_loss: 3.4325e-04\n",
      "Epoch 596/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3266e-04 - val_loss: 3.4323e-04\n",
      "Epoch 597/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3261e-04 - val_loss: 3.4315e-04\n",
      "Epoch 598/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3250e-04 - val_loss: 3.4358e-04\n",
      "Epoch 599/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3248e-04 - val_loss: 3.4284e-04\n",
      "Epoch 600/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3230e-04 - val_loss: 3.4359e-04\n",
      "Epoch 601/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3259e-04 - val_loss: 3.4360e-04\n",
      "Epoch 602/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3237e-04 - val_loss: 3.4260e-04\n",
      "Epoch 603/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3263e-04 - val_loss: 3.4286e-04\n",
      "Epoch 604/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3225e-04 - val_loss: 3.4257e-04\n",
      "Epoch 605/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3207e-04 - val_loss: 3.4345e-04\n",
      "Epoch 606/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3202e-04 - val_loss: 3.4325e-04\n",
      "Epoch 607/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3233e-04 - val_loss: 3.4273e-04\n",
      "Epoch 608/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3248e-04 - val_loss: 3.4461e-04\n",
      "Epoch 609/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3237e-04 - val_loss: 3.4258e-04\n",
      "Epoch 610/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3235e-04 - val_loss: 3.4298e-04\n",
      "Epoch 611/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3220e-04 - val_loss: 3.4293e-04\n",
      "Epoch 612/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3224e-04 - val_loss: 3.4317e-04\n",
      "Epoch 613/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3200e-04 - val_loss: 3.4296e-04\n",
      "Epoch 614/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3199e-04 - val_loss: 3.4278e-04\n",
      "Epoch 615/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3208e-04 - val_loss: 3.4396e-04\n",
      "Epoch 616/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3200e-04 - val_loss: 3.4299e-04\n",
      "Epoch 617/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3216e-04 - val_loss: 3.4263e-04\n",
      "Epoch 618/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3211e-04 - val_loss: 3.4300e-04\n",
      "Epoch 619/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3212e-04 - val_loss: 3.4289e-04\n",
      "Epoch 620/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3195e-04 - val_loss: 3.4340e-04\n",
      "Epoch 621/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3189e-04 - val_loss: 3.4306e-04\n",
      "Epoch 622/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3186e-04 - val_loss: 3.4330e-04\n",
      "Epoch 623/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3195e-04 - val_loss: 3.4307e-04\n",
      "Epoch 624/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3200e-04 - val_loss: 3.4258e-04\n",
      "Epoch 625/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3153e-04 - val_loss: 3.4234e-04\n",
      "Epoch 626/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3186e-04 - val_loss: 3.4235e-04\n",
      "Epoch 627/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3188e-04 - val_loss: 3.4226e-04\n",
      "Epoch 628/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3205e-04 - val_loss: 3.4255e-04\n",
      "Epoch 629/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3178e-04 - val_loss: 3.4242e-04\n",
      "Epoch 630/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3152e-04 - val_loss: 3.4305e-04\n",
      "Epoch 631/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3171e-04 - val_loss: 3.4349e-04\n",
      "Epoch 632/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3163e-04 - val_loss: 3.4267e-04\n",
      "Epoch 633/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3158e-04 - val_loss: 3.4267e-04\n",
      "Epoch 634/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3172e-04 - val_loss: 3.4281e-04\n",
      "Epoch 635/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3132e-04 - val_loss: 3.4286e-04\n",
      "Epoch 636/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3158e-04 - val_loss: 3.4286e-04\n",
      "Epoch 637/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3155e-04 - val_loss: 3.4239e-04\n",
      "Epoch 638/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3154e-04 - val_loss: 3.4222e-04\n",
      "Epoch 639/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.3133e-04 - val_loss: 3.4201e-04\n",
      "Epoch 640/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3149e-04 - val_loss: 3.4333e-04\n",
      "Epoch 641/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3158e-04 - val_loss: 3.4255e-04\n",
      "Epoch 642/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3133e-04 - val_loss: 3.4218e-04\n",
      "Epoch 643/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3159e-04 - val_loss: 3.4248e-04\n",
      "Epoch 644/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3142e-04 - val_loss: 3.4273e-04\n",
      "Epoch 645/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3124e-04 - val_loss: 3.4250e-04\n",
      "Epoch 646/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3119e-04 - val_loss: 3.4213e-04\n",
      "Epoch 647/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3133e-04 - val_loss: 3.4216e-04\n",
      "Epoch 648/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3139e-04 - val_loss: 3.4217e-04\n",
      "Epoch 649/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3115e-04 - val_loss: 3.4493e-04\n",
      "Epoch 650/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3089e-04 - val_loss: 3.4248e-04\n",
      "Epoch 651/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3103e-04 - val_loss: 3.4223e-04\n",
      "Epoch 652/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3111e-04 - val_loss: 3.4197e-04\n",
      "Epoch 653/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3114e-04 - val_loss: 3.4234e-04\n",
      "Epoch 654/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3089e-04 - val_loss: 3.4215e-04\n",
      "Epoch 655/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3080e-04 - val_loss: 3.4233e-04\n",
      "Epoch 656/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3093e-04 - val_loss: 3.4208e-04\n",
      "Epoch 657/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3116e-04 - val_loss: 3.4167e-04\n",
      "Epoch 658/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3098e-04 - val_loss: 3.4210e-04\n",
      "Epoch 659/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3125e-04 - val_loss: 3.4200e-04\n",
      "Epoch 660/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3108e-04 - val_loss: 3.4269e-04\n",
      "Epoch 661/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3085e-04 - val_loss: 3.4244e-04\n",
      "Epoch 662/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3084e-04 - val_loss: 3.4164e-04\n",
      "Epoch 663/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3100e-04 - val_loss: 3.4186e-04\n",
      "Epoch 664/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3052e-04 - val_loss: 3.4214e-04\n",
      "Epoch 665/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3067e-04 - val_loss: 3.4235e-04\n",
      "Epoch 666/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3074e-04 - val_loss: 3.4158e-04\n",
      "Epoch 667/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3071e-04 - val_loss: 3.4421e-04\n",
      "Epoch 668/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3088e-04 - val_loss: 3.4217e-04\n",
      "Epoch 669/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3047e-04 - val_loss: 3.4147e-04\n",
      "Epoch 670/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3084e-04 - val_loss: 3.4160e-04\n",
      "Epoch 671/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3063e-04 - val_loss: 3.4204e-04\n",
      "Epoch 672/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3079e-04 - val_loss: 3.4152e-04\n",
      "Epoch 673/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3040e-04 - val_loss: 3.4247e-04\n",
      "Epoch 674/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3078e-04 - val_loss: 3.4246e-04\n",
      "Epoch 675/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3027e-04 - val_loss: 3.4257e-04\n",
      "Epoch 676/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3039e-04 - val_loss: 3.4176e-04\n",
      "Epoch 677/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3074e-04 - val_loss: 3.4147e-04\n",
      "Epoch 678/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3050e-04 - val_loss: 3.4137e-04\n",
      "Epoch 679/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3046e-04 - val_loss: 3.4113e-04\n",
      "Epoch 680/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3029e-04 - val_loss: 3.4159e-04\n",
      "Epoch 681/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3041e-04 - val_loss: 3.4106e-04\n",
      "Epoch 682/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3042e-04 - val_loss: 3.4112e-04\n",
      "Epoch 683/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3037e-04 - val_loss: 3.4185e-04\n",
      "Epoch 684/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3022e-04 - val_loss: 3.4213e-04\n",
      "Epoch 685/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3034e-04 - val_loss: 3.4105e-04\n",
      "Epoch 686/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3000e-04 - val_loss: 3.4181e-04\n",
      "Epoch 687/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3012e-04 - val_loss: 3.4233e-04\n",
      "Epoch 688/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2990e-04 - val_loss: 3.4116e-04\n",
      "Epoch 689/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3013e-04 - val_loss: 3.4243e-04\n",
      "Epoch 690/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3029e-04 - val_loss: 3.4114e-04\n",
      "Epoch 691/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3018e-04 - val_loss: 3.4201e-04\n",
      "Epoch 692/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3016e-04 - val_loss: 3.4204e-04\n",
      "Epoch 693/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2988e-04 - val_loss: 3.4125e-04\n",
      "Epoch 694/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3011e-04 - val_loss: 3.4120e-04\n",
      "Epoch 695/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3001e-04 - val_loss: 3.4099e-04\n",
      "Epoch 696/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2996e-04 - val_loss: 3.4154e-04\n",
      "Epoch 697/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3002e-04 - val_loss: 3.4115e-04\n",
      "Epoch 698/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2988e-04 - val_loss: 3.4170e-04\n",
      "Epoch 699/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.3014e-04 - val_loss: 3.4122e-04\n",
      "Epoch 700/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2994e-04 - val_loss: 3.4100e-04\n",
      "Epoch 701/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2984e-04 - val_loss: 3.4028e-04\n",
      "Epoch 702/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2976e-04 - val_loss: 3.4070e-04\n",
      "Epoch 703/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2986e-04 - val_loss: 3.4104e-04\n",
      "Epoch 704/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2975e-04 - val_loss: 3.4084e-04\n",
      "Epoch 705/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2979e-04 - val_loss: 3.4098e-04\n",
      "Epoch 706/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2993e-04 - val_loss: 3.4226e-04\n",
      "Epoch 707/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2957e-04 - val_loss: 3.4082e-04\n",
      "Epoch 708/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2955e-04 - val_loss: 3.4087e-04\n",
      "Epoch 709/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2971e-04 - val_loss: 3.4122e-04\n",
      "Epoch 710/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2980e-04 - val_loss: 3.4216e-04\n",
      "Epoch 711/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2958e-04 - val_loss: 3.4066e-04\n",
      "Epoch 712/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2952e-04 - val_loss: 3.4033e-04\n",
      "Epoch 713/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2966e-04 - val_loss: 3.4076e-04\n",
      "Epoch 714/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2952e-04 - val_loss: 3.4041e-04\n",
      "Epoch 715/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2970e-04 - val_loss: 3.4238e-04\n",
      "Epoch 716/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2929e-04 - val_loss: 3.4213e-04\n",
      "Epoch 717/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2920e-04 - val_loss: 3.4120e-04\n",
      "Epoch 718/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2929e-04 - val_loss: 3.4066e-04\n",
      "Epoch 719/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2926e-04 - val_loss: 3.4057e-04\n",
      "Epoch 720/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2932e-04 - val_loss: 3.4205e-04\n",
      "Epoch 721/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2920e-04 - val_loss: 3.4089e-04\n",
      "Epoch 722/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2923e-04 - val_loss: 3.4069e-04\n",
      "Epoch 723/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2927e-04 - val_loss: 3.4165e-04\n",
      "Epoch 724/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2901e-04 - val_loss: 3.4092e-04\n",
      "Epoch 725/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2922e-04 - val_loss: 3.4092e-04\n",
      "Epoch 726/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2924e-04 - val_loss: 3.4043e-04\n",
      "Epoch 727/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2911e-04 - val_loss: 3.4049e-04\n",
      "Epoch 728/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2929e-04 - val_loss: 3.4099e-04\n",
      "Epoch 729/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2915e-04 - val_loss: 3.4370e-04\n",
      "Epoch 730/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2917e-04 - val_loss: 3.4045e-04\n",
      "Epoch 731/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2888e-04 - val_loss: 3.4039e-04\n",
      "Epoch 732/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2919e-04 - val_loss: 3.4093e-04\n",
      "Epoch 733/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2941e-04 - val_loss: 3.3997e-04\n",
      "Epoch 734/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2906e-04 - val_loss: 3.4061e-04\n",
      "Epoch 735/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2897e-04 - val_loss: 3.4096e-04\n",
      "Epoch 736/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2890e-04 - val_loss: 3.4005e-04\n",
      "Epoch 737/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2880e-04 - val_loss: 3.4010e-04\n",
      "Epoch 738/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2896e-04 - val_loss: 3.4023e-04\n",
      "Epoch 739/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2884e-04 - val_loss: 3.4124e-04\n",
      "Epoch 740/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2893e-04 - val_loss: 3.4035e-04\n",
      "Epoch 741/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2895e-04 - val_loss: 3.4087e-04\n",
      "Epoch 742/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2872e-04 - val_loss: 3.4012e-04\n",
      "Epoch 743/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2892e-04 - val_loss: 3.4048e-04\n",
      "Epoch 744/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2855e-04 - val_loss: 3.4178e-04\n",
      "Epoch 745/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2882e-04 - val_loss: 3.4027e-04\n",
      "Epoch 746/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2885e-04 - val_loss: 3.4007e-04\n",
      "Epoch 747/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2883e-04 - val_loss: 3.4004e-04\n",
      "Epoch 748/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2876e-04 - val_loss: 3.4059e-04\n",
      "Epoch 749/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2859e-04 - val_loss: 3.4032e-04\n",
      "Epoch 750/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2861e-04 - val_loss: 3.4021e-04\n",
      "Epoch 751/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2852e-04 - val_loss: 3.3978e-04\n",
      "Epoch 752/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2859e-04 - val_loss: 3.4032e-04\n",
      "Epoch 753/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2844e-04 - val_loss: 3.4056e-04\n",
      "Epoch 754/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2853e-04 - val_loss: 3.3949e-04\n",
      "Epoch 755/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2846e-04 - val_loss: 3.4000e-04\n",
      "Epoch 756/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2857e-04 - val_loss: 3.3964e-04\n",
      "Epoch 757/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2849e-04 - val_loss: 3.4192e-04\n",
      "Epoch 758/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2828e-04 - val_loss: 3.3944e-04\n",
      "Epoch 759/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2832e-04 - val_loss: 3.3991e-04\n",
      "Epoch 760/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2835e-04 - val_loss: 3.3957e-04\n",
      "Epoch 761/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2829e-04 - val_loss: 3.4019e-04\n",
      "Epoch 762/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2842e-04 - val_loss: 3.3981e-04\n",
      "Epoch 763/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2827e-04 - val_loss: 3.4021e-04\n",
      "Epoch 764/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2836e-04 - val_loss: 3.3946e-04\n",
      "Epoch 765/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2789e-04 - val_loss: 3.4157e-04\n",
      "Epoch 766/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2831e-04 - val_loss: 3.4053e-04\n",
      "Epoch 767/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2821e-04 - val_loss: 3.3947e-04\n",
      "Epoch 768/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2781e-04 - val_loss: 3.3905e-04\n",
      "Epoch 769/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2814e-04 - val_loss: 3.3943e-04\n",
      "Epoch 770/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2826e-04 - val_loss: 3.3914e-04\n",
      "Epoch 771/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2816e-04 - val_loss: 3.3956e-04\n",
      "Epoch 772/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2787e-04 - val_loss: 3.3966e-04\n",
      "Epoch 773/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2789e-04 - val_loss: 3.3949e-04\n",
      "Epoch 774/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2796e-04 - val_loss: 3.4069e-04\n",
      "Epoch 775/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2797e-04 - val_loss: 3.4058e-04\n",
      "Epoch 776/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2803e-04 - val_loss: 3.4063e-04\n",
      "Epoch 777/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2798e-04 - val_loss: 3.4020e-04\n",
      "Epoch 778/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2786e-04 - val_loss: 3.3912e-04\n",
      "Epoch 779/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2786e-04 - val_loss: 3.4032e-04\n",
      "Epoch 780/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2763e-04 - val_loss: 3.4086e-04\n",
      "Epoch 781/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2799e-04 - val_loss: 3.3920e-04\n",
      "Epoch 782/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2754e-04 - val_loss: 3.3981e-04\n",
      "Epoch 783/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2791e-04 - val_loss: 3.4003e-04\n",
      "Epoch 784/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2755e-04 - val_loss: 3.3984e-04\n",
      "Epoch 785/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2803e-04 - val_loss: 3.3932e-04\n",
      "Epoch 786/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2795e-04 - val_loss: 3.3997e-04\n",
      "Epoch 787/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2771e-04 - val_loss: 3.3960e-04\n",
      "Epoch 788/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2752e-04 - val_loss: 3.3923e-04\n",
      "Epoch 789/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2778e-04 - val_loss: 3.3931e-04\n",
      "Epoch 790/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2737e-04 - val_loss: 3.3964e-04\n",
      "Epoch 791/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2762e-04 - val_loss: 3.3937e-04\n",
      "Epoch 792/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2728e-04 - val_loss: 3.3927e-04\n",
      "Epoch 793/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2752e-04 - val_loss: 3.3885e-04\n",
      "Epoch 794/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2749e-04 - val_loss: 3.3877e-04\n",
      "Epoch 795/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2716e-04 - val_loss: 3.3977e-04\n",
      "Epoch 796/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2753e-04 - val_loss: 3.3934e-04\n",
      "Epoch 797/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2726e-04 - val_loss: 3.3876e-04\n",
      "Epoch 798/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2724e-04 - val_loss: 3.3836e-04\n",
      "Epoch 799/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2763e-04 - val_loss: 3.3894e-04\n",
      "Epoch 800/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2735e-04 - val_loss: 3.3887e-04\n",
      "Epoch 801/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2715e-04 - val_loss: 3.3977e-04\n",
      "Epoch 802/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2701e-04 - val_loss: 3.3932e-04\n",
      "Epoch 803/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2705e-04 - val_loss: 3.4066e-04\n",
      "Epoch 804/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2728e-04 - val_loss: 3.3862e-04\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2735e-04 - val_loss: 3.3841e-04\n",
      "Epoch 806/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2707e-04 - val_loss: 3.3901e-04\n",
      "Epoch 807/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2691e-04 - val_loss: 3.3940e-04\n",
      "Epoch 808/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2733e-04 - val_loss: 3.3833e-04\n",
      "Epoch 809/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2697e-04 - val_loss: 3.3875e-04\n",
      "Epoch 810/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2707e-04 - val_loss: 3.3964e-04\n",
      "Epoch 811/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2720e-04 - val_loss: 3.3849e-04\n",
      "Epoch 812/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2695e-04 - val_loss: 3.3893e-04\n",
      "Epoch 813/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2681e-04 - val_loss: 3.3879e-04\n",
      "Epoch 814/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2682e-04 - val_loss: 3.3837e-04\n",
      "Epoch 815/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2676e-04 - val_loss: 3.3851e-04\n",
      "Epoch 816/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2689e-04 - val_loss: 3.3840e-04\n",
      "Epoch 817/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2672e-04 - val_loss: 3.3856e-04\n",
      "Epoch 818/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2672e-04 - val_loss: 3.3881e-04\n",
      "Epoch 819/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2665e-04 - val_loss: 3.3853e-04\n",
      "Epoch 820/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2667e-04 - val_loss: 3.3890e-04\n",
      "Epoch 821/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2670e-04 - val_loss: 3.3897e-04\n",
      "Epoch 822/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2655e-04 - val_loss: 3.3892e-04\n",
      "Epoch 823/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2683e-04 - val_loss: 3.3877e-04\n",
      "Epoch 824/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2651e-04 - val_loss: 3.3885e-04\n",
      "Epoch 825/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2672e-04 - val_loss: 3.3882e-04\n",
      "Epoch 826/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2656e-04 - val_loss: 3.3802e-04\n",
      "Epoch 827/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2645e-04 - val_loss: 3.3850e-04\n",
      "Epoch 828/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2689e-04 - val_loss: 3.3944e-04\n",
      "Epoch 829/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2620e-04 - val_loss: 3.3919e-04\n",
      "Epoch 830/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2664e-04 - val_loss: 3.3793e-04\n",
      "Epoch 831/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2635e-04 - val_loss: 3.3822e-04\n",
      "Epoch 832/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2674e-04 - val_loss: 3.4037e-04\n",
      "Epoch 833/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2656e-04 - val_loss: 3.3956e-04\n",
      "Epoch 834/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2617e-04 - val_loss: 3.3788e-04\n",
      "Epoch 835/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2648e-04 - val_loss: 3.3756e-04\n",
      "Epoch 836/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2636e-04 - val_loss: 3.3825e-04\n",
      "Epoch 837/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2656e-04 - val_loss: 3.3820e-04\n",
      "Epoch 838/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2646e-04 - val_loss: 3.3805e-04\n",
      "Epoch 839/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2626e-04 - val_loss: 3.3806e-04\n",
      "Epoch 840/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2619e-04 - val_loss: 3.3786e-04\n",
      "Epoch 841/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2616e-04 - val_loss: 3.3865e-04\n",
      "Epoch 842/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2611e-04 - val_loss: 3.3767e-04\n",
      "Epoch 843/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2615e-04 - val_loss: 3.3826e-04\n",
      "Epoch 844/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2612e-04 - val_loss: 3.3772e-04\n",
      "Epoch 845/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2628e-04 - val_loss: 3.3768e-04\n",
      "Epoch 846/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2586e-04 - val_loss: 3.3769e-04\n",
      "Epoch 847/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2586e-04 - val_loss: 3.3914e-04\n",
      "Epoch 848/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2638e-04 - val_loss: 3.3788e-04\n",
      "Epoch 849/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2587e-04 - val_loss: 3.3786e-04\n",
      "Epoch 850/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2571e-04 - val_loss: 3.3751e-04\n",
      "Epoch 851/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2589e-04 - val_loss: 3.3805e-04\n",
      "Epoch 852/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2582e-04 - val_loss: 3.3852e-04\n",
      "Epoch 853/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2592e-04 - val_loss: 3.3765e-04\n",
      "Epoch 854/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2591e-04 - val_loss: 3.3828e-04\n",
      "Epoch 855/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2575e-04 - val_loss: 3.3818e-04\n",
      "Epoch 856/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2593e-04 - val_loss: 3.3819e-04\n",
      "Epoch 857/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2589e-04 - val_loss: 3.3788e-04\n",
      "Epoch 858/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2578e-04 - val_loss: 3.3801e-04\n",
      "Epoch 859/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2571e-04 - val_loss: 3.3752e-04\n",
      "Epoch 860/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2562e-04 - val_loss: 3.3759e-04\n",
      "Epoch 861/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2551e-04 - val_loss: 3.3781e-04\n",
      "Epoch 862/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2569e-04 - val_loss: 3.3810e-04\n",
      "Epoch 863/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2569e-04 - val_loss: 3.3740e-04\n",
      "Epoch 864/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2575e-04 - val_loss: 3.3782e-04\n",
      "Epoch 865/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2548e-04 - val_loss: 3.3871e-04\n",
      "Epoch 866/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2575e-04 - val_loss: 3.3731e-04\n",
      "Epoch 867/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2548e-04 - val_loss: 3.3753e-04\n",
      "Epoch 868/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2549e-04 - val_loss: 3.3767e-04\n",
      "Epoch 869/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2552e-04 - val_loss: 3.3702e-04\n",
      "Epoch 870/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2520e-04 - val_loss: 3.3734e-04\n",
      "Epoch 871/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2541e-04 - val_loss: 3.3823e-04\n",
      "Epoch 872/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2544e-04 - val_loss: 3.3775e-04\n",
      "Epoch 873/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2537e-04 - val_loss: 3.3793e-04\n",
      "Epoch 874/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2527e-04 - val_loss: 3.3771e-04\n",
      "Epoch 875/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2518e-04 - val_loss: 3.3747e-04\n",
      "Epoch 876/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2514e-04 - val_loss: 3.3679e-04\n",
      "Epoch 877/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2542e-04 - val_loss: 3.3850e-04\n",
      "Epoch 878/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2527e-04 - val_loss: 3.3746e-04\n",
      "Epoch 879/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2536e-04 - val_loss: 3.3797e-04\n",
      "Epoch 880/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2505e-04 - val_loss: 3.3759e-04\n",
      "Epoch 881/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2502e-04 - val_loss: 3.4032e-04\n",
      "Epoch 882/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2551e-04 - val_loss: 3.3700e-04\n",
      "Epoch 883/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2493e-04 - val_loss: 3.3725e-04\n",
      "Epoch 884/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2508e-04 - val_loss: 3.3708e-04\n",
      "Epoch 885/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2500e-04 - val_loss: 3.3725e-04\n",
      "Epoch 886/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2491e-04 - val_loss: 3.3772e-04\n",
      "Epoch 887/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2525e-04 - val_loss: 3.3772e-04\n",
      "Epoch 888/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2491e-04 - val_loss: 3.3682e-04\n",
      "Epoch 889/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2469e-04 - val_loss: 3.3674e-04\n",
      "Epoch 890/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2486e-04 - val_loss: 3.3711e-04\n",
      "Epoch 891/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2502e-04 - val_loss: 3.3699e-04\n",
      "Epoch 892/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2479e-04 - val_loss: 3.3822e-04\n",
      "Epoch 893/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2495e-04 - val_loss: 3.3721e-04\n",
      "Epoch 894/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2465e-04 - val_loss: 3.3724e-04\n",
      "Epoch 895/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2465e-04 - val_loss: 3.3832e-04\n",
      "Epoch 896/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2466e-04 - val_loss: 3.3666e-04\n",
      "Epoch 897/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2494e-04 - val_loss: 3.3646e-04\n",
      "Epoch 898/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2484e-04 - val_loss: 3.3749e-04\n",
      "Epoch 899/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2479e-04 - val_loss: 3.3682e-04\n",
      "Epoch 900/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2434e-04 - val_loss: 3.3632e-04\n",
      "Epoch 901/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2447e-04 - val_loss: 3.3701e-04\n",
      "Epoch 902/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2464e-04 - val_loss: 3.3666e-04\n",
      "Epoch 903/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2455e-04 - val_loss: 3.3766e-04\n",
      "Epoch 904/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2489e-04 - val_loss: 3.3829e-04\n",
      "Epoch 905/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2449e-04 - val_loss: 3.3688e-04\n",
      "Epoch 906/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2439e-04 - val_loss: 3.3703e-04\n",
      "Epoch 907/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2466e-04 - val_loss: 3.3713e-04\n",
      "Epoch 908/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2453e-04 - val_loss: 3.3618e-04\n",
      "Epoch 909/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2419e-04 - val_loss: 3.3852e-04\n",
      "Epoch 910/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2463e-04 - val_loss: 3.3690e-04\n",
      "Epoch 911/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2434e-04 - val_loss: 3.3634e-04\n",
      "Epoch 912/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2425e-04 - val_loss: 3.3620e-04\n",
      "Epoch 913/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2408e-04 - val_loss: 3.3693e-04\n",
      "Epoch 914/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2428e-04 - val_loss: 3.3643e-04\n",
      "Epoch 915/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2471e-04 - val_loss: 3.3651e-04\n",
      "Epoch 916/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2427e-04 - val_loss: 3.3764e-04\n",
      "Epoch 917/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2423e-04 - val_loss: 3.3649e-04\n",
      "Epoch 918/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2392e-04 - val_loss: 3.3663e-04\n",
      "Epoch 919/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2402e-04 - val_loss: 3.3708e-04\n",
      "Epoch 920/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2403e-04 - val_loss: 3.3613e-04\n",
      "Epoch 921/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2412e-04 - val_loss: 3.3599e-04\n",
      "Epoch 922/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2389e-04 - val_loss: 3.3666e-04\n",
      "Epoch 923/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2381e-04 - val_loss: 3.3696e-04\n",
      "Epoch 924/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2393e-04 - val_loss: 3.3603e-04\n",
      "Epoch 925/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2391e-04 - val_loss: 3.3647e-04\n",
      "Epoch 926/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2400e-04 - val_loss: 3.3632e-04\n",
      "Epoch 927/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2383e-04 - val_loss: 3.3650e-04\n",
      "Epoch 928/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2393e-04 - val_loss: 3.3662e-04\n",
      "Epoch 929/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2402e-04 - val_loss: 3.3635e-04\n",
      "Epoch 930/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2373e-04 - val_loss: 3.3670e-04\n",
      "Epoch 931/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2377e-04 - val_loss: 3.3681e-04\n",
      "Epoch 932/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2369e-04 - val_loss: 3.3723e-04\n",
      "Epoch 933/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2375e-04 - val_loss: 3.3662e-04\n",
      "Epoch 934/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2393e-04 - val_loss: 3.3689e-04\n",
      "Epoch 935/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2380e-04 - val_loss: 3.3688e-04\n",
      "Epoch 936/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2354e-04 - val_loss: 3.3600e-04\n",
      "Epoch 937/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2369e-04 - val_loss: 3.3623e-04\n",
      "Epoch 938/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2349e-04 - val_loss: 3.3603e-04\n",
      "Epoch 939/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2351e-04 - val_loss: 3.3598e-04\n",
      "Epoch 940/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2339e-04 - val_loss: 3.3573e-04\n",
      "Epoch 941/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2340e-04 - val_loss: 3.3593e-04\n",
      "Epoch 942/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2322e-04 - val_loss: 3.3581e-04\n",
      "Epoch 943/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2368e-04 - val_loss: 3.3630e-04\n",
      "Epoch 944/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2354e-04 - val_loss: 3.3668e-04\n",
      "Epoch 945/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2348e-04 - val_loss: 3.3583e-04\n",
      "Epoch 946/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2364e-04 - val_loss: 3.3751e-04\n",
      "Epoch 947/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2323e-04 - val_loss: 3.3626e-04\n",
      "Epoch 948/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2348e-04 - val_loss: 3.3556e-04\n",
      "Epoch 949/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2335e-04 - val_loss: 3.3631e-04\n",
      "Epoch 950/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2317e-04 - val_loss: 3.3503e-04\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2317e-04 - val_loss: 3.3642e-04\n",
      "Epoch 952/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2338e-04 - val_loss: 3.3548e-04\n",
      "Epoch 953/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2307e-04 - val_loss: 3.3602e-04\n",
      "Epoch 954/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2305e-04 - val_loss: 3.3554e-04\n",
      "Epoch 955/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2327e-04 - val_loss: 3.3541e-04\n",
      "Epoch 956/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2324e-04 - val_loss: 3.3523e-04\n",
      "Epoch 957/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 3.2310e-04 - val_loss: 3.3579e-04\n",
      "Epoch 958/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2316e-04 - val_loss: 3.3620e-04\n",
      "Epoch 959/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2292e-04 - val_loss: 3.3565e-04\n",
      "Epoch 960/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2287e-04 - val_loss: 3.3558e-04\n",
      "Epoch 961/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2309e-04 - val_loss: 3.3641e-04\n",
      "Epoch 962/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2296e-04 - val_loss: 3.3582e-04\n",
      "Epoch 963/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2313e-04 - val_loss: 3.3587e-04\n",
      "Epoch 964/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2292e-04 - val_loss: 3.3752e-04\n",
      "Epoch 965/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2283e-04 - val_loss: 3.3585e-04\n",
      "Epoch 966/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2307e-04 - val_loss: 3.3601e-04\n",
      "Epoch 967/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2274e-04 - val_loss: 3.3571e-04\n",
      "Epoch 968/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2262e-04 - val_loss: 3.3538e-04\n",
      "Epoch 969/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2281e-04 - val_loss: 3.3742e-04\n",
      "Epoch 970/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2270e-04 - val_loss: 3.3552e-04\n",
      "Epoch 971/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2304e-04 - val_loss: 3.3553e-04\n",
      "Epoch 972/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2288e-04 - val_loss: 3.3534e-04\n",
      "Epoch 973/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2312e-04 - val_loss: 3.3454e-04\n",
      "Epoch 974/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2237e-04 - val_loss: 3.3574e-04\n",
      "Epoch 975/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2256e-04 - val_loss: 3.3539e-04\n",
      "Epoch 976/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2275e-04 - val_loss: 3.3517e-04\n",
      "Epoch 977/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2278e-04 - val_loss: 3.3513e-04\n",
      "Epoch 978/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2232e-04 - val_loss: 3.3531e-04\n",
      "Epoch 979/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2276e-04 - val_loss: 3.3562e-04\n",
      "Epoch 980/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2257e-04 - val_loss: 3.3572e-04\n",
      "Epoch 981/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2276e-04 - val_loss: 3.3545e-04\n",
      "Epoch 982/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2255e-04 - val_loss: 3.3521e-04\n",
      "Epoch 983/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2235e-04 - val_loss: 3.3471e-04\n",
      "Epoch 984/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2233e-04 - val_loss: 3.3498e-04\n",
      "Epoch 985/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2232e-04 - val_loss: 3.3481e-04\n",
      "Epoch 986/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2224e-04 - val_loss: 3.3517e-04\n",
      "Epoch 987/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2237e-04 - val_loss: 3.3496e-04\n",
      "Epoch 988/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2219e-04 - val_loss: 3.3525e-04\n",
      "Epoch 989/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2227e-04 - val_loss: 3.3468e-04\n",
      "Epoch 990/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2237e-04 - val_loss: 3.3525e-04\n",
      "Epoch 991/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2238e-04 - val_loss: 3.3470e-04\n",
      "Epoch 992/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2209e-04 - val_loss: 3.3518e-04\n",
      "Epoch 993/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2224e-04 - val_loss: 3.3624e-04\n",
      "Epoch 994/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2236e-04 - val_loss: 3.3544e-04\n",
      "Epoch 995/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2205e-04 - val_loss: 3.3427e-04\n",
      "Epoch 996/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2241e-04 - val_loss: 3.3522e-04\n",
      "Epoch 997/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2188e-04 - val_loss: 3.3499e-04\n",
      "Epoch 998/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2198e-04 - val_loss: 3.3501e-04\n",
      "Epoch 999/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 3.2179e-04 - val_loss: 3.3522e-04\n",
      "Epoch 1000/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2211e-04 - val_loss: 3.3568e-04\n",
      "INFO:tensorflow:Assets written to: AET_CF_Trial_14/models/saved_model_14_LSP_AET_CF_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: AET_CF_Trial_14/models/saved_model_14_LSP_AET_CF_1/assets\n",
      "  4%|█▎                                     | 2/57 [45:11<20:43:24, 1356.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 3.2202e-04 - val_loss: 3.3498e-04\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 3.2204e-04 - val_loss: 3.3521e-04\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2175e-04 - val_loss: 3.3482e-04\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2175e-04 - val_loss: 3.3438e-04\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2173e-04 - val_loss: 3.3453e-04\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2201e-04 - val_loss: 3.3409e-04\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2161e-04 - val_loss: 3.3472e-04\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2205e-04 - val_loss: 3.3461e-04\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2159e-04 - val_loss: 3.3557e-04\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2193e-04 - val_loss: 3.3432e-04\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2135e-04 - val_loss: 3.3472e-04\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2158e-04 - val_loss: 3.3495e-04\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2168e-04 - val_loss: 3.3477e-04\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2182e-04 - val_loss: 3.3470e-04\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2139e-04 - val_loss: 3.3433e-04\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2155e-04 - val_loss: 3.3565e-04\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2144e-04 - val_loss: 3.3515e-04\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2146e-04 - val_loss: 3.3457e-04\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2130e-04 - val_loss: 3.3394e-04\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2160e-04 - val_loss: 3.3658e-04\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2141e-04 - val_loss: 3.3495e-04\n",
      "Epoch 22/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2198e-04 - val_loss: 3.3384e-04\n",
      "Epoch 23/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2140e-04 - val_loss: 3.3438e-04\n",
      "Epoch 24/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2136e-04 - val_loss: 3.3448e-04\n",
      "Epoch 25/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2141e-04 - val_loss: 3.3401e-04\n",
      "Epoch 26/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2149e-04 - val_loss: 3.3492e-04\n",
      "Epoch 27/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2128e-04 - val_loss: 3.3376e-04\n",
      "Epoch 28/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2123e-04 - val_loss: 3.3416e-04\n",
      "Epoch 29/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2128e-04 - val_loss: 3.3384e-04\n",
      "Epoch 30/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2125e-04 - val_loss: 3.3451e-04\n",
      "Epoch 31/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2120e-04 - val_loss: 3.3405e-04\n",
      "Epoch 32/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2153e-04 - val_loss: 3.3401e-04\n",
      "Epoch 33/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2100e-04 - val_loss: 3.3426e-04\n",
      "Epoch 34/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2102e-04 - val_loss: 3.3362e-04\n",
      "Epoch 35/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2097e-04 - val_loss: 3.3353e-04\n",
      "Epoch 36/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2112e-04 - val_loss: 3.3437e-04\n",
      "Epoch 37/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2106e-04 - val_loss: 3.3384e-04\n",
      "Epoch 38/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2081e-04 - val_loss: 3.3411e-04\n",
      "Epoch 39/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2103e-04 - val_loss: 3.3484e-04\n",
      "Epoch 40/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2069e-04 - val_loss: 3.3446e-04\n",
      "Epoch 41/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2105e-04 - val_loss: 3.3412e-04\n",
      "Epoch 42/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2068e-04 - val_loss: 3.3479e-04\n",
      "Epoch 43/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2110e-04 - val_loss: 3.3517e-04\n",
      "Epoch 44/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2107e-04 - val_loss: 3.3517e-04\n",
      "Epoch 45/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2104e-04 - val_loss: 3.3415e-04\n",
      "Epoch 46/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2068e-04 - val_loss: 3.3412e-04\n",
      "Epoch 47/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2093e-04 - val_loss: 3.3369e-04\n",
      "Epoch 48/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2077e-04 - val_loss: 3.3391e-04\n",
      "Epoch 49/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2083e-04 - val_loss: 3.3370e-04\n",
      "Epoch 50/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2079e-04 - val_loss: 3.3357e-04\n",
      "Epoch 51/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2074e-04 - val_loss: 3.3417e-04\n",
      "Epoch 52/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.2061e-04 - val_loss: 3.3363e-04\n",
      "Epoch 53/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2065e-04 - val_loss: 3.3394e-04\n",
      "Epoch 54/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2115e-04 - val_loss: 3.3351e-04\n",
      "Epoch 55/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2057e-04 - val_loss: 3.3349e-04\n",
      "Epoch 56/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2041e-04 - val_loss: 3.3335e-04\n",
      "Epoch 57/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2028e-04 - val_loss: 3.3328e-04\n",
      "Epoch 58/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2053e-04 - val_loss: 3.3338e-04\n",
      "Epoch 59/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2088e-04 - val_loss: 3.3355e-04\n",
      "Epoch 60/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2030e-04 - val_loss: 3.3478e-04\n",
      "Epoch 61/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2061e-04 - val_loss: 3.3424e-04\n",
      "Epoch 62/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2095e-04 - val_loss: 3.3398e-04\n",
      "Epoch 63/1000\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 3.2042e-04 - val_loss: 3.3375e-04\n",
      "Epoch 64/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.2050e-04 - val_loss: 3.3387e-04\n",
      "Epoch 65/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2058e-04 - val_loss: 3.3342e-04\n",
      "Epoch 66/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2012e-04 - val_loss: 3.3316e-04\n",
      "Epoch 67/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2007e-04 - val_loss: 3.3350e-04\n",
      "Epoch 68/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2045e-04 - val_loss: 3.3566e-04\n",
      "Epoch 69/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.2030e-04 - val_loss: 3.3307e-04\n",
      "Epoch 70/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2111e-04 - val_loss: 3.3698e-04\n",
      "Epoch 71/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2049e-04 - val_loss: 3.3334e-04\n",
      "Epoch 72/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2011e-04 - val_loss: 3.3322e-04\n",
      "Epoch 73/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2013e-04 - val_loss: 3.3318e-04\n",
      "Epoch 74/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2006e-04 - val_loss: 3.3363e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.2018e-04 - val_loss: 3.3360e-04\n",
      "Epoch 76/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2027e-04 - val_loss: 3.3317e-04\n",
      "Epoch 77/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1993e-04 - val_loss: 3.3329e-04\n",
      "Epoch 78/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1998e-04 - val_loss: 3.3338e-04\n",
      "Epoch 79/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1998e-04 - val_loss: 3.3437e-04\n",
      "Epoch 80/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1977e-04 - val_loss: 3.3293e-04\n",
      "Epoch 81/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1988e-04 - val_loss: 3.3347e-04\n",
      "Epoch 82/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2024e-04 - val_loss: 3.3372e-04\n",
      "Epoch 83/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.2001e-04 - val_loss: 3.3305e-04\n",
      "Epoch 84/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1989e-04 - val_loss: 3.3433e-04\n",
      "Epoch 85/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1970e-04 - val_loss: 3.3355e-04\n",
      "Epoch 86/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1976e-04 - val_loss: 3.3388e-04\n",
      "Epoch 87/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1993e-04 - val_loss: 3.3295e-04\n",
      "Epoch 88/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1985e-04 - val_loss: 3.3395e-04\n",
      "Epoch 89/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1961e-04 - val_loss: 3.3272e-04\n",
      "Epoch 90/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1990e-04 - val_loss: 3.3330e-04\n",
      "Epoch 91/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1975e-04 - val_loss: 3.3304e-04\n",
      "Epoch 92/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1982e-04 - val_loss: 3.3278e-04\n",
      "Epoch 93/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1939e-04 - val_loss: 3.3289e-04\n",
      "Epoch 94/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1964e-04 - val_loss: 3.3290e-04\n",
      "Epoch 95/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1970e-04 - val_loss: 3.3274e-04\n",
      "Epoch 96/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1993e-04 - val_loss: 3.3303e-04\n",
      "Epoch 97/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1944e-04 - val_loss: 3.3280e-04\n",
      "Epoch 98/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1954e-04 - val_loss: 3.3351e-04\n",
      "Epoch 99/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1951e-04 - val_loss: 3.3361e-04\n",
      "Epoch 100/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1950e-04 - val_loss: 3.3298e-04\n",
      "Epoch 101/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1970e-04 - val_loss: 3.3412e-04\n",
      "Epoch 102/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1955e-04 - val_loss: 3.3230e-04\n",
      "Epoch 103/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1930e-04 - val_loss: 3.3272e-04\n",
      "Epoch 104/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1930e-04 - val_loss: 3.3240e-04\n",
      "Epoch 105/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1918e-04 - val_loss: 3.3341e-04\n",
      "Epoch 106/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1938e-04 - val_loss: 3.3225e-04\n",
      "Epoch 107/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1945e-04 - val_loss: 3.3300e-04\n",
      "Epoch 108/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1928e-04 - val_loss: 3.3243e-04\n",
      "Epoch 109/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1993e-04 - val_loss: 3.3254e-04\n",
      "Epoch 110/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1929e-04 - val_loss: 3.3281e-04\n",
      "Epoch 111/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1904e-04 - val_loss: 3.3231e-04\n",
      "Epoch 112/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1912e-04 - val_loss: 3.3272e-04\n",
      "Epoch 113/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1956e-04 - val_loss: 3.3220e-04\n",
      "Epoch 114/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1903e-04 - val_loss: 3.3332e-04\n",
      "Epoch 115/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1918e-04 - val_loss: 3.3262e-04\n",
      "Epoch 116/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1945e-04 - val_loss: 3.3291e-04\n",
      "Epoch 117/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1906e-04 - val_loss: 3.3260e-04\n",
      "Epoch 118/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1906e-04 - val_loss: 3.3232e-04\n",
      "Epoch 119/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1910e-04 - val_loss: 3.3225e-04\n",
      "Epoch 120/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1909e-04 - val_loss: 3.3288e-04\n",
      "Epoch 121/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1905e-04 - val_loss: 3.3230e-04\n",
      "Epoch 122/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1905e-04 - val_loss: 3.3253e-04\n",
      "Epoch 123/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1891e-04 - val_loss: 3.3238e-04\n",
      "Epoch 124/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1888e-04 - val_loss: 3.3258e-04\n",
      "Epoch 125/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 3.1913e-04 - val_loss: 3.3174e-04\n",
      "Epoch 126/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 3.1878e-04 - val_loss: 3.3267e-04\n",
      "Epoch 127/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1915e-04 - val_loss: 3.3245e-04\n",
      "Epoch 128/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1900e-04 - val_loss: 3.3187e-04\n",
      "Epoch 129/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1889e-04 - val_loss: 3.3434e-04\n",
      "Epoch 130/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1884e-04 - val_loss: 3.3208e-04\n",
      "Epoch 131/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1886e-04 - val_loss: 3.3323e-04\n",
      "Epoch 132/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1862e-04 - val_loss: 3.3184e-04\n",
      "Epoch 133/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1853e-04 - val_loss: 3.3238e-04\n",
      "Epoch 134/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1892e-04 - val_loss: 3.3256e-04\n",
      "Epoch 135/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1850e-04 - val_loss: 3.3209e-04\n",
      "Epoch 136/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1842e-04 - val_loss: 3.3244e-04\n",
      "Epoch 137/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1879e-04 - val_loss: 3.3224e-04\n",
      "Epoch 138/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1864e-04 - val_loss: 3.3202e-04\n",
      "Epoch 139/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1865e-04 - val_loss: 3.3190e-04\n",
      "Epoch 140/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1833e-04 - val_loss: 3.3259e-04\n",
      "Epoch 141/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1864e-04 - val_loss: 3.3304e-04\n",
      "Epoch 142/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1877e-04 - val_loss: 3.3202e-04\n",
      "Epoch 143/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1871e-04 - val_loss: 3.3159e-04\n",
      "Epoch 144/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1841e-04 - val_loss: 3.3206e-04\n",
      "Epoch 145/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1831e-04 - val_loss: 3.3190e-04\n",
      "Epoch 146/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1824e-04 - val_loss: 3.3170e-04\n",
      "Epoch 147/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1823e-04 - val_loss: 3.3190e-04\n",
      "Epoch 148/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1833e-04 - val_loss: 3.3209e-04\n",
      "Epoch 149/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1847e-04 - val_loss: 3.3179e-04\n",
      "Epoch 150/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1821e-04 - val_loss: 3.3227e-04\n",
      "Epoch 151/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1853e-04 - val_loss: 3.3161e-04\n",
      "Epoch 152/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1839e-04 - val_loss: 3.3442e-04\n",
      "Epoch 153/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1839e-04 - val_loss: 3.3188e-04\n",
      "Epoch 154/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1838e-04 - val_loss: 3.3258e-04\n",
      "Epoch 155/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1819e-04 - val_loss: 3.3202e-04\n",
      "Epoch 156/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1824e-04 - val_loss: 3.3179e-04\n",
      "Epoch 157/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1830e-04 - val_loss: 3.3413e-04\n",
      "Epoch 158/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1830e-04 - val_loss: 3.3152e-04\n",
      "Epoch 159/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1810e-04 - val_loss: 3.3139e-04\n",
      "Epoch 160/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1836e-04 - val_loss: 3.3231e-04\n",
      "Epoch 161/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1791e-04 - val_loss: 3.3193e-04\n",
      "Epoch 162/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1811e-04 - val_loss: 3.3191e-04\n",
      "Epoch 163/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1809e-04 - val_loss: 3.3196e-04\n",
      "Epoch 164/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1832e-04 - val_loss: 3.3121e-04\n",
      "Epoch 165/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1786e-04 - val_loss: 3.3196e-04\n",
      "Epoch 166/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1808e-04 - val_loss: 3.3117e-04\n",
      "Epoch 167/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1823e-04 - val_loss: 3.3153e-04\n",
      "Epoch 168/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1808e-04 - val_loss: 3.3113e-04\n",
      "Epoch 169/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1781e-04 - val_loss: 3.3167e-04\n",
      "Epoch 170/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1792e-04 - val_loss: 3.3204e-04\n",
      "Epoch 171/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1793e-04 - val_loss: 3.3146e-04\n",
      "Epoch 172/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1783e-04 - val_loss: 3.3158e-04\n",
      "Epoch 173/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1786e-04 - val_loss: 3.3242e-04\n",
      "Epoch 174/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1785e-04 - val_loss: 3.3311e-04\n",
      "Epoch 175/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1810e-04 - val_loss: 3.3193e-04\n",
      "Epoch 176/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1795e-04 - val_loss: 3.3118e-04\n",
      "Epoch 177/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1770e-04 - val_loss: 3.3258e-04\n",
      "Epoch 178/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1762e-04 - val_loss: 3.3164e-04\n",
      "Epoch 179/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1775e-04 - val_loss: 3.3084e-04\n",
      "Epoch 180/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1814e-04 - val_loss: 3.3148e-04\n",
      "Epoch 181/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1767e-04 - val_loss: 3.3196e-04\n",
      "Epoch 182/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 3.1751e-04 - val_loss: 3.3175e-04\n",
      "Epoch 183/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 3.1742e-04 - val_loss: 3.3188e-04\n",
      "Epoch 184/1000\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 3.1760e-04 - val_loss: 3.3143e-04\n",
      "Epoch 185/1000\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 3.1754e-04 - val_loss: 3.3177e-04\n",
      "Epoch 186/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1756e-04 - val_loss: 3.3054e-04\n",
      "Epoch 187/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1736e-04 - val_loss: 3.3141e-04\n",
      "Epoch 188/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1750e-04 - val_loss: 3.3160e-04\n",
      "Epoch 189/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1733e-04 - val_loss: 3.3110e-04\n",
      "Epoch 190/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1739e-04 - val_loss: 3.3078e-04\n",
      "Epoch 191/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1730e-04 - val_loss: 3.3142e-04\n",
      "Epoch 192/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1737e-04 - val_loss: 3.3041e-04\n",
      "Epoch 193/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1748e-04 - val_loss: 3.3189e-04\n",
      "Epoch 194/1000\n",
      "250/250 [==============================] - 1s 4ms/step - loss: 3.1749e-04 - val_loss: 3.3273e-04\n",
      "Epoch 195/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1759e-04 - val_loss: 3.3070e-04\n",
      "Epoch 196/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1729e-04 - val_loss: 3.3086e-04\n",
      "Epoch 197/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1726e-04 - val_loss: 3.3057e-04\n",
      "Epoch 198/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1729e-04 - val_loss: 3.3045e-04\n",
      "Epoch 199/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1728e-04 - val_loss: 3.3088e-04\n",
      "Epoch 200/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1761e-04 - val_loss: 3.3048e-04\n",
      "Epoch 201/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1715e-04 - val_loss: 3.3088e-04\n",
      "Epoch 202/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1731e-04 - val_loss: 3.3052e-04\n",
      "Epoch 203/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1729e-04 - val_loss: 3.3056e-04\n",
      "Epoch 204/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1738e-04 - val_loss: 3.3081e-04\n",
      "Epoch 205/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1713e-04 - val_loss: 3.3104e-04\n",
      "Epoch 206/1000\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 3.1725e-04 - val_loss: 3.3206e-04\n",
      "Epoch 207/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1711e-04 - val_loss: 3.3056e-04\n",
      "Epoch 208/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1712e-04 - val_loss: 3.3082e-04\n",
      "Epoch 209/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1725e-04 - val_loss: 3.3071e-04\n",
      "Epoch 210/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1693e-04 - val_loss: 3.3124e-04\n",
      "Epoch 211/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1687e-04 - val_loss: 3.3077e-04\n",
      "Epoch 212/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1672e-04 - val_loss: 3.3045e-04\n",
      "Epoch 213/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1684e-04 - val_loss: 3.3153e-04\n",
      "Epoch 214/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1683e-04 - val_loss: 3.3045e-04\n",
      "Epoch 215/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1699e-04 - val_loss: 3.3070e-04\n",
      "Epoch 216/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1694e-04 - val_loss: 3.3041e-04\n",
      "Epoch 217/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1685e-04 - val_loss: 3.3020e-04\n",
      "Epoch 218/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1707e-04 - val_loss: 3.2988e-04\n",
      "Epoch 219/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1681e-04 - val_loss: 3.3138e-04\n",
      "Epoch 220/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1718e-04 - val_loss: 3.3054e-04\n",
      "Epoch 221/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1683e-04 - val_loss: 3.3043e-04\n",
      "Epoch 222/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1671e-04 - val_loss: 3.3066e-04\n",
      "Epoch 223/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1683e-04 - val_loss: 3.3090e-04\n",
      "Epoch 224/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1667e-04 - val_loss: 3.3087e-04\n",
      "Epoch 225/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1687e-04 - val_loss: 3.3017e-04\n",
      "Epoch 226/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1658e-04 - val_loss: 3.3023e-04\n",
      "Epoch 227/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1674e-04 - val_loss: 3.3100e-04\n",
      "Epoch 228/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1652e-04 - val_loss: 3.2993e-04\n",
      "Epoch 229/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1647e-04 - val_loss: 3.3144e-04\n",
      "Epoch 230/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1652e-04 - val_loss: 3.3056e-04\n",
      "Epoch 231/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1668e-04 - val_loss: 3.3059e-04\n",
      "Epoch 232/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1667e-04 - val_loss: 3.3239e-04\n",
      "Epoch 233/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1659e-04 - val_loss: 3.2969e-04\n",
      "Epoch 234/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1645e-04 - val_loss: 3.3066e-04\n",
      "Epoch 235/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1660e-04 - val_loss: 3.2937e-04\n",
      "Epoch 236/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1667e-04 - val_loss: 3.3133e-04\n",
      "Epoch 237/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1651e-04 - val_loss: 3.3181e-04\n",
      "Epoch 238/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1674e-04 - val_loss: 3.2967e-04\n",
      "Epoch 239/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1639e-04 - val_loss: 3.2990e-04\n",
      "Epoch 240/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 3.1634e-04 - val_loss: 3.3017e-04\n",
      "Epoch 241/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1619e-04 - val_loss: 3.3047e-04\n",
      "Epoch 242/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1617e-04 - val_loss: 3.3084e-04\n",
      "Epoch 243/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1626e-04 - val_loss: 3.2994e-04\n",
      "Epoch 244/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1650e-04 - val_loss: 3.3028e-04\n",
      "Epoch 245/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1643e-04 - val_loss: 3.3031e-04\n",
      "Epoch 246/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1663e-04 - val_loss: 3.3025e-04\n",
      "Epoch 247/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1613e-04 - val_loss: 3.2945e-04\n",
      "Epoch 248/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1625e-04 - val_loss: 3.3168e-04\n",
      "Epoch 249/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1647e-04 - val_loss: 3.3038e-04\n",
      "Epoch 250/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1609e-04 - val_loss: 3.2957e-04\n",
      "Epoch 251/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1611e-04 - val_loss: 3.3074e-04\n",
      "Epoch 252/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1603e-04 - val_loss: 3.3037e-04\n",
      "Epoch 253/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1608e-04 - val_loss: 3.3102e-04\n",
      "Epoch 254/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1610e-04 - val_loss: 3.3043e-04\n",
      "Epoch 255/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1614e-04 - val_loss: 3.3024e-04\n",
      "Epoch 256/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1622e-04 - val_loss: 3.2957e-04\n",
      "Epoch 257/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1600e-04 - val_loss: 3.2988e-04\n",
      "Epoch 258/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1610e-04 - val_loss: 3.3001e-04\n",
      "Epoch 259/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1589e-04 - val_loss: 3.2929e-04\n",
      "Epoch 260/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1598e-04 - val_loss: 3.2891e-04\n",
      "Epoch 261/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1636e-04 - val_loss: 3.2981e-04\n",
      "Epoch 262/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1570e-04 - val_loss: 3.2919e-04\n",
      "Epoch 263/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1570e-04 - val_loss: 3.2947e-04\n",
      "Epoch 264/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1585e-04 - val_loss: 3.2953e-04\n",
      "Epoch 265/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1601e-04 - val_loss: 3.2979e-04\n",
      "Epoch 266/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1582e-04 - val_loss: 3.2980e-04\n",
      "Epoch 267/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1588e-04 - val_loss: 3.3161e-04\n",
      "Epoch 268/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1598e-04 - val_loss: 3.3132e-04\n",
      "Epoch 269/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1581e-04 - val_loss: 3.2986e-04\n",
      "Epoch 270/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1579e-04 - val_loss: 3.2972e-04\n",
      "Epoch 271/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1554e-04 - val_loss: 3.2980e-04\n",
      "Epoch 272/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1573e-04 - val_loss: 3.2927e-04\n",
      "Epoch 273/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1565e-04 - val_loss: 3.2900e-04\n",
      "Epoch 274/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1552e-04 - val_loss: 3.2938e-04\n",
      "Epoch 275/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1566e-04 - val_loss: 3.2917e-04\n",
      "Epoch 276/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1571e-04 - val_loss: 3.2978e-04\n",
      "Epoch 277/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1533e-04 - val_loss: 3.2962e-04\n",
      "Epoch 278/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1574e-04 - val_loss: 3.3040e-04\n",
      "Epoch 279/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1541e-04 - val_loss: 3.2955e-04\n",
      "Epoch 280/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1569e-04 - val_loss: 3.3049e-04\n",
      "Epoch 281/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1550e-04 - val_loss: 3.3010e-04\n",
      "Epoch 282/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1548e-04 - val_loss: 3.2994e-04\n",
      "Epoch 283/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1533e-04 - val_loss: 3.2892e-04\n",
      "Epoch 284/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1562e-04 - val_loss: 3.2907e-04\n",
      "Epoch 285/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1547e-04 - val_loss: 3.2947e-04\n",
      "Epoch 286/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1526e-04 - val_loss: 3.2915e-04\n",
      "Epoch 287/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1545e-04 - val_loss: 3.2941e-04\n",
      "Epoch 288/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1520e-04 - val_loss: 3.2925e-04\n",
      "Epoch 289/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1511e-04 - val_loss: 3.2900e-04\n",
      "Epoch 290/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1542e-04 - val_loss: 3.2849e-04\n",
      "Epoch 291/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1526e-04 - val_loss: 3.2929e-04\n",
      "Epoch 292/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1515e-04 - val_loss: 3.2910e-04\n",
      "Epoch 293/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1524e-04 - val_loss: 3.2949e-04\n",
      "Epoch 294/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1513e-04 - val_loss: 3.2973e-04\n",
      "Epoch 295/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1509e-04 - val_loss: 3.2916e-04\n",
      "Epoch 296/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1517e-04 - val_loss: 3.2987e-04\n",
      "Epoch 297/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1545e-04 - val_loss: 3.2922e-04\n",
      "Epoch 298/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1525e-04 - val_loss: 3.3110e-04\n",
      "Epoch 299/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1517e-04 - val_loss: 3.2941e-04\n",
      "Epoch 300/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1512e-04 - val_loss: 3.2857e-04\n",
      "Epoch 301/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1506e-04 - val_loss: 3.2907e-04\n",
      "Epoch 302/1000\n",
      "250/250 [==============================] - 2s 8ms/step - loss: 3.1497e-04 - val_loss: 3.2916e-04\n",
      "Epoch 303/1000\n",
      "250/250 [==============================] - 2s 7ms/step - loss: 3.1496e-04 - val_loss: 3.2851e-04\n",
      "Epoch 304/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1492e-04 - val_loss: 3.2888e-04\n",
      "Epoch 305/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1500e-04 - val_loss: 3.2871e-04\n",
      "Epoch 306/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1492e-04 - val_loss: 3.2902e-04\n",
      "Epoch 307/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1488e-04 - val_loss: 3.2896e-04\n",
      "Epoch 308/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1508e-04 - val_loss: 3.2860e-04\n",
      "Epoch 309/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1497e-04 - val_loss: 3.2891e-04\n",
      "Epoch 310/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1493e-04 - val_loss: 3.2957e-04\n",
      "Epoch 311/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1510e-04 - val_loss: 3.2907e-04\n",
      "Epoch 312/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1467e-04 - val_loss: 3.2902e-04\n",
      "Epoch 313/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1460e-04 - val_loss: 3.2883e-04\n",
      "Epoch 314/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1503e-04 - val_loss: 3.3109e-04\n",
      "Epoch 315/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1462e-04 - val_loss: 3.2900e-04\n",
      "Epoch 316/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1507e-04 - val_loss: 3.2919e-04\n",
      "Epoch 317/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1507e-04 - val_loss: 3.2888e-04\n",
      "Epoch 318/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1472e-04 - val_loss: 3.3025e-04\n",
      "Epoch 319/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1499e-04 - val_loss: 3.2898e-04\n",
      "Epoch 320/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1465e-04 - val_loss: 3.2828e-04\n",
      "Epoch 321/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1467e-04 - val_loss: 3.2881e-04\n",
      "Epoch 322/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1485e-04 - val_loss: 3.3046e-04\n",
      "Epoch 323/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1473e-04 - val_loss: 3.2899e-04\n",
      "Epoch 324/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1474e-04 - val_loss: 3.2873e-04\n",
      "Epoch 325/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1460e-04 - val_loss: 3.2849e-04\n",
      "Epoch 326/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1481e-04 - val_loss: 3.2834e-04\n",
      "Epoch 327/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1467e-04 - val_loss: 3.2841e-04\n",
      "Epoch 328/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1447e-04 - val_loss: 3.2902e-04\n",
      "Epoch 329/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1445e-04 - val_loss: 3.2890e-04\n",
      "Epoch 330/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1466e-04 - val_loss: 3.2780e-04\n",
      "Epoch 331/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1460e-04 - val_loss: 3.2789e-04\n",
      "Epoch 332/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1446e-04 - val_loss: 3.2857e-04\n",
      "Epoch 333/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1443e-04 - val_loss: 3.2798e-04\n",
      "Epoch 334/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1483e-04 - val_loss: 3.2919e-04\n",
      "Epoch 335/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1503e-04 - val_loss: 3.2913e-04\n",
      "Epoch 336/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1443e-04 - val_loss: 3.2909e-04\n",
      "Epoch 337/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1436e-04 - val_loss: 3.2803e-04\n",
      "Epoch 338/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1442e-04 - val_loss: 3.2932e-04\n",
      "Epoch 339/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1436e-04 - val_loss: 3.2772e-04\n",
      "Epoch 340/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1413e-04 - val_loss: 3.2877e-04\n",
      "Epoch 341/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1413e-04 - val_loss: 3.2894e-04\n",
      "Epoch 342/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1425e-04 - val_loss: 3.2996e-04\n",
      "Epoch 343/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1440e-04 - val_loss: 3.2837e-04\n",
      "Epoch 344/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1421e-04 - val_loss: 3.2812e-04\n",
      "Epoch 345/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1396e-04 - val_loss: 3.2793e-04\n",
      "Epoch 346/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1431e-04 - val_loss: 3.2847e-04\n",
      "Epoch 347/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1422e-04 - val_loss: 3.2802e-04\n",
      "Epoch 348/1000\n",
      "250/250 [==============================] - 2s 6ms/step - loss: 3.1399e-04 - val_loss: 3.2880e-04\n",
      "Epoch 349/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1412e-04 - val_loss: 3.2863e-04\n",
      "Epoch 350/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1422e-04 - val_loss: 3.2865e-04\n",
      "Epoch 351/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1422e-04 - val_loss: 3.2833e-04\n",
      "Epoch 352/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1469e-04 - val_loss: 3.2766e-04\n",
      "Epoch 353/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1416e-04 - val_loss: 3.2889e-04\n",
      "Epoch 354/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1400e-04 - val_loss: 3.2756e-04\n",
      "Epoch 355/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1407e-04 - val_loss: 3.2806e-04\n",
      "Epoch 356/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1399e-04 - val_loss: 3.2802e-04\n",
      "Epoch 357/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1394e-04 - val_loss: 3.2757e-04\n",
      "Epoch 358/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1386e-04 - val_loss: 3.2916e-04\n",
      "Epoch 359/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1406e-04 - val_loss: 3.2801e-04\n",
      "Epoch 360/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1382e-04 - val_loss: 3.2800e-04\n",
      "Epoch 361/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1435e-04 - val_loss: 3.2823e-04\n",
      "Epoch 362/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1405e-04 - val_loss: 3.2799e-04\n",
      "Epoch 363/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1402e-04 - val_loss: 3.2852e-04\n",
      "Epoch 364/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1389e-04 - val_loss: 3.2815e-04\n",
      "Epoch 365/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1378e-04 - val_loss: 3.2777e-04\n",
      "Epoch 366/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1371e-04 - val_loss: 3.2793e-04\n",
      "Epoch 367/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1393e-04 - val_loss: 3.2915e-04\n",
      "Epoch 368/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1371e-04 - val_loss: 3.2761e-04\n",
      "Epoch 369/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1368e-04 - val_loss: 3.2976e-04\n",
      "Epoch 370/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1389e-04 - val_loss: 3.2742e-04\n",
      "Epoch 371/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1383e-04 - val_loss: 3.2813e-04\n",
      "Epoch 372/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1370e-04 - val_loss: 3.2991e-04\n",
      "Epoch 373/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1381e-04 - val_loss: 3.2862e-04\n",
      "Epoch 374/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1357e-04 - val_loss: 3.2838e-04\n",
      "Epoch 375/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1391e-04 - val_loss: 3.2742e-04\n",
      "Epoch 376/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1361e-04 - val_loss: 3.2712e-04\n",
      "Epoch 377/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1352e-04 - val_loss: 3.2772e-04\n",
      "Epoch 378/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1354e-04 - val_loss: 3.2935e-04\n",
      "Epoch 379/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1386e-04 - val_loss: 3.2803e-04\n",
      "Epoch 380/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1370e-04 - val_loss: 3.2711e-04\n",
      "Epoch 381/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1355e-04 - val_loss: 3.2755e-04\n",
      "Epoch 382/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1370e-04 - val_loss: 3.2771e-04\n",
      "Epoch 383/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1328e-04 - val_loss: 3.2877e-04\n",
      "Epoch 384/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1396e-04 - val_loss: 3.2778e-04\n",
      "Epoch 385/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1329e-04 - val_loss: 3.2808e-04\n",
      "Epoch 386/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1330e-04 - val_loss: 3.2737e-04\n",
      "Epoch 387/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1349e-04 - val_loss: 3.2778e-04\n",
      "Epoch 388/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1342e-04 - val_loss: 3.2753e-04\n",
      "Epoch 389/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1322e-04 - val_loss: 3.2750e-04\n",
      "Epoch 390/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1341e-04 - val_loss: 3.2729e-04\n",
      "Epoch 391/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1338e-04 - val_loss: 3.2737e-04\n",
      "Epoch 392/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1335e-04 - val_loss: 3.2849e-04\n",
      "Epoch 393/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1387e-04 - val_loss: 3.2760e-04\n",
      "Epoch 394/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1338e-04 - val_loss: 3.2789e-04\n",
      "Epoch 395/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1339e-04 - val_loss: 3.2730e-04\n",
      "Epoch 396/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1327e-04 - val_loss: 3.2838e-04\n",
      "Epoch 397/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1329e-04 - val_loss: 3.2814e-04\n",
      "Epoch 398/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1328e-04 - val_loss: 3.2924e-04\n",
      "Epoch 399/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1309e-04 - val_loss: 3.2753e-04\n",
      "Epoch 400/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1319e-04 - val_loss: 3.2787e-04\n",
      "Epoch 401/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1310e-04 - val_loss: 3.2759e-04\n",
      "Epoch 402/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1332e-04 - val_loss: 3.2696e-04\n",
      "Epoch 403/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1312e-04 - val_loss: 3.2723e-04\n",
      "Epoch 404/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1319e-04 - val_loss: 3.2813e-04\n",
      "Epoch 405/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1300e-04 - val_loss: 3.2662e-04\n",
      "Epoch 406/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1300e-04 - val_loss: 3.2682e-04\n",
      "Epoch 407/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1344e-04 - val_loss: 3.2692e-04\n",
      "Epoch 408/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1312e-04 - val_loss: 3.2765e-04\n",
      "Epoch 409/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1303e-04 - val_loss: 3.2710e-04\n",
      "Epoch 410/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1317e-04 - val_loss: 3.2836e-04\n",
      "Epoch 411/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1312e-04 - val_loss: 3.2730e-04\n",
      "Epoch 412/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1296e-04 - val_loss: 3.2774e-04\n",
      "Epoch 413/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1289e-04 - val_loss: 3.2779e-04\n",
      "Epoch 414/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1297e-04 - val_loss: 3.2705e-04\n",
      "Epoch 415/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1310e-04 - val_loss: 3.2723e-04\n",
      "Epoch 416/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1305e-04 - val_loss: 3.2650e-04\n",
      "Epoch 417/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1269e-04 - val_loss: 3.2684e-04\n",
      "Epoch 418/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1269e-04 - val_loss: 3.2694e-04\n",
      "Epoch 419/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1283e-04 - val_loss: 3.2771e-04\n",
      "Epoch 420/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1268e-04 - val_loss: 3.2738e-04\n",
      "Epoch 421/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1294e-04 - val_loss: 3.2654e-04\n",
      "Epoch 422/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1276e-04 - val_loss: 3.2778e-04\n",
      "Epoch 423/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1275e-04 - val_loss: 3.2860e-04\n",
      "Epoch 424/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1321e-04 - val_loss: 3.2750e-04\n",
      "Epoch 425/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1263e-04 - val_loss: 3.2695e-04\n",
      "Epoch 426/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1267e-04 - val_loss: 3.2736e-04\n",
      "Epoch 427/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1275e-04 - val_loss: 3.2640e-04\n",
      "Epoch 428/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1243e-04 - val_loss: 3.2638e-04\n",
      "Epoch 429/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1277e-04 - val_loss: 3.2749e-04\n",
      "Epoch 430/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1247e-04 - val_loss: 3.2693e-04\n",
      "Epoch 431/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1244e-04 - val_loss: 3.2670e-04\n",
      "Epoch 432/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1275e-04 - val_loss: 3.2734e-04\n",
      "Epoch 433/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1270e-04 - val_loss: 3.2777e-04\n",
      "Epoch 434/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1259e-04 - val_loss: 3.2718e-04\n",
      "Epoch 435/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1256e-04 - val_loss: 3.2631e-04\n",
      "Epoch 436/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1235e-04 - val_loss: 3.2705e-04\n",
      "Epoch 437/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1259e-04 - val_loss: 3.2676e-04\n",
      "Epoch 438/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1230e-04 - val_loss: 3.2699e-04\n",
      "Epoch 439/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1254e-04 - val_loss: 3.2672e-04\n",
      "Epoch 440/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1248e-04 - val_loss: 3.2634e-04\n",
      "Epoch 441/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1258e-04 - val_loss: 3.2748e-04\n",
      "Epoch 442/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1240e-04 - val_loss: 3.2831e-04\n",
      "Epoch 443/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1251e-04 - val_loss: 3.2627e-04\n",
      "Epoch 444/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1261e-04 - val_loss: 3.2644e-04\n",
      "Epoch 445/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1235e-04 - val_loss: 3.2682e-04\n",
      "Epoch 446/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1210e-04 - val_loss: 3.2728e-04\n",
      "Epoch 447/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1216e-04 - val_loss: 3.2587e-04\n",
      "Epoch 448/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1243e-04 - val_loss: 3.2773e-04\n",
      "Epoch 449/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1196e-04 - val_loss: 3.2569e-04\n",
      "Epoch 450/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1250e-04 - val_loss: 3.2672e-04\n",
      "Epoch 451/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1223e-04 - val_loss: 3.2786e-04\n",
      "Epoch 452/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1206e-04 - val_loss: 3.2600e-04\n",
      "Epoch 453/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1238e-04 - val_loss: 3.2680e-04\n",
      "Epoch 454/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1211e-04 - val_loss: 3.2608e-04\n",
      "Epoch 455/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1220e-04 - val_loss: 3.2636e-04\n",
      "Epoch 456/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1208e-04 - val_loss: 3.2639e-04\n",
      "Epoch 457/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1236e-04 - val_loss: 3.2627e-04\n",
      "Epoch 458/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1221e-04 - val_loss: 3.2628e-04\n",
      "Epoch 459/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1209e-04 - val_loss: 3.2679e-04\n",
      "Epoch 460/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1187e-04 - val_loss: 3.2646e-04\n",
      "Epoch 461/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1218e-04 - val_loss: 3.2663e-04\n",
      "Epoch 462/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1217e-04 - val_loss: 3.2640e-04\n",
      "Epoch 463/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1224e-04 - val_loss: 3.2702e-04\n",
      "Epoch 464/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1177e-04 - val_loss: 3.2673e-04\n",
      "Epoch 465/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1186e-04 - val_loss: 3.2651e-04\n",
      "Epoch 466/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1190e-04 - val_loss: 3.2636e-04\n",
      "Epoch 467/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1224e-04 - val_loss: 3.2755e-04\n",
      "Epoch 468/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1199e-04 - val_loss: 3.2665e-04\n",
      "Epoch 469/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1200e-04 - val_loss: 3.2601e-04\n",
      "Epoch 470/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1190e-04 - val_loss: 3.2806e-04\n",
      "Epoch 471/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1175e-04 - val_loss: 3.2702e-04\n",
      "Epoch 472/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1221e-04 - val_loss: 3.2656e-04\n",
      "Epoch 473/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1175e-04 - val_loss: 3.2706e-04\n",
      "Epoch 474/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1197e-04 - val_loss: 3.2683e-04\n",
      "Epoch 475/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1205e-04 - val_loss: 3.2694e-04\n",
      "Epoch 476/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1191e-04 - val_loss: 3.2623e-04\n",
      "Epoch 477/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1168e-04 - val_loss: 3.2585e-04\n",
      "Epoch 478/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1198e-04 - val_loss: 3.2659e-04\n",
      "Epoch 479/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1176e-04 - val_loss: 3.2561e-04\n",
      "Epoch 480/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1158e-04 - val_loss: 3.2575e-04\n",
      "Epoch 481/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1168e-04 - val_loss: 3.2581e-04\n",
      "Epoch 482/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1166e-04 - val_loss: 3.2931e-04\n",
      "Epoch 483/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1187e-04 - val_loss: 3.2721e-04\n",
      "Epoch 484/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1176e-04 - val_loss: 3.2579e-04\n",
      "Epoch 485/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1136e-04 - val_loss: 3.2605e-04\n",
      "Epoch 486/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1170e-04 - val_loss: 3.2664e-04\n",
      "Epoch 487/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1168e-04 - val_loss: 3.2705e-04\n",
      "Epoch 488/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1164e-04 - val_loss: 3.2545e-04\n",
      "Epoch 489/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1156e-04 - val_loss: 3.2650e-04\n",
      "Epoch 490/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1164e-04 - val_loss: 3.2578e-04\n",
      "Epoch 491/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1148e-04 - val_loss: 3.2626e-04\n",
      "Epoch 492/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1148e-04 - val_loss: 3.2672e-04\n",
      "Epoch 493/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1171e-04 - val_loss: 3.2671e-04\n",
      "Epoch 494/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1135e-04 - val_loss: 3.2589e-04\n",
      "Epoch 495/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1138e-04 - val_loss: 3.2605e-04\n",
      "Epoch 496/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1147e-04 - val_loss: 3.2618e-04\n",
      "Epoch 497/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1131e-04 - val_loss: 3.2587e-04\n",
      "Epoch 498/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1131e-04 - val_loss: 3.2716e-04\n",
      "Epoch 499/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1171e-04 - val_loss: 3.2664e-04\n",
      "Epoch 500/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1136e-04 - val_loss: 3.2615e-04\n",
      "Epoch 501/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1137e-04 - val_loss: 3.2578e-04\n",
      "Epoch 502/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1115e-04 - val_loss: 3.2597e-04\n",
      "Epoch 503/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1122e-04 - val_loss: 3.2630e-04\n",
      "Epoch 504/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1119e-04 - val_loss: 3.2630e-04\n",
      "Epoch 505/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1168e-04 - val_loss: 3.2814e-04\n",
      "Epoch 506/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1137e-04 - val_loss: 3.2668e-04\n",
      "Epoch 507/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1144e-04 - val_loss: 3.2570e-04\n",
      "Epoch 508/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1127e-04 - val_loss: 3.2556e-04\n",
      "Epoch 509/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1096e-04 - val_loss: 3.2560e-04\n",
      "Epoch 510/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1127e-04 - val_loss: 3.2670e-04\n",
      "Epoch 511/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1107e-04 - val_loss: 3.2646e-04\n",
      "Epoch 512/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1099e-04 - val_loss: 3.2607e-04\n",
      "Epoch 513/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1107e-04 - val_loss: 3.2654e-04\n",
      "Epoch 514/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1150e-04 - val_loss: 3.2586e-04\n",
      "Epoch 515/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1134e-04 - val_loss: 3.2571e-04\n",
      "Epoch 516/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1123e-04 - val_loss: 3.2577e-04\n",
      "Epoch 517/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1131e-04 - val_loss: 3.2577e-04\n",
      "Epoch 518/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1099e-04 - val_loss: 3.2563e-04\n",
      "Epoch 519/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1104e-04 - val_loss: 3.2546e-04\n",
      "Epoch 520/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1104e-04 - val_loss: 3.2588e-04\n",
      "Epoch 521/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1110e-04 - val_loss: 3.2643e-04\n",
      "Epoch 522/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1093e-04 - val_loss: 3.2576e-04\n",
      "Epoch 523/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1103e-04 - val_loss: 3.2553e-04\n",
      "Epoch 524/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1121e-04 - val_loss: 3.2651e-04\n",
      "Epoch 525/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1101e-04 - val_loss: 3.2564e-04\n",
      "Epoch 526/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1096e-04 - val_loss: 3.2566e-04\n",
      "Epoch 527/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1094e-04 - val_loss: 3.2526e-04\n",
      "Epoch 528/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1072e-04 - val_loss: 3.2525e-04\n",
      "Epoch 529/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1085e-04 - val_loss: 3.2648e-04\n",
      "Epoch 530/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1087e-04 - val_loss: 3.2573e-04\n",
      "Epoch 531/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1138e-04 - val_loss: 3.2569e-04\n",
      "Epoch 532/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1074e-04 - val_loss: 3.2544e-04\n",
      "Epoch 533/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1094e-04 - val_loss: 3.2630e-04\n",
      "Epoch 534/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1104e-04 - val_loss: 3.2562e-04\n",
      "Epoch 535/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1055e-04 - val_loss: 3.2507e-04\n",
      "Epoch 536/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1060e-04 - val_loss: 3.2590e-04\n",
      "Epoch 537/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1073e-04 - val_loss: 3.2519e-04\n",
      "Epoch 538/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1059e-04 - val_loss: 3.2571e-04\n",
      "Epoch 539/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1062e-04 - val_loss: 3.2599e-04\n",
      "Epoch 540/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1068e-04 - val_loss: 3.2562e-04\n",
      "Epoch 541/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1072e-04 - val_loss: 3.2502e-04\n",
      "Epoch 542/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1083e-04 - val_loss: 3.2524e-04\n",
      "Epoch 543/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1055e-04 - val_loss: 3.2543e-04\n",
      "Epoch 544/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1059e-04 - val_loss: 3.2478e-04\n",
      "Epoch 545/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1045e-04 - val_loss: 3.2546e-04\n",
      "Epoch 546/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1047e-04 - val_loss: 3.2521e-04\n",
      "Epoch 547/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1071e-04 - val_loss: 3.2540e-04\n",
      "Epoch 548/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1055e-04 - val_loss: 3.2556e-04\n",
      "Epoch 549/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1038e-04 - val_loss: 3.2504e-04\n",
      "Epoch 550/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1044e-04 - val_loss: 3.2506e-04\n",
      "Epoch 551/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1031e-04 - val_loss: 3.2543e-04\n",
      "Epoch 552/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1068e-04 - val_loss: 3.2562e-04\n",
      "Epoch 553/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1055e-04 - val_loss: 3.2487e-04\n",
      "Epoch 554/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1048e-04 - val_loss: 3.2481e-04\n",
      "Epoch 555/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1059e-04 - val_loss: 3.2498e-04\n",
      "Epoch 556/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1037e-04 - val_loss: 3.2508e-04\n",
      "Epoch 557/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1049e-04 - val_loss: 3.2576e-04\n",
      "Epoch 558/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1046e-04 - val_loss: 3.2828e-04\n",
      "Epoch 559/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1064e-04 - val_loss: 3.2522e-04\n",
      "Epoch 560/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1025e-04 - val_loss: 3.2466e-04\n",
      "Epoch 561/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1023e-04 - val_loss: 3.2622e-04\n",
      "Epoch 562/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1041e-04 - val_loss: 3.2451e-04\n",
      "Epoch 563/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1014e-04 - val_loss: 3.2486e-04\n",
      "Epoch 564/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1020e-04 - val_loss: 3.2533e-04\n",
      "Epoch 565/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1027e-04 - val_loss: 3.2546e-04\n",
      "Epoch 566/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1003e-04 - val_loss: 3.2437e-04\n",
      "Epoch 567/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1061e-04 - val_loss: 3.2481e-04\n",
      "Epoch 568/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1008e-04 - val_loss: 3.2424e-04\n",
      "Epoch 569/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1014e-04 - val_loss: 3.2545e-04\n",
      "Epoch 570/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1054e-04 - val_loss: 3.2424e-04\n",
      "Epoch 571/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1032e-04 - val_loss: 3.2425e-04\n",
      "Epoch 572/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1034e-04 - val_loss: 3.2481e-04\n",
      "Epoch 573/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0996e-04 - val_loss: 3.2564e-04\n",
      "Epoch 574/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1014e-04 - val_loss: 3.2453e-04\n",
      "Epoch 575/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1026e-04 - val_loss: 3.2477e-04\n",
      "Epoch 576/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0996e-04 - val_loss: 3.2468e-04\n",
      "Epoch 577/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.1012e-04 - val_loss: 3.2458e-04\n",
      "Epoch 578/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0994e-04 - val_loss: 3.2504e-04\n",
      "Epoch 579/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0999e-04 - val_loss: 3.2418e-04\n",
      "Epoch 580/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1019e-04 - val_loss: 3.2566e-04\n",
      "Epoch 581/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0990e-04 - val_loss: 3.2500e-04\n",
      "Epoch 582/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1015e-04 - val_loss: 3.2520e-04\n",
      "Epoch 583/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0990e-04 - val_loss: 3.2451e-04\n",
      "Epoch 584/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1018e-04 - val_loss: 3.2472e-04\n",
      "Epoch 585/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0992e-04 - val_loss: 3.2520e-04\n",
      "Epoch 586/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0990e-04 - val_loss: 3.2473e-04\n",
      "Epoch 587/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0989e-04 - val_loss: 3.2533e-04\n",
      "Epoch 588/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1007e-04 - val_loss: 3.2437e-04\n",
      "Epoch 589/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0992e-04 - val_loss: 3.2483e-04\n",
      "Epoch 590/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0968e-04 - val_loss: 3.2602e-04\n",
      "Epoch 591/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0989e-04 - val_loss: 3.2479e-04\n",
      "Epoch 592/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0989e-04 - val_loss: 3.2498e-04\n",
      "Epoch 593/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0988e-04 - val_loss: 3.2439e-04\n",
      "Epoch 594/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0975e-04 - val_loss: 3.2403e-04\n",
      "Epoch 595/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0995e-04 - val_loss: 3.2578e-04\n",
      "Epoch 596/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0996e-04 - val_loss: 3.2434e-04\n",
      "Epoch 597/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0962e-04 - val_loss: 3.2504e-04\n",
      "Epoch 598/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0970e-04 - val_loss: 3.2445e-04\n",
      "Epoch 599/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0970e-04 - val_loss: 3.2591e-04\n",
      "Epoch 600/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0978e-04 - val_loss: 3.2577e-04\n",
      "Epoch 601/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.1033e-04 - val_loss: 3.2494e-04\n",
      "Epoch 602/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0966e-04 - val_loss: 3.2436e-04\n",
      "Epoch 603/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0953e-04 - val_loss: 3.2486e-04\n",
      "Epoch 604/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0959e-04 - val_loss: 3.2450e-04\n",
      "Epoch 605/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0978e-04 - val_loss: 3.2468e-04\n",
      "Epoch 606/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0944e-04 - val_loss: 3.2442e-04\n",
      "Epoch 607/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0952e-04 - val_loss: 3.2493e-04\n",
      "Epoch 608/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0988e-04 - val_loss: 3.2511e-04\n",
      "Epoch 609/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0956e-04 - val_loss: 3.2456e-04\n",
      "Epoch 610/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0966e-04 - val_loss: 3.2464e-04\n",
      "Epoch 611/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0947e-04 - val_loss: 3.2377e-04\n",
      "Epoch 612/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0953e-04 - val_loss: 3.2487e-04\n",
      "Epoch 613/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0955e-04 - val_loss: 3.2420e-04\n",
      "Epoch 614/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0941e-04 - val_loss: 3.2443e-04\n",
      "Epoch 615/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0949e-04 - val_loss: 3.2463e-04\n",
      "Epoch 616/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0951e-04 - val_loss: 3.2461e-04\n",
      "Epoch 617/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0981e-04 - val_loss: 3.2427e-04\n",
      "Epoch 618/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0941e-04 - val_loss: 3.2533e-04\n",
      "Epoch 619/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0972e-04 - val_loss: 3.2499e-04\n",
      "Epoch 620/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0956e-04 - val_loss: 3.2434e-04\n",
      "Epoch 621/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0921e-04 - val_loss: 3.2333e-04\n",
      "Epoch 622/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0970e-04 - val_loss: 3.2433e-04\n",
      "Epoch 623/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0917e-04 - val_loss: 3.2371e-04\n",
      "Epoch 624/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0930e-04 - val_loss: 3.2455e-04\n",
      "Epoch 625/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0954e-04 - val_loss: 3.2402e-04\n",
      "Epoch 626/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0928e-04 - val_loss: 3.2377e-04\n",
      "Epoch 627/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0933e-04 - val_loss: 3.2455e-04\n",
      "Epoch 628/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0946e-04 - val_loss: 3.2480e-04\n",
      "Epoch 629/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0933e-04 - val_loss: 3.2662e-04\n",
      "Epoch 630/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0934e-04 - val_loss: 3.2408e-04\n",
      "Epoch 631/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0931e-04 - val_loss: 3.2459e-04\n",
      "Epoch 632/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0907e-04 - val_loss: 3.2410e-04\n",
      "Epoch 633/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0915e-04 - val_loss: 3.2430e-04\n",
      "Epoch 634/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0904e-04 - val_loss: 3.2362e-04\n",
      "Epoch 635/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0896e-04 - val_loss: 3.2597e-04\n",
      "Epoch 636/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0917e-04 - val_loss: 3.2470e-04\n",
      "Epoch 637/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0931e-04 - val_loss: 3.2678e-04\n",
      "Epoch 638/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0922e-04 - val_loss: 3.2384e-04\n",
      "Epoch 639/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0909e-04 - val_loss: 3.2402e-04\n",
      "Epoch 640/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0916e-04 - val_loss: 3.2411e-04\n",
      "Epoch 641/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0899e-04 - val_loss: 3.2359e-04\n",
      "Epoch 642/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0902e-04 - val_loss: 3.2394e-04\n",
      "Epoch 643/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0915e-04 - val_loss: 3.2341e-04\n",
      "Epoch 644/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0899e-04 - val_loss: 3.2363e-04\n",
      "Epoch 645/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0886e-04 - val_loss: 3.2402e-04\n",
      "Epoch 646/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0892e-04 - val_loss: 3.2457e-04\n",
      "Epoch 647/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0911e-04 - val_loss: 3.2494e-04\n",
      "Epoch 648/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0886e-04 - val_loss: 3.2480e-04\n",
      "Epoch 649/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0912e-04 - val_loss: 3.2458e-04\n",
      "Epoch 650/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0927e-04 - val_loss: 3.2405e-04\n",
      "Epoch 651/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0901e-04 - val_loss: 3.2412e-04\n",
      "Epoch 652/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0915e-04 - val_loss: 3.2522e-04\n",
      "Epoch 653/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0894e-04 - val_loss: 3.2331e-04\n",
      "Epoch 654/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0920e-04 - val_loss: 3.2349e-04\n",
      "Epoch 655/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0885e-04 - val_loss: 3.2421e-04\n",
      "Epoch 656/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0875e-04 - val_loss: 3.2382e-04\n",
      "Epoch 657/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0883e-04 - val_loss: 3.2454e-04\n",
      "Epoch 658/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0894e-04 - val_loss: 3.2421e-04\n",
      "Epoch 659/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0876e-04 - val_loss: 3.2383e-04\n",
      "Epoch 660/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0891e-04 - val_loss: 3.2371e-04\n",
      "Epoch 661/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0892e-04 - val_loss: 3.2421e-04\n",
      "Epoch 662/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0872e-04 - val_loss: 3.2500e-04\n",
      "Epoch 663/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0892e-04 - val_loss: 3.2363e-04\n",
      "Epoch 664/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0864e-04 - val_loss: 3.2346e-04\n",
      "Epoch 665/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0885e-04 - val_loss: 3.2400e-04\n",
      "Epoch 666/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0869e-04 - val_loss: 3.2335e-04\n",
      "Epoch 667/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0874e-04 - val_loss: 3.2398e-04\n",
      "Epoch 668/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0861e-04 - val_loss: 3.2344e-04\n",
      "Epoch 669/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0857e-04 - val_loss: 3.2395e-04\n",
      "Epoch 670/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0872e-04 - val_loss: 3.2375e-04\n",
      "Epoch 671/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0859e-04 - val_loss: 3.2348e-04\n",
      "Epoch 672/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0872e-04 - val_loss: 3.2417e-04\n",
      "Epoch 673/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0862e-04 - val_loss: 3.2454e-04\n",
      "Epoch 674/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0865e-04 - val_loss: 3.2502e-04\n",
      "Epoch 675/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0968e-04 - val_loss: 3.2280e-04\n",
      "Epoch 676/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0858e-04 - val_loss: 3.2337e-04\n",
      "Epoch 677/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0875e-04 - val_loss: 3.2317e-04\n",
      "Epoch 678/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0853e-04 - val_loss: 3.2318e-04\n",
      "Epoch 679/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0850e-04 - val_loss: 3.2378e-04\n",
      "Epoch 680/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0858e-04 - val_loss: 3.2357e-04\n",
      "Epoch 681/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0854e-04 - val_loss: 3.2415e-04\n",
      "Epoch 682/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0857e-04 - val_loss: 3.2355e-04\n",
      "Epoch 683/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0841e-04 - val_loss: 3.2279e-04\n",
      "Epoch 684/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0850e-04 - val_loss: 3.2330e-04\n",
      "Epoch 685/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0839e-04 - val_loss: 3.2326e-04\n",
      "Epoch 686/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0837e-04 - val_loss: 3.2340e-04\n",
      "Epoch 687/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0845e-04 - val_loss: 3.2306e-04\n",
      "Epoch 688/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0857e-04 - val_loss: 3.2345e-04\n",
      "Epoch 689/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0838e-04 - val_loss: 3.2376e-04\n",
      "Epoch 690/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0832e-04 - val_loss: 3.2393e-04\n",
      "Epoch 691/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0848e-04 - val_loss: 3.2286e-04\n",
      "Epoch 692/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0830e-04 - val_loss: 3.2323e-04\n",
      "Epoch 693/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0843e-04 - val_loss: 3.2541e-04\n",
      "Epoch 694/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0838e-04 - val_loss: 3.2366e-04\n",
      "Epoch 695/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0829e-04 - val_loss: 3.2310e-04\n",
      "Epoch 696/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0810e-04 - val_loss: 3.2279e-04\n",
      "Epoch 697/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0831e-04 - val_loss: 3.2378e-04\n",
      "Epoch 698/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0823e-04 - val_loss: 3.2327e-04\n",
      "Epoch 699/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0807e-04 - val_loss: 3.2383e-04\n",
      "Epoch 700/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0826e-04 - val_loss: 3.2381e-04\n",
      "Epoch 701/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0801e-04 - val_loss: 3.2264e-04\n",
      "Epoch 702/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0811e-04 - val_loss: 3.2328e-04\n",
      "Epoch 703/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0815e-04 - val_loss: 3.2261e-04\n",
      "Epoch 704/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0899e-04 - val_loss: 3.2342e-04\n",
      "Epoch 705/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0812e-04 - val_loss: 3.2326e-04\n",
      "Epoch 706/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0833e-04 - val_loss: 3.2391e-04\n",
      "Epoch 707/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0819e-04 - val_loss: 3.2379e-04\n",
      "Epoch 708/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0805e-04 - val_loss: 3.2288e-04\n",
      "Epoch 709/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0777e-04 - val_loss: 3.2276e-04\n",
      "Epoch 710/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0791e-04 - val_loss: 3.2390e-04\n",
      "Epoch 711/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0808e-04 - val_loss: 3.2316e-04\n",
      "Epoch 712/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0795e-04 - val_loss: 3.2310e-04\n",
      "Epoch 713/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0786e-04 - val_loss: 3.2260e-04\n",
      "Epoch 714/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0796e-04 - val_loss: 3.2304e-04\n",
      "Epoch 715/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0789e-04 - val_loss: 3.2284e-04\n",
      "Epoch 716/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0781e-04 - val_loss: 3.2421e-04\n",
      "Epoch 717/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0809e-04 - val_loss: 3.2322e-04\n",
      "Epoch 718/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0785e-04 - val_loss: 3.2389e-04\n",
      "Epoch 719/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0790e-04 - val_loss: 3.2249e-04\n",
      "Epoch 720/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0799e-04 - val_loss: 3.2325e-04\n",
      "Epoch 721/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0786e-04 - val_loss: 3.2228e-04\n",
      "Epoch 722/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0754e-04 - val_loss: 3.2219e-04\n",
      "Epoch 723/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0774e-04 - val_loss: 3.2273e-04\n",
      "Epoch 724/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0793e-04 - val_loss: 3.2314e-04\n",
      "Epoch 725/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0777e-04 - val_loss: 3.2275e-04\n",
      "Epoch 726/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0766e-04 - val_loss: 3.2203e-04\n",
      "Epoch 727/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0784e-04 - val_loss: 3.2322e-04\n",
      "Epoch 728/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0789e-04 - val_loss: 3.2246e-04\n",
      "Epoch 729/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0769e-04 - val_loss: 3.2239e-04\n",
      "Epoch 730/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0774e-04 - val_loss: 3.2252e-04\n",
      "Epoch 731/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0767e-04 - val_loss: 3.2255e-04\n",
      "Epoch 732/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0769e-04 - val_loss: 3.2288e-04\n",
      "Epoch 733/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0809e-04 - val_loss: 3.2293e-04\n",
      "Epoch 734/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0774e-04 - val_loss: 3.2193e-04\n",
      "Epoch 735/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0763e-04 - val_loss: 3.2331e-04\n",
      "Epoch 736/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0740e-04 - val_loss: 3.2247e-04\n",
      "Epoch 737/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0759e-04 - val_loss: 3.2235e-04\n",
      "Epoch 738/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0744e-04 - val_loss: 3.2401e-04\n",
      "Epoch 739/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0768e-04 - val_loss: 3.2225e-04\n",
      "Epoch 740/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0780e-04 - val_loss: 3.2294e-04\n",
      "Epoch 741/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0756e-04 - val_loss: 3.2445e-04\n",
      "Epoch 742/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0791e-04 - val_loss: 3.2241e-04\n",
      "Epoch 743/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0747e-04 - val_loss: 3.2232e-04\n",
      "Epoch 744/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0755e-04 - val_loss: 3.2527e-04\n",
      "Epoch 745/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0749e-04 - val_loss: 3.2271e-04\n",
      "Epoch 746/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0743e-04 - val_loss: 3.2338e-04\n",
      "Epoch 747/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0791e-04 - val_loss: 3.2331e-04\n",
      "Epoch 748/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0754e-04 - val_loss: 3.2181e-04\n",
      "Epoch 749/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0739e-04 - val_loss: 3.2222e-04\n",
      "Epoch 750/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0734e-04 - val_loss: 3.2243e-04\n",
      "Epoch 751/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0752e-04 - val_loss: 3.2317e-04\n",
      "Epoch 752/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0753e-04 - val_loss: 3.2274e-04\n",
      "Epoch 753/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0719e-04 - val_loss: 3.2300e-04\n",
      "Epoch 754/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0763e-04 - val_loss: 3.2283e-04\n",
      "Epoch 755/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0715e-04 - val_loss: 3.2251e-04\n",
      "Epoch 756/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0731e-04 - val_loss: 3.2203e-04\n",
      "Epoch 757/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0720e-04 - val_loss: 3.2238e-04\n",
      "Epoch 758/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0715e-04 - val_loss: 3.2255e-04\n",
      "Epoch 759/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0712e-04 - val_loss: 3.2244e-04\n",
      "Epoch 760/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0741e-04 - val_loss: 3.2240e-04\n",
      "Epoch 761/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0735e-04 - val_loss: 3.2236e-04\n",
      "Epoch 762/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0728e-04 - val_loss: 3.2217e-04\n",
      "Epoch 763/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0707e-04 - val_loss: 3.2388e-04\n",
      "Epoch 764/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0705e-04 - val_loss: 3.2185e-04\n",
      "Epoch 765/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0709e-04 - val_loss: 3.2270e-04\n",
      "Epoch 766/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0734e-04 - val_loss: 3.2251e-04\n",
      "Epoch 767/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0733e-04 - val_loss: 3.2207e-04\n",
      "Epoch 768/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0703e-04 - val_loss: 3.2279e-04\n",
      "Epoch 769/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0696e-04 - val_loss: 3.2215e-04\n",
      "Epoch 770/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0724e-04 - val_loss: 3.2258e-04\n",
      "Epoch 771/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0690e-04 - val_loss: 3.2163e-04\n",
      "Epoch 772/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0714e-04 - val_loss: 3.2161e-04\n",
      "Epoch 773/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0703e-04 - val_loss: 3.2224e-04\n",
      "Epoch 774/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0711e-04 - val_loss: 3.2223e-04\n",
      "Epoch 775/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0703e-04 - val_loss: 3.2250e-04\n",
      "Epoch 776/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0711e-04 - val_loss: 3.2329e-04\n",
      "Epoch 777/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0691e-04 - val_loss: 3.2163e-04\n",
      "Epoch 778/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0701e-04 - val_loss: 3.2263e-04\n",
      "Epoch 779/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0700e-04 - val_loss: 3.2205e-04\n",
      "Epoch 780/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0703e-04 - val_loss: 3.2203e-04\n",
      "Epoch 781/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0679e-04 - val_loss: 3.2163e-04\n",
      "Epoch 782/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0711e-04 - val_loss: 3.2150e-04\n",
      "Epoch 783/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0690e-04 - val_loss: 3.2157e-04\n",
      "Epoch 784/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0689e-04 - val_loss: 3.2148e-04\n",
      "Epoch 785/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0671e-04 - val_loss: 3.2218e-04\n",
      "Epoch 786/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0675e-04 - val_loss: 3.2195e-04\n",
      "Epoch 787/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0683e-04 - val_loss: 3.2363e-04\n",
      "Epoch 788/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0683e-04 - val_loss: 3.2303e-04\n",
      "Epoch 789/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0686e-04 - val_loss: 3.2253e-04\n",
      "Epoch 790/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0686e-04 - val_loss: 3.2127e-04\n",
      "Epoch 791/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0674e-04 - val_loss: 3.2266e-04\n",
      "Epoch 792/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0664e-04 - val_loss: 3.2149e-04\n",
      "Epoch 793/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0690e-04 - val_loss: 3.2204e-04\n",
      "Epoch 794/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0675e-04 - val_loss: 3.2182e-04\n",
      "Epoch 795/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0682e-04 - val_loss: 3.2230e-04\n",
      "Epoch 796/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0696e-04 - val_loss: 3.2233e-04\n",
      "Epoch 797/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0670e-04 - val_loss: 3.2156e-04\n",
      "Epoch 798/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0700e-04 - val_loss: 3.2295e-04\n",
      "Epoch 799/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0656e-04 - val_loss: 3.2205e-04\n",
      "Epoch 800/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0639e-04 - val_loss: 3.2218e-04\n",
      "Epoch 801/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0759e-04 - val_loss: 3.2340e-04\n",
      "Epoch 802/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0685e-04 - val_loss: 3.2214e-04\n",
      "Epoch 803/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0672e-04 - val_loss: 3.2187e-04\n",
      "Epoch 804/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0693e-04 - val_loss: 3.2193e-04\n",
      "Epoch 805/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0679e-04 - val_loss: 3.2212e-04\n",
      "Epoch 806/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0650e-04 - val_loss: 3.2131e-04\n",
      "Epoch 807/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0665e-04 - val_loss: 3.2185e-04\n",
      "Epoch 808/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0646e-04 - val_loss: 3.2215e-04\n",
      "Epoch 809/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0658e-04 - val_loss: 3.2164e-04\n",
      "Epoch 810/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0650e-04 - val_loss: 3.2202e-04\n",
      "Epoch 811/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0655e-04 - val_loss: 3.2190e-04\n",
      "Epoch 812/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0655e-04 - val_loss: 3.2185e-04\n",
      "Epoch 813/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0639e-04 - val_loss: 3.2161e-04\n",
      "Epoch 814/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0647e-04 - val_loss: 3.2109e-04\n",
      "Epoch 815/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0662e-04 - val_loss: 3.2174e-04\n",
      "Epoch 816/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0664e-04 - val_loss: 3.2278e-04\n",
      "Epoch 817/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0639e-04 - val_loss: 3.2233e-04\n",
      "Epoch 818/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0645e-04 - val_loss: 3.2144e-04\n",
      "Epoch 819/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0633e-04 - val_loss: 3.2108e-04\n",
      "Epoch 820/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0639e-04 - val_loss: 3.2234e-04\n",
      "Epoch 821/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0645e-04 - val_loss: 3.2209e-04\n",
      "Epoch 822/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0624e-04 - val_loss: 3.2182e-04\n",
      "Epoch 823/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0633e-04 - val_loss: 3.2234e-04\n",
      "Epoch 824/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0633e-04 - val_loss: 3.2197e-04\n",
      "Epoch 825/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0623e-04 - val_loss: 3.2103e-04\n",
      "Epoch 826/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0632e-04 - val_loss: 3.2131e-04\n",
      "Epoch 827/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0614e-04 - val_loss: 3.2123e-04\n",
      "Epoch 828/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0655e-04 - val_loss: 3.2138e-04\n",
      "Epoch 829/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0629e-04 - val_loss: 3.2113e-04\n",
      "Epoch 830/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0602e-04 - val_loss: 3.2145e-04\n",
      "Epoch 831/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0635e-04 - val_loss: 3.2237e-04\n",
      "Epoch 832/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0618e-04 - val_loss: 3.2228e-04\n",
      "Epoch 833/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0626e-04 - val_loss: 3.2131e-04\n",
      "Epoch 834/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0617e-04 - val_loss: 3.2111e-04\n",
      "Epoch 835/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0622e-04 - val_loss: 3.2143e-04\n",
      "Epoch 836/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0616e-04 - val_loss: 3.2183e-04\n",
      "Epoch 837/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0629e-04 - val_loss: 3.2621e-04\n",
      "Epoch 838/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0646e-04 - val_loss: 3.2207e-04\n",
      "Epoch 839/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0602e-04 - val_loss: 3.2196e-04\n",
      "Epoch 840/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0604e-04 - val_loss: 3.2290e-04\n",
      "Epoch 841/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0587e-04 - val_loss: 3.2152e-04\n",
      "Epoch 842/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0598e-04 - val_loss: 3.2136e-04\n",
      "Epoch 843/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0620e-04 - val_loss: 3.2218e-04\n",
      "Epoch 844/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0612e-04 - val_loss: 3.2100e-04\n",
      "Epoch 845/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0596e-04 - val_loss: 3.2119e-04\n",
      "Epoch 846/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0603e-04 - val_loss: 3.2124e-04\n",
      "Epoch 847/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0604e-04 - val_loss: 3.2165e-04\n",
      "Epoch 848/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0597e-04 - val_loss: 3.2362e-04\n",
      "Epoch 849/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0616e-04 - val_loss: 3.2094e-04\n",
      "Epoch 850/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0591e-04 - val_loss: 3.2177e-04\n",
      "Epoch 851/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0597e-04 - val_loss: 3.2232e-04\n",
      "Epoch 852/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0588e-04 - val_loss: 3.2035e-04\n",
      "Epoch 853/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0581e-04 - val_loss: 3.2121e-04\n",
      "Epoch 854/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0592e-04 - val_loss: 3.2119e-04\n",
      "Epoch 855/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0589e-04 - val_loss: 3.2210e-04\n",
      "Epoch 856/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0575e-04 - val_loss: 3.2081e-04\n",
      "Epoch 857/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0568e-04 - val_loss: 3.2174e-04\n",
      "Epoch 858/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0595e-04 - val_loss: 3.2143e-04\n",
      "Epoch 859/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0590e-04 - val_loss: 3.2132e-04\n",
      "Epoch 860/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0575e-04 - val_loss: 3.2136e-04\n",
      "Epoch 861/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0566e-04 - val_loss: 3.2239e-04\n",
      "Epoch 862/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0591e-04 - val_loss: 3.2245e-04\n",
      "Epoch 863/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0589e-04 - val_loss: 3.2223e-04\n",
      "Epoch 864/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0583e-04 - val_loss: 3.2080e-04\n",
      "Epoch 865/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0591e-04 - val_loss: 3.2171e-04\n",
      "Epoch 866/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0572e-04 - val_loss: 3.2090e-04\n",
      "Epoch 867/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0573e-04 - val_loss: 3.2097e-04\n",
      "Epoch 868/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0558e-04 - val_loss: 3.2191e-04\n",
      "Epoch 869/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0596e-04 - val_loss: 3.2142e-04\n",
      "Epoch 870/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0551e-04 - val_loss: 3.2117e-04\n",
      "Epoch 871/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0559e-04 - val_loss: 3.2140e-04\n",
      "Epoch 872/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0556e-04 - val_loss: 3.2168e-04\n",
      "Epoch 873/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0570e-04 - val_loss: 3.2013e-04\n",
      "Epoch 874/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0578e-04 - val_loss: 3.2129e-04\n",
      "Epoch 875/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0547e-04 - val_loss: 3.2103e-04\n",
      "Epoch 876/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0532e-04 - val_loss: 3.2046e-04\n",
      "Epoch 877/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0590e-04 - val_loss: 3.2067e-04\n",
      "Epoch 878/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0563e-04 - val_loss: 3.2096e-04\n",
      "Epoch 879/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0543e-04 - val_loss: 3.2216e-04\n",
      "Epoch 880/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0541e-04 - val_loss: 3.2184e-04\n",
      "Epoch 881/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0528e-04 - val_loss: 3.2051e-04\n",
      "Epoch 882/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0549e-04 - val_loss: 3.2095e-04\n",
      "Epoch 883/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0549e-04 - val_loss: 3.2076e-04\n",
      "Epoch 884/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0529e-04 - val_loss: 3.2116e-04\n",
      "Epoch 885/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0534e-04 - val_loss: 3.2036e-04\n",
      "Epoch 886/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0540e-04 - val_loss: 3.2009e-04\n",
      "Epoch 887/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0520e-04 - val_loss: 3.2111e-04\n",
      "Epoch 888/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0558e-04 - val_loss: 3.2145e-04\n",
      "Epoch 889/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0553e-04 - val_loss: 3.2019e-04\n",
      "Epoch 890/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0538e-04 - val_loss: 3.2093e-04\n",
      "Epoch 891/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0558e-04 - val_loss: 3.2082e-04\n",
      "Epoch 892/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0534e-04 - val_loss: 3.2095e-04\n",
      "Epoch 893/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0544e-04 - val_loss: 3.2048e-04\n",
      "Epoch 894/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0531e-04 - val_loss: 3.2082e-04\n",
      "Epoch 895/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0512e-04 - val_loss: 3.2115e-04\n",
      "Epoch 896/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0522e-04 - val_loss: 3.2076e-04\n",
      "Epoch 897/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0517e-04 - val_loss: 3.2086e-04\n",
      "Epoch 898/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0641e-04 - val_loss: 3.2080e-04\n",
      "Epoch 899/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0552e-04 - val_loss: 3.2078e-04\n",
      "Epoch 900/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0524e-04 - val_loss: 3.2047e-04\n",
      "Epoch 901/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0481e-04 - val_loss: 3.2020e-04\n",
      "Epoch 902/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0562e-04 - val_loss: 3.2112e-04\n",
      "Epoch 903/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0548e-04 - val_loss: 3.2045e-04\n",
      "Epoch 904/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0511e-04 - val_loss: 3.2035e-04\n",
      "Epoch 905/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0509e-04 - val_loss: 3.2100e-04\n",
      "Epoch 906/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0514e-04 - val_loss: 3.2023e-04\n",
      "Epoch 907/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0526e-04 - val_loss: 3.2081e-04\n",
      "Epoch 908/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0519e-04 - val_loss: 3.2102e-04\n",
      "Epoch 909/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0517e-04 - val_loss: 3.2044e-04\n",
      "Epoch 910/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0521e-04 - val_loss: 3.2014e-04\n",
      "Epoch 911/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0527e-04 - val_loss: 3.1960e-04\n",
      "Epoch 912/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0497e-04 - val_loss: 3.2051e-04\n",
      "Epoch 913/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0493e-04 - val_loss: 3.2029e-04\n",
      "Epoch 914/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0480e-04 - val_loss: 3.2045e-04\n",
      "Epoch 915/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0521e-04 - val_loss: 3.2007e-04\n",
      "Epoch 916/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0533e-04 - val_loss: 3.2068e-04\n",
      "Epoch 917/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0517e-04 - val_loss: 3.2051e-04\n",
      "Epoch 918/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0480e-04 - val_loss: 3.2028e-04\n",
      "Epoch 919/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0489e-04 - val_loss: 3.2186e-04\n",
      "Epoch 920/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0520e-04 - val_loss: 3.2026e-04\n",
      "Epoch 921/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0471e-04 - val_loss: 3.2060e-04\n",
      "Epoch 922/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0473e-04 - val_loss: 3.2037e-04\n",
      "Epoch 923/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0482e-04 - val_loss: 3.2191e-04\n",
      "Epoch 924/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0495e-04 - val_loss: 3.2232e-04\n",
      "Epoch 925/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0470e-04 - val_loss: 3.2032e-04\n",
      "Epoch 926/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0513e-04 - val_loss: 3.2119e-04\n",
      "Epoch 927/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0490e-04 - val_loss: 3.2033e-04\n",
      "Epoch 928/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0462e-04 - val_loss: 3.2075e-04\n",
      "Epoch 929/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0495e-04 - val_loss: 3.2012e-04\n",
      "Epoch 930/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0501e-04 - val_loss: 3.2119e-04\n",
      "Epoch 931/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0493e-04 - val_loss: 3.2069e-04\n",
      "Epoch 932/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0478e-04 - val_loss: 3.2069e-04\n",
      "Epoch 933/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0442e-04 - val_loss: 3.2002e-04\n",
      "Epoch 934/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0476e-04 - val_loss: 3.2024e-04\n",
      "Epoch 935/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0441e-04 - val_loss: 3.2048e-04\n",
      "Epoch 936/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0474e-04 - val_loss: 3.1997e-04\n",
      "Epoch 937/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0485e-04 - val_loss: 3.2062e-04\n",
      "Epoch 938/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0485e-04 - val_loss: 3.2153e-04\n",
      "Epoch 939/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0505e-04 - val_loss: 3.2016e-04\n",
      "Epoch 940/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0474e-04 - val_loss: 3.1980e-04\n",
      "Epoch 941/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0470e-04 - val_loss: 3.2124e-04\n",
      "Epoch 942/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0444e-04 - val_loss: 3.2002e-04\n",
      "Epoch 943/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0452e-04 - val_loss: 3.2084e-04\n",
      "Epoch 944/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0474e-04 - val_loss: 3.1953e-04\n",
      "Epoch 945/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0461e-04 - val_loss: 3.2036e-04\n",
      "Epoch 946/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0442e-04 - val_loss: 3.1951e-04\n",
      "Epoch 947/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0450e-04 - val_loss: 3.2191e-04\n",
      "Epoch 948/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0453e-04 - val_loss: 3.2033e-04\n",
      "Epoch 949/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0442e-04 - val_loss: 3.2067e-04\n",
      "Epoch 950/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0444e-04 - val_loss: 3.1989e-04\n",
      "Epoch 951/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0470e-04 - val_loss: 3.2011e-04\n",
      "Epoch 952/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0439e-04 - val_loss: 3.2045e-04\n",
      "Epoch 953/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0434e-04 - val_loss: 3.2025e-04\n",
      "Epoch 954/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0451e-04 - val_loss: 3.2047e-04\n",
      "Epoch 955/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0452e-04 - val_loss: 3.2014e-04\n",
      "Epoch 956/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0458e-04 - val_loss: 3.2033e-04\n",
      "Epoch 957/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0438e-04 - val_loss: 3.1918e-04\n",
      "Epoch 958/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0454e-04 - val_loss: 3.1992e-04\n",
      "Epoch 959/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0448e-04 - val_loss: 3.2015e-04\n",
      "Epoch 960/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0440e-04 - val_loss: 3.1935e-04\n",
      "Epoch 961/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0431e-04 - val_loss: 3.2092e-04\n",
      "Epoch 962/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0437e-04 - val_loss: 3.2216e-04\n",
      "Epoch 963/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0408e-04 - val_loss: 3.1989e-04\n",
      "Epoch 964/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0446e-04 - val_loss: 3.2011e-04\n",
      "Epoch 965/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0430e-04 - val_loss: 3.1976e-04\n",
      "Epoch 966/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0452e-04 - val_loss: 3.2024e-04\n",
      "Epoch 967/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0433e-04 - val_loss: 3.2014e-04\n",
      "Epoch 968/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0434e-04 - val_loss: 3.2143e-04\n",
      "Epoch 969/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0417e-04 - val_loss: 3.1965e-04\n",
      "Epoch 970/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0411e-04 - val_loss: 3.2046e-04\n",
      "Epoch 971/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0435e-04 - val_loss: 3.2084e-04\n",
      "Epoch 972/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0416e-04 - val_loss: 3.1996e-04\n",
      "Epoch 973/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0421e-04 - val_loss: 3.1916e-04\n",
      "Epoch 974/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0400e-04 - val_loss: 3.2038e-04\n",
      "Epoch 975/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0422e-04 - val_loss: 3.1985e-04\n",
      "Epoch 976/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0406e-04 - val_loss: 3.2095e-04\n",
      "Epoch 977/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0441e-04 - val_loss: 3.2008e-04\n",
      "Epoch 978/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0435e-04 - val_loss: 3.1968e-04\n",
      "Epoch 979/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0408e-04 - val_loss: 3.1972e-04\n",
      "Epoch 980/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0389e-04 - val_loss: 3.1975e-04\n",
      "Epoch 981/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0587e-04 - val_loss: 3.2043e-04\n",
      "Epoch 982/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0394e-04 - val_loss: 3.2023e-04\n",
      "Epoch 983/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0396e-04 - val_loss: 3.1897e-04\n",
      "Epoch 984/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0397e-04 - val_loss: 3.2044e-04\n",
      "Epoch 985/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0436e-04 - val_loss: 3.2054e-04\n",
      "Epoch 986/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0471e-04 - val_loss: 3.1955e-04\n",
      "Epoch 987/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0389e-04 - val_loss: 3.2047e-04\n",
      "Epoch 988/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0392e-04 - val_loss: 3.1918e-04\n",
      "Epoch 989/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0383e-04 - val_loss: 3.1989e-04\n",
      "Epoch 990/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0366e-04 - val_loss: 3.2015e-04\n",
      "Epoch 991/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0386e-04 - val_loss: 3.2009e-04\n",
      "Epoch 992/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0404e-04 - val_loss: 3.1960e-04\n",
      "Epoch 993/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0389e-04 - val_loss: 3.2268e-04\n",
      "Epoch 994/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0399e-04 - val_loss: 3.2048e-04\n",
      "Epoch 995/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0394e-04 - val_loss: 3.2041e-04\n",
      "Epoch 996/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0409e-04 - val_loss: 3.1945e-04\n",
      "Epoch 997/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0397e-04 - val_loss: 3.1932e-04\n",
      "Epoch 998/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0368e-04 - val_loss: 3.1933e-04\n",
      "Epoch 999/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0370e-04 - val_loss: 3.1955e-04\n",
      "Epoch 1000/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0399e-04 - val_loss: 3.1946e-04\n",
      "INFO:tensorflow:Assets written to: AET_CF_Trial_14/models/saved_model_14_LSP_AET_CF_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: AET_CF_Trial_14/models/saved_model_14_LSP_AET_CF_2/assets\n",
      "  5%|█▉                                   | 3/57 [1:08:15<20:32:07, 1369.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0380e-04 - val_loss: 3.1969e-04\n",
      "Epoch 2/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0368e-04 - val_loss: 3.1926e-04\n",
      "Epoch 3/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0382e-04 - val_loss: 3.1954e-04\n",
      "Epoch 4/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0395e-04 - val_loss: 3.1999e-04\n",
      "Epoch 5/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0350e-04 - val_loss: 3.1934e-04\n",
      "Epoch 6/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0363e-04 - val_loss: 3.2181e-04\n",
      "Epoch 7/1000\n",
      "250/250 [==============================] - 1s 6ms/step - loss: 3.0410e-04 - val_loss: 3.2091e-04\n",
      "Epoch 8/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0360e-04 - val_loss: 3.1909e-04\n",
      "Epoch 9/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0369e-04 - val_loss: 3.1914e-04\n",
      "Epoch 10/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0365e-04 - val_loss: 3.1902e-04\n",
      "Epoch 11/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0345e-04 - val_loss: 3.2102e-04\n",
      "Epoch 12/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0402e-04 - val_loss: 3.1935e-04\n",
      "Epoch 13/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0375e-04 - val_loss: 3.1983e-04\n",
      "Epoch 14/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0370e-04 - val_loss: 3.1956e-04\n",
      "Epoch 15/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0382e-04 - val_loss: 3.1914e-04\n",
      "Epoch 16/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0361e-04 - val_loss: 3.1966e-04\n",
      "Epoch 17/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0376e-04 - val_loss: 3.1991e-04\n",
      "Epoch 18/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0362e-04 - val_loss: 3.1999e-04\n",
      "Epoch 19/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0350e-04 - val_loss: 3.2008e-04\n",
      "Epoch 20/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0376e-04 - val_loss: 3.1933e-04\n",
      "Epoch 21/1000\n",
      "250/250 [==============================] - 1s 5ms/step - loss: 3.0349e-04 - val_loss: 3.1926e-04\n",
      "Epoch 22/1000\n",
      " 40/250 [===>..........................] - ETA: 1s - loss: 2.9966e-04"
     ]
    }
   ],
   "source": [
    "for counts in tqdm(range(57)):\n",
    "    output_path = os.path.join(folder_name, name + f\"Predictions{counts}.txt\")\n",
    "    with open(output_path, \"w\") as file:\n",
    "        history = autoencoder.fit(X_train_f, X_train_f, batch_size=256, epochs=1000,\n",
    "                                  validation_data=(X_valid_f, X_valid_f), verbose=1)\n",
    "\n",
    "        training_history = pd.DataFrame(history.history)\n",
    "        plt.plot(training_history)\n",
    "        file_name_0 = os.path.join(folder_name, name + \"Training_History\" + str(counts))\n",
    "        training_history.to_pickle(file_name_0)\n",
    "        file_name_1 = os.path.join(folder_name, name + \"Training_History\" + str(counts) + \".png\")\n",
    "        plt.savefig(file_name_1, dpi=300)\n",
    "        plt.clf()\n",
    "\n",
    "        dr_model = tf.keras.models.Model(inputs=autoencoder.get_layer('ae_input').input,\n",
    "                                         outputs=autoencoder.get_layer('ae_latent').output)\n",
    "        dr_model.summary(print_fn=lambda x: file.write(x + '\\n'))\n",
    "\n",
    "        batch_size = 32\n",
    "        x = []\n",
    "        y = []\n",
    "        z = []\n",
    "        indices = []\n",
    "\n",
    "        for batch_start in range(0, len(X_valid_f), batch_size):\n",
    "            batch_end = min(batch_start + batch_size, len(X_valid_f))\n",
    "            X_batch = np.array(X_valid_f.iloc[batch_start:batch_end])\n",
    "            y_batch = y_valid_f.iloc[batch_start:batch_end]\n",
    "\n",
    "            op_batch = dr_model.predict(X_batch, verbose=0)\n",
    "\n",
    "            for i, op in enumerate(op_batch):\n",
    "                z.append(y_batch.iloc[i]['class'])  # Access class label correctly\n",
    "                x.append(op[0])\n",
    "                y.append(op[1])\n",
    "                indices.append(y_batch.iloc[i].name)  # Using .name to get the index of the row\n",
    "                file.write(f\"Prediction {batch_start + i}: {op}\\n\")\n",
    "\n",
    "        df = pd.DataFrame()\n",
    "        df['x'] = x\n",
    "        df['y'] = y\n",
    "        df['z'] = [\"trajectory-\" + str(k) for k in z]\n",
    "        df['index'] = indices\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        fig = sns.scatterplot(x='x', y='y', hue='z', data=df, s=10)\n",
    "        file_name_2 = os.path.join(folder_name, name + 'Predictions' + str(counts) + \".png\")\n",
    "        fig.figure.savefig(file_name_2, dpi=300)\n",
    "        plt.clf()\n",
    "\n",
    "        file_name_3 = os.path.join(folder_name, name + 'Predictions' + str(counts))\n",
    "        df.to_pickle(file_name_3)\n",
    "\n",
    "        model_folder = os.path.join(folder_name, 'models')\n",
    "        if not os.path.exists(model_folder):\n",
    "            os.makedirs(model_folder)\n",
    "        file_name = os.path.join(model_folder, 'saved_model_' + name + str(counts))\n",
    "        autoencoder.save(file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
